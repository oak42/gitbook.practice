# CONTENTS:

* 01 天天写CRUD，你知道你的系统是如何跟MySQL打交道的吗？
* 02 为了执行SQL语句，你知道MySQL用了什么样的架构设计吗？
* 03 用一次数据更新流程，初步了解InnoDB存储引擎的架构设计
* 04 借着更新语句在InnoDB存储引擎中的执行流程，聊聊binlog是什么？
* 05 生产经验：真实生产环境下的数据库机器配置如何规划？
* 06 生产经验：互联网公司的生产环境数据库是如何进行性能测试的？
* 07 生产经验：如何对生产环境中的数据库进行360度无死角压测？
* 08 生产经验：在数据库的压测过程中，如何360度无死角观察机器性能？
* 09 生产经验：如何为生产环境中的数据库部署监控系统？
* 10 生产经验：如何为数据库的监控系统部署可视化报表系统？
* 11 从数据的增删改开始讲起，回顾一下Buffer Pool在数据库里的地位
* 12 Buffer Pool这个内存数据结构到底长个什么样子？
* 13 从磁盘读取数据页到Buffer Pool的时候，free链表有什么用？
* 14 当我们更新Buffer Pool中的数据时，flush链表有什么用？
* 15 当Buffer Pool中的缓存页不够的时候，如何基于LRU算法淘汰部分缓存？
* 16 简单的LRU链表在Buffer Pool实际运行中，可能导致哪些问题？
* 17 MySQL是如何基于冷热数据分离的方案，来优化LRU算法的？
* 18 基于冷热数据分离方案优化后的LRU链表，是如何解决之前的问题的？
* 19 MySQL是如何将LRU链表的使用性能优化到极致的？
* 20 对于LRU链表中尾部的缓存页，是如何淘汰他们刷入磁盘的？
* 21 生产经验：如何通过多个Buffer Pool来优化数据库的并发性能？
* 22 生产经验：如何通过chunk来支持数据库运行期间的Buffer Pool动态调整？
* 23 生产经验：在生产环境中，如何基于机器配置来合理设置Buffer Pool？
* 24 我们写入数据库的一行数据，在磁盘上是怎么存储的？
* 25 对于VARCHAR这种变长字段，在磁盘上到底是如何存储的？
* 26 一行数据中的多个NULL字段值在磁盘上怎么存储？
* 27 磁盘文件中， 40个bit位的数据头以及真实数据是如何存储的？
* 28 我们每一行的实际数据在磁盘上是如何存储的？
* 29 理解数据在磁盘上的物理存储之后，聊聊行溢出是什么东西？
* 30 用于存放磁盘上的多行数据的数据页到底长个什么样子？
* 31 表空间以及划分多个数据页的数据区，又是什么概念？
* 32 一文总结初步了解到的MySQL存储模型以及数据读写机制
* 33 MySQL数据库的日志顺序读写以及数据文件随机读写的原理
* 34 生产经验：Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理
* 35 生产经验：数据库服务器使用的RAID存储架构初步介绍
* 36 生产经验：数据库服务器上的RAID存储架构的电池充放电原理
* 37 案例实战：RAID锂电池充放电导致的MySQL数据库性能抖动的优化
* 38 案例实战：数据库无法连接故障的定位，Too many connections
* 39 案例实战：如何解决经典的Too many connections故障？背后原理是什么
* 40 重新回顾redo日志对于事务提交后，数据绝对不会丢失的意义
* 41 在Buffer Pool执行完增删改之后，写入日志文件的redo log长什么样？
* 42 redo log是直接一条一条写入文件的吗？非也，揭秘redo log block！
* 43 直接强行把redo log写入磁盘？非也，揭秘redo log buffer！
* 44 redo log buffer中的缓冲日志，到底什么时候可以写入磁盘？
* 45 如果事务执行到一半要回滚怎么办？再探undo log回滚日志原理！
* 46 一起来看看INSRET语句的undo log回滚日志长什么样？
* 47 简单回顾一下， MySQL运行时多个事务同时执行是什么场景？
* 48 多个事务并发更新以及查询数据，为什么会有脏写和脏读的问题？
* 49 一个事务多次查询一条数据读到的都是不同的值，这就是不可重复读？
* 50 听起来很恐怖的数据库幻读，到底是个什么奇葩问题？
* 51 SQL标准中对事务的4个隔离级别，都是如何规定的呢？
* 52 MySQL是如何支持4种事务隔离级别的？Spring事务注解是如何设置的？
* 53 理解MVCC机制的前奏：undo log版本链是个什么东西？
* 54 基于undo log多版本链条实现的ReadView机制，到底是什么？
* 55 Read Committed隔离级别是如何基于ReadView机制实现的？
* 56 MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？
* 57 停一停脚步：梳理一下数据库的多事务并发运行的隔离机制
* 58 多个事务更新同一行数据时，是如何加锁避免脏写的？
* 59 对MySQL锁机制再深入一步，共享锁和独占锁到底是什么？
* 60 在数据库里，哪些操作会导致在表级别加锁呢？
* 61 表锁和行锁互相之间的关系以及互斥规则是什么呢？
* 62 案例实战：线上数据库不确定性的性能抖动优化实践（上）
* 63 案例实战：线上数据库莫名其妙的随机性能抖动优化（下）
* 64 深入研究索引之前，先来看看磁盘数据页的存储结构
* 65 假设没有任何索引，数据库是如何根据查询语句搜索数据的？
* 66 不断在表中插入数据时，物理存储是如何进行页分裂的？
* 67 基于主键的索引是如何设计的，以及如何根据主键索引查询？
* 68 索引的页存储物理结构，是如何用B+树来实现的？
* 69 更新数据的时候，自动维护的聚簇索引到底是什么？
* 70 针对主键之外的字段建立的二级索引，又是如何运作的？
* 71 插入数据时到底是如何维护好不同索引的B+树的？
* 72 一个表里是不是索引搞的越多越好？那你就大错特错了！
* 73 通过一步一图来深入理解联合索引查询原理以及全值匹配规则
* 74 再来看看几个最常见和最基本的索引使用规则
* 75 当我们在SQL里进行排序的时候，如何才能使用索引？
* 76 当我们在SQL里进行分组的时候，如何才能使用索引？
* 77 回表查询对性能的损害以及覆盖索引是什么？
* 78 设计索引的时候，我们一般要考虑哪些因素呢？（上）
* 79 设计索引的时候，我们一般要考虑哪些因素呢？（中）
* 80 设计索引的时候，我们一般要考虑哪些因素呢？（下）
* 81 案例实战：陌生人社交APP的MySQL索引设计实战（一）
* 82 案例实战：陌生人社交APP的MySQL索引设计实战（二）
* 83 案例实战：陌生人社交APP的MySQL索引设计实战（3）
* 84 案例实战：陌生人社交APP的MySQL索引设计实战（4）
* 85 提纲挈领的告诉你，SQL语句的执行计划和性能优化有什么关系？
* 86 以MySQL单表查询来举例，看看执行计划包含哪些内容（1）？
* 87 以MySQL单表查询来举例，看看执行计划包含哪些内容（2）？
* 88 再次重温写出各种SQL语句的时候，会用什么执行计划？（1）
* 89 再次重温写出各种SQL语句的时候，会用什么执行计划？（2）
* 90 再次重温写出各种SQL语句的时候，会用什么执行计划？（3）
* 91 深入探索多表关联的SQL语句到底是如何执行的？（1）
* 92 深入探索多表关联的SQL语句到底是如何执行的？（2）
* 93 深入探索多表关联的SQL语句到底是如何执行的？（3）
* 94 MySQL是如何根据成本优化选择执行计划的？（上）
* 95 MySQL是如何根据成本优化选择执行计划的？（中）
* 96 MySQL是如何根据成本优化选择执行计划的？（下）
* 97 MySQL是如何基于各种规则去优化执行计划的？（上）
* 98 MySQL是如何基于各种规则去优化执行计划的？（中）
* 99 MySQL是如何基于各种规则去优化执行计划的？（下）
* 100 透彻研究通过explain命令得到的SQL执行计划（1）
* 101 透彻研究通过explain命令得到的SQL执行计划（2）
* 102 透彻研究通过explain命令得到的SQL执行计划（3）
* 103 透彻研究通过explain命令得到的SQL执行计划（4）
* 104 透彻研究通过explain命令得到的SQL执行计划（5）
* 105 透彻研究通过explain命令得到的SQL执行计划（6）
* 106 透彻研究通过explain命令得到的SQL执行计划（7）
* 107 透彻研究通过explain命令得到的SQL执行计划（8）
* 108 透彻研究通过explain命令得到的SQL执行计划（9）
* 109 案例实战：千万级用户场景下的运营系统SQL调优（1）
* 110 案例实战：千万级用户场景下的运营系统SQL调优（2）
* 111 案例实战：千万级用户场景下的运营系统SQL调优（3）
* 112 案例实战：亿级数据量商品系统的SQL调优实战（1）
* 113 案例实战：亿级数据量商品系统的SQL调优实战（2）
* 114 案例实战：亿级数据量商品系统的SQL调优实战（3）
* 115 案例实战：数十亿数量级评论系统的SQL调优实战（1）
* 116 案例实战：千万级数据删除导致的慢查询优化实践（1）
* 117 案例实战：千万级数据删除导致的慢查询优化实践（2）
* 118 我们为什么要搭建一套MySQL的主从复制架构？（1）
* 119 我们为什么要搭建一套MySQL的主从复制架构？（2）
* 120 案例实战：千万级数据删除导致的慢查询优化实践（3）
* 121 如何为MySQL搭建一套主从复制架构？（1）
* 122 如何为MySQL搭建一套主从复制架构？（2）
* 123 如何为MySQL搭建一套主从复制架构？（3）
* 124 主从复制架构中的数据延迟问题，应该如何解决？
* 125 数据库高可用：基于主从复制实现故障转移（1）
* 126 数据库高可用：基于主从复制实现故障转移（2）
* 127 数据库高可用：基于主从复制实现故障转移（3）
* 128 案例实战：大型电商网站的上亿数据量的用户表如何进行水平拆分？
* 129 案例实战：一线电商公司的订单系统是如何进行数据库设计的？
* 130 案例实战：下一个难题，如果需要进行垮库的分页操作，应该怎么来做？
* 131 案例实战：当分库分表技术方案运行几年过后，再次进行扩容应该怎么做？
* 132 专栏总结：撒花庆祝大家对数据库技术的掌握更进一步



## 01 天天写CRUD，你知道你的系统是如何跟MySQL打交道的吗？

**1、Java工程师眼中的数据库是什么东西？**

从今天开始，我们将要开始一个MySQL的专栏，一起来研究MySQL数据库的底层原理和各种实践案例，以及互联网公司的技术方案。

现在我们先来看看，在一个Java工程师眼中的数据库是什么东西？

平时我们在做Java系统时，一般情况下都会连接到一个MySQL数据库上去，执行各种增删改查的语句。

据我所知，目前行业里大部分的Java工程师对MySQL的了解和掌握程度，大致就停留在这么一个阶段：对MySQL可以建库建表建索引，然后就是执行增删改查去更新和查询里面的数据！

所以我们看下面的图，很多Java工程师眼中的数据库大致就是下面这样子。

（**附加说明**：我在写《从0开始带你成为JVM实战高手》专栏时，采用的是亿图图示这个画图工具，现在为了统一画图风格，本专栏会改成《从0开始带你成为消息中间件实战高手》专栏一样的画图工具）    ![img](all_in_one.assets/0)

但是实际在使用MySQL的过程中，大家总会遇到这样那样的一些问题，比如死锁异常、SQL性能太差、异常报错，等等。

很多Java工程师在遇到MySQL数据库的一些问题时，一般都会上网搜索博客，然后自己尝试捣鼓着解决一下，最后解决了问题，自己可能也没搞明白里面的原理。

因此我们就是要带着大家去探索MySQL底层原理的方方面面，以及探索在解决MySQL各种生产实战问题的时候，如何基于MySQL底层原理去进行分析、排查和定位。

**2、MySQL驱动到底是什么东西？**

大家都知道，我们如果要在Java系统中去访问一个MySQL数据库，必须得在系统的依赖中加入一个MySQL驱动，有了这个MySQL驱动才能跟MySQL数据库建立连接，然后执行各种各样的SQL语句。

那么这个MySQL驱动到底是个什么东西？

我们先来看下面的一段maven配置，这段maven配置中就引入了一个MySQL驱动。这里的mysql-connector-java就是面向Java语言的MySQL驱动。

![image.png](all_in_one.assets/2333600_1578799525.png)

大家都知道，如果我们要访问数据库，必须得跟数据库建立一个网络连接，那么这个连接由谁来建立呢？

其实答案就是这个MySQL驱动，他会在底层跟数据库建立网络连接，有网络连接，接着才能去发送请求给数据库服务器！我们看下图。

![img](all_in_one.assets/0-16555970336234)

然后当我们跟数据库之间有了网络连接之后，我们的Java代码才能基于这个连接去执行各种各样的增删改查SQL语句

我们看下图

![img](all_in_one.assets/0-16555970336235)

所以对于Java语言开发的系统，MySQL会提供Java版本的MySQL驱动，对于PHP、Perl、.NET、Python、Ruby等各种常见的编程语言，MySQL都会提供对应语言的MySQL驱动，让各种语言编写的系统通过MySQL驱动去访问数据库。

**3、数据库连接池到底是用来干什么的？**

接着我们来思考一个问题，一个Java系统难道只会跟数据库建立一个连接吗？

这个肯定是不行的，因为我们要明白一个道理，假设我们用Java开发了一个Web系统，是部署在Tomcat中的，那么Tomcat本身肯定是有多个线程来并发的处理同时接收到的多个请求的，我们看下图。

![img](all_in_one.assets/0-16555970336236)

这个时候，如果Tomcat中的多个线程并发处理多个请求的时候，都要去抢夺一个连接去访问数据库的话，那效率肯定是很低下的

我们看下面的图

![img](all_in_one.assets/0-16555970336237)
那么如果Tomcat中的每个线程在每次访问数据库的时候，都基于MySQL驱动去创建一个数据库连接，然后执行SQL语句，然后执行完之后再销毁这个数据库连接，这样行不行呢？

可能Tomcat中上百个线程会并发的频繁创建数据库连接，执行SQL语句，然后频繁的销毁数据库连接。

上述这个过程反复循环执行，大家觉得可行吗？

这也是非常不好的，因为每次建立一个数据库连接都很耗时，好不容易建立好了连接，执行完了SQL语句，你还把数据库连接给销毁了，下一次再重新建立数据库连接，那肯定是效率很低下的！如下图。

![img](all_in_one.assets/0-16555970336238)
所以一般我们必须要使用一个数据库连接池，也就是说在一个池子里维持多个数据库连接，让多个线程使用里面的不同的数据库连接去执行SQL语句，然后执行完SQL语句之后，不要销毁这个数据库连接，而是把连接放回池子里，后续还可以继续使用。

基于这样的一个数据库连接池的机制，就可以解决多个线程并发的使用多个数据库连接去执行SQL语句的问题，而且还避免了数据库连接使用完之后就销毁的问题，我们看下图的说明。

![img](all_in_one.assets/0-16555970336249)

**常见的数据库连接池有DBCP，C3P0，Druid，等等，大家如果有兴趣的话，可以去搜索一下数据库连接池的使用例子和代码，甚至探索一下数据库连接池的底层原理，但这个不是我们专栏的重点，我们就不会拓展了。**

毕竟我们专栏主要还是会专注讲解MySQL数据库本身的内容，只不过在开头的时候，需要大家对Java系统与数据库的交互方式有一个了解。

其实不光是Java系统，如果你是一个Python、Ruby、.NET、PHP的程序员，这个系统与数据库的交互本质都是一样的，都是基于数据库连接池去与数据库进行交互。

**4、MySQL数据库的连接池是用来干什么的？**

现在我们已经知道，我们任何一个系统都会有一个数据库连接池去访问数据库，也就是说这个系统会有多个数据库连接，供多线程并发的使用。同时我们可能会有多个系统同时去访问一个数据库，这都是有可能的。

所以当我们把目光转移到MySQL的时候，我们要来思考一个问题，那就是肯定会有很多系统要与MySQL数据库建立很多个连接，那么MySQL也必然要维护与系统之间的多个连接，所以**MySQL架构体系中的第一个环节，就是连接池**。

我们看下面的图，实际上MySQL中的**连接池**就是维护了与系统之间的多个数据库连接。除此之外，你的系统每次跟MySQL建立连接的时候，还会根据你传递过来的账号和密码，进行账号密码的验证，库表权限的验证。

![img](all_in_one.assets/0-165559703362410)

**5、小作业：自己试一试写代码建立MySQL连接**

当我们看完今天的内容后，大家可以用自己工作中经常使用的编程语言，来写一下跟MySQL建立连接的代码，想必写完之后，再对照今天的内容，感受会更深一些。

另外，大家可以基于数据库连接池框架，去写一下对应的代码例子，感受一下你建立多个数据库连接让多个线程并发访问数据库的效果。



## 02 为了执行SQL语句，你知道MySQL用了什么样的架构设计吗？

**1、把MySQL当个黑盒子一样执行SQL语句**

上一讲我们已经说到，我们的系统采用数据库连接池的方式去并发访问数据库，然后数据库自己其实也会维护一个连接池，其中管理了各种系统跟这台数据库服务器建立的所有连接

我们先看下图回顾一下

```

```

![img](all_in_one.assets/0-165559718549229)

当我们的系统只要能从数据库连接池获取到一个数据库连接之后，我们就可以执行增删改查的SQL语句了

从上图其实我们就可以看到，我们可以通过数据库连接把要执行的SQL语句发送给MySQL数据库。

然后呢？大部分同学了解到这个程度就停下来了，然后大家觉得要关注的可能主要就是数据库里的表结构，建了哪些索引，然后就按照SQL语法去编写增删改查SQL语句，把MySQL当个黑盒子去执行SQL语句就可以了。

我们只知道执行了insert语句之后，在表里会多出来一条数据；执行了update语句之后，会对表里的数据进行更改；执行了delete语句之后，会把表里的一条数据删除掉；执行了select语句之后，会从表里查询一些数据出来。

如果语句性能有点差？没关系，在表里建几个索引就可以了！可能这就是目前行业内很多工程师对数据库的一个认知，完全当他是个黑盒子，来建表以及执行SQL语句。

但是大家既然跟着我开始学习了，从现在开始就要打破这种把数据库当黑盒子的认知程度，要<u>深入底层</u>，去探索**数据库的工作原理**以及**生产问题的优化手段**！

**2、一个不变的原则：网络连接必须让线程来处理**

现在假设我们的数据库服务器的连接池中的某个连接接收到了网络请求，假设就是一条SQL语句，那么大家先思考一个问题，谁负责从这个连接中去监听网络请求？谁负责从网络连接里把请求数据读取出来？

我想很多人恐怕都没思考过这个问题，但是如果大家对计算机基础知识有一个简单了解的话，应该或多或少知道一点，那就是网络连接必须得分配给一个线程去进行处理，由一个线程来监听请求以及读取请求数据，比如从网络连接中读取和解析出来一条我们的系统发送过去的SQL语句，如下图所示：

```

```

![img](all_in_one.assets/0-165559718549330)

**Figure 16.3 MySQL Architecture with Pluggable Storage Engines**

![MySQL architecture diagram showing connectors, interfaces, pluggable storage engines, the file system with files and logs.](all_in_one.assets/mysql-architecture.png)



Figure 8-1. Execution path of a query
![img](all_in_one.assets/000008-1655614529761108.png)



**3、SQL接口：负责处理接收到的SQL语句**

接着我们来思考一下，当MySQL内部的工作线程从一个网络连接中读取出来一个SQL语句之后，此时会如何来执行这个SQL语句呢？

其实SQL是一项伟大的发明，他发明了简单易用的数据读写的语法和模型，哪怕是个产品经理，或者是运营专员，甚至是销售专员，即使他不会技术，他也能轻松学会使用SQL语句。

但如果你要去执行这个SQL语句，去完成底层数据的增删改查，那这就是一项极度复杂的任务了！

所以MySQL内部首先提供了一个组件，就是**SQL接口（SQL Interface）**，他是一套执行SQL语句的接口，专门用于执行我们发送给MySQL的那些增删改查的SQL语句

因此MySQL的工作线程接收到SQL语句之后，就会转交给SQL接口去执行，如下图。

![img](all_in_one.assets/0-165559718549331)

**4、查询解析器：让MySQL能看懂SQL语句**

接着下一个问题来了，SQL接口怎么执行SQL语句呢？你直接把SQL语句交给MySQL，他能看懂和理解这些SQL语句吗？

比如我们来举一个例子，现在我们有这么一个SQL语句：

select id,name,age from users where id=1

这个SQL语句，我们用人脑是直接就可以处理一下，只要懂SQL语法的人，立马大家就知道他是什么意思，但是MySQL自己本身也是一个系统，是一个数据库管理系统，他没法直接理解这些SQL语句！

所以此时有一个关键的组件要出场了，那就是**查询解析器**

这个**查询解析器（Parser）**就是负责对SQL语句进行解析的，比如对上面那个SQL语句进行一下拆解，拆解成以下几个部分：

1. 我们现在要从“users”表里查询数据
2. 查询“id”字段的值等于1的那行数据
3. 对查出来的那行数据要提取里面的“id,name,age”三个字段。

所谓的SQL解析，就是按照既定的SQL语法，对我们按照SQL语法规则编写的SQL语句进行解析，然后理解这个SQL语句要干什么事情，如下图所示：

```

```

![img](all_in_one.assets/0-165559718549432)

**5、查询优化器：选择<u>最优的查询路径</u>**

当我们通过解析器理解了SQL语句要干什么之后，接着会找**查询优化器（Optimizer）**来选择一个<u>最优的查询路径</u>。

可能有同学这里就不太理解什么是<u>最优的查询路径</u>了，这个看起来确实很抽象，当然，这个查询优化器的工作原理，后续将会是我们分析的重点，大家现在不用去纠结他的原理。

但是我们可以用一个极为通俗简单的例子，让大家理解一下所谓的最优查询路径是什么。

就用我们刚才讲的那个例子好了，我们现在理解了一个SQL想要干这么一个事儿：我们现在要从“users”表里查询数据，查询“id”字段的值等于1的那行数据，对查出来的那行数据要提取里面的“id,name,age”三个字段。

事是明白了，但是到底应该怎么来实现呢？

你看，要完成这个事儿我们有以下几个查询路径（**纯属用于大家理解的例子，不代表真实的MySQL原理，但是通过这个例子，大家肯定能理解所谓最优查询路径的意思**）：

1. 直接定位到“users”表中的“id”字段等于1的一行数据，然后查出来那行数据的“id,name,age”三个字段的值就可以了
2. 先把“users”表中的每一行数据的“id,name,age”三个字段的值都查出来，然后从这批数据里过滤出来“id”字段等于1的那行数据的“id,name,age”三个字段

上面这就是一个最简单的SQL语句的两种实现路径，其实我们会发现，要完成这个SQL语句的目标，两个路径都可以做到，但是哪一种更好呢？显然感觉上是第一种查询路径更好一些。

所以查询优化器大概就是干这个的，他会针对你编写的几十行、几百行甚至上千行的复杂SQL语句生成查询路径树，然后从里面选择一条最优的查询路径出来。

相当于他会告诉你，你应该按照一个什么样的步骤和顺序，去执行哪些操作，然后一步一步的把SQL语句就给完成了。

我们来一起看看下面的图：      ![img](all_in_one.assets/0-165559718549433)

**6、调用存储引擎接口，真正执行SQL语句**

最后一步，就是把查询优化器选择的最优查询路径，也就是你到底应该按照一个什么样的顺序和步骤去执行这个SQL语句的计划，把这个计划交给底层的存储引擎去真正的执行。这个存储引擎是MySQL的架构设计中很有特色的一个环节。

不知道大家是否思考过，真正在执行SQL语句的时候，要不然是更新数据，要不然是查询数据，那么数据你觉得存放在哪里？

说白了，数据库也不是什么神秘莫测的东西，你可以把他理解为本身就是一个类似你平时写的图书馆管理系统、电信计费系统、电商订单系统之类的系统罢了。

数据库自己就是一个编程语言写出来的系统而已，然后启动之后也是一个进程，执行他里面的各种代码，也就是我们上面所说的那些东西。所以对数据库而言，我们的数据要不然是放在**内存**里，要不然是放在**磁盘文件**里，没什么特殊的地方！

所以我们来思考一下，假设我们的数据有的存放在**内存**里，有的存放在**磁盘文件**里，如下图所示。

```

```

![img](all_in_one.assets/0-165559718549434)

那么现在问题来了，我们已经知道一个SQL语句要如何执行了，但是我们现在怎么知道哪些数据在内存里？哪些数据在磁盘里？我们执行的时候是更新内存的数据？还是更新磁盘的数据？我们如果更新磁盘的数据，是先查询哪个磁盘文件，再更新哪个磁盘文件？

是不是感觉一头雾水

所以这个时候就需要**存储引擎**了，存储引擎其实就是执行SQL语句的，他会按照一定的步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据，等等，执行诸如此类的一系列的操作，如下图所示。

```

```

![img](all_in_one.assets/0-165559718549435)

MySQL的架构设计中，SQL接口、SQL解析器、查询优化器其实都是通用的，他就是一套组件而已。

但是存储引擎的话，他是支持各种各样的存储引擎的，比如我们常见的InnoDB、MyISAM、Memory等等，我们是可以选择使用哪种存储引擎来负责具体的SQL语句执行的。

当然现在MySQL一般都是使用InnoDB存储引擎的，至于存储引擎的原理，后续我们也会深入一步一步分析，大家不必着急。

**7、执行器：根据执行计划调用存储引擎的接口**

那么看完存储引擎之后，我们回过头来思考一个问题，存储引擎可以帮助我们去访问内存以及磁盘上的数据，那么是谁来调用存储引擎的接口呢？

其实我们现在还漏了一个执行器的概念，这个执行器会根据优化器选择的执行方案，去调用存储引擎的接口按照一定的顺序和步骤，就把SQL语句的逻辑给执行了。

举个例子，比如执行器可能会先调用存储引擎的一个接口，去获取“users”表中的第一行数据，然后判断一下这个数据的“id”字段的值是否等于我们期望的一个值，如果不是的话，那就继续调用存储引擎的接口，去获取“users”表的下一行数据。

就是基于上述的思路，**<u>执行器</u>就会去根据我们的优化器生成的一套执行计划，然后不停的调用存储引擎的各种接口去完成SQL语句的执行计划**，大致就是不停的更新或者提取一些数据出来

我们看下图的示意

```

```

![img](all_in_one.assets/0-165559718549436)

**8、小思考题：打开脑洞，你觉得不同的存储引擎是用来干什么的？**

今天给大家留一个小的思考题，就是你先别管MySQL有哪些存储引擎，你就从业务场景来出发考虑，有的场景可能是高并发的更新，有的场景可能是大规模数据查询，有的场景可能是允许丢失数据的

那么你觉得如果让你来设计存储引擎，你觉得应该有哪些存储引擎，分别适用于什么场景？



## 03 用一次数据更新流程，初步了解InnoDB存储引擎的架构设计

**1、更新语句在MySQL中是如何执行的？**

之前我们已经分析了MySQL架构上的整体设计原理，现在对一条SQL语句从我们的系统层面发送到MySQL中，然后一步一步执行这条SQL的流程，都有了一个整体的了解。

我们已经知道了，MySQL最常用的就是InnoDB存储引擎，那么我们今天借助一条更新语句的执行，来初步的了解一下InnoDB存储引擎的架构设计。

首先假设我们有一条SQL语句是这样的：

update users set name='xxx' where id=10

那么我们先想一下这条SQL语句是如何执行的？

首先肯定是我们的系统通过一个数据库连接发送到了MySQL上，然后肯定会经过SQL接口、解析器、优化器、执行器几个环节，解析SQL语句，生成执行计划，接着去由执行器负责这个计划的执行，调用InnoDB存储引擎的接口去执行。

所以先看下图，大致还是会走下图的这个流程

![img](all_in_one.assets/0-165559727364253)

今天我们就来探索一下这个<u>**存储引擎**里的架构设计</u>，以及如何基于存储引擎完成一条更新语句的执行

**2、InnoDB的重要内存结构：缓冲池**

**Figure 15.1 InnoDB Architecture**

![InnoDB architecture diagram showing in-memory and on-disk structures. In-memory structures include the buffer pool, adaptive hash index, change buffer, and log buffer. On-disk structures include tablespaces, redo logs, and doublewrite buffer files.](all_in_one.assets/innodb-architecture.png)

InnoDB存储引擎中有一个非常重要的放在内存里的组件，就是**缓冲池（Buffer Pool）**，这里面会缓存很多的数据，以便于以后在查询的时候，万一你要是内存缓冲池里有数据，就可以不用去查磁盘了，我们看下图。

![img](all_in_one.assets/0-165559727364354)   

所以当我们的InnoDB存储引擎要执行更新语句的时候 ，比如对“id=10”这一行数据，他其实会先将“id=10”这一行数据看看是否在缓冲池里，如果不在的话，那么会直接从磁盘里加载到缓冲池里来，而且接着还会对这行记录加独占锁。

因为我们想一下，在我们更新“id=10”这一行数据的时候，肯定是不允许别人同时更新的，所以必须要对这行记录加独占锁

至于锁的详细分析，我们后续也会有，大家不用着急，在这里先初步了解即可，我们看下面的图

![img](all_in_one.assets/0-165559727364355)

**3、undo日志文件：如何让你更新的数据可以回滚？**

接着下一步，假设“id=10”这行数据的name原来是“zhangsan”，现在我们要更新为“xxx”，那么此时我们得先把要更新的原来的值“zhangsan”和“id=10”这些信息，写入到undo日志文件中去。

其实稍微对数据库 有一点了解的同学都应该知道，如果我们执行一个更新语句，要是他是在一个事务里的话，那么事务提交之前我们都是可以对数据进行回滚的，也就是把你更新为“xxx”的值回滚到之前的“zhangsan”去。

所以为了考虑到未来可能要回滚数据的需要，这里会把你更新前的值写入undo日志文件，我们看下图。

![img](all_in_one.assets/0-165559727364456)

**4、更新buffer pool中的缓存数据**

当我们把要更新的那行记录从磁盘文件加载到缓冲池，同时对他加锁之后，而且还把更新前的旧值写入undo日志文件之后，我们就可以正式开始更新这行记录了，更新的时候，先是会**更新<u>缓冲池</u>中的记录**，此时这个数据就是脏数据了。

这里所谓的更新内存缓冲池里的数据，意思就是把**内存里的**“id=10”这行数据的name字段修改为“xxx”

那么为什么说此时这行数据就是脏数据了呢？

因为这个时候磁盘上“id=10”这行数据的name字段还是“zhangsan”，但是内存里这行数据已经被修改了，所以就会叫他是脏数据。

我们看下图，我同时把几个步骤的序号标记出来了。

![img](all_in_one.assets/0-165559727364457)

**5、Redo Log Buffer：万一系统宕机，如何避免数据丢失？**

接着我们来思考一个问题，按照上图的说明，现在已经把内存里的数据进行了修改，但是磁盘上的数据还没修改。

那么此时万一MySQL所在的机器宕机了，必然会导致内存里修改过的数据丢失，这可怎么办呢？

这个时候，就必须要把对内存所做的修改写入到一个**Redo Log Buffer**里去，这也是内存里的一个缓冲区，是用来存放redo日志的。

所谓的redo日志，就是记录下来你对数据做了什么修改，比如对“id=10这行记录修改了name字段的值为xxx”，这就是一个日志。

我们先看下图的示意

```

```

![img](all_in_one.assets/0-165559727364458)

这个redo日志其实是用来在MySQL突然宕机的时候，用来恢复你更新过的数据的，但是我们现在还没法直接讲解redo是如何使用的，毕竟现在redo日志还仅仅停留在内存缓冲里。

大家稍安勿躁，继续往下看

**6、如果还没提交事务，MySQL宕机了怎么办？**

这里我们假设每个人看专栏的人，都对MySQL的基本SQL语法、事务的基本概念以及索引的基本概念有一个基础的了解，因为但凡一个后端工程师，要跟数据库打交道，必然会跟这些概念有一定的了解。

所以我们都知道，其实在数据库中，哪怕执行一条SQL语句，其实也可以是一个独立的事务，只有当你提交事务之后，SQL语句才算执行结束。

所以这里我们都知道，到目前为止，其实还没有提交事务，那么此时如果MySQL崩溃，必然导致内存里Buffer Pool中的修改过的数据都丢失，同时你写入Redo Log Buffer中的redo日志也会丢失。

我们看下图

![img](all_in_one.assets/0-165559727364459)

那么此时数据丢失要紧吗？

其实是不要紧的，因为你一条更新语句，没提交事务，就代表他没执行成功，此时MySQL宕机虽然导致内存里的数据都丢失了，但是你会发现，磁盘上的数据依然还停留在原样子。

也就是说，“id=1”的那行数据的name字段的值还是老的值，“zhangsan”，所以此时你的这个事务就是执行失败了，没能成功完成更新，你会收到一个数据库的异常。然后当mysql重启之后，你会发现你的数据并没有任何变化。

所以此时如果mysql宕机，不会有任何的问题。

**7、<u>提交事务的时候</u>将redo日志写入磁盘中**

接着我们想要提交一个事务了，此时就会根据一定的策略把redo日志从redo log buffer里刷入到磁盘文件里去。

此时这个策略是通过innodb_flush_log_at_trx_commit来配置的，他有几个选项。

当这个参数的值为0的时候，那么你提<u>交事务的时候</u>，不会把redo log buffer里的数据刷入磁盘文件的，此时可能你都提交事务了，结果mysql宕机了，然后此时内存里的数据全部丢失。

相当于你提交事务成功了，但是由于MySQL突然宕机，导致内存中的数据和redo日志都丢失了，我们看下图：

![img](all_in_one.assets/0-165559727364460)当这个参数的值为1的时候，你<u>提交事务的时候</u>，就必须把redo log从内存刷入到磁盘文件里去，只要事务提交成功，那么redo log就必然在磁盘里了，我们看下图：

![img](all_in_one.assets/0-165559727364461)那么只要提交事务成功之后，redo日志一定在磁盘文件里，此时你肯定会有一条redo日志说了，“我此时对哪个数据做了一个什么修改，比如name字段修改为xxx了”。

然后哪怕此时buffer pool中更新过的数据还没刷新到磁盘里去，此时内存里的数据是已经更新过的“name=xxx”，然后磁盘上的数据还是没更新过的“name=zhangsan”。

我们看下图，提交事务之后，可能处于的一个状态。

![img](all_in_one.assets/0-165559727364562)

此时如果说提交事务后处于上图的状态，然后mysql系统突然崩溃了，此时会如何？会丢失数据吗？

肯定不会啊，因为虽然内存里的修改成name=xxx的数据会丢失，但是**<u>redo日志</u>**里**已经**说了，对某某数据做了修改name=xxx。

所以此时<u>mysql</u>重启之后，他可以<u>根据**redo日志**去恢复之前做过的修改</u>，我们看下图。

![img](all_in_one.assets/0-165559727364563)

最后来看看，如果innodb_flush_log_at_trx_commit参数的值是2呢？

他的意思就是，<u>提交事务的时候</u>，把<u>redo日志</u>写入磁盘文件对应的<u>os cache缓存</u>里去，而不是直接进入磁盘文件，可能1秒后才会把<u>os cache</u>里的数据写入到磁盘文件里去。

这种模式下，你提交事务之后，redo log可能仅仅停留在os cache内存缓存里，没实际进入磁盘文件，万一此时你要是机器宕机了，那么os cache里的redo log就会丢失，同样会让你感觉提交事务了，结果数据丢了，看下图。

![img](all_in_one.assets/0-165559727364564)



**// 《MySQL Administrator's Bible    2009》**

### Recovering MySQL Transactions

To be ACID-compliant, 
a database system must resolve situations where a transaction is interrupted and where data from a completed transaction has not been written to disk. Perhaps the power goes out, the hard drive crashes, or the database tries to use too much memory and crashes.

If such an interruption occurs, when <code>mysqld</code> starts again there is potentially inconsistent data.
Inconsistent data is resolved through a recovery process involving log files that are called <u>transactional log</u>s. 
There are two types of <u>transactional log</u>s — the ***redo log***s and ***undo log***s.

**Redo log**s are used to apply changes that were made in memory but not flushed to the permanent table records. 
Before a `COMMIT` statement is successful, the **redo log** is written to. 
Logging is done in this manner because it provides for faster database operation. 
This might be seen as counter-intuitive at first look. 
Instead of writing to only the data file(s), `mysqld` additionally writes the **redo log**. 
Writes to the **redo log**s are always sequential, whereas often data files are not written to sequentially. 
Sequential writes are faster than non-sequential writes. 
Therefore, 
the much faster <u>**redo log** write</u>s occur when a statement is committed, and 
the slower writes to the data files can be batched periodically. 
Thus, the database actually operates faster writing to both files rather than just one file.

The **redo log**s are stored in different places for different transactional storage engines — the storage engine defines the exact **redo log** implementation. 
When `mysql`d starts up after a crash, it checks and applies all **redo log**s. 
This <u>application</u> of the **redo log**s provides the durability part of ACID compliance in transactional storage engines within MySQL.  

**Undo log**s are used to roll back uncommitted transactions. 
When a transaction is started and commands are executed, 
the storage engine does not know if the transaction will end with a `COMMIT`, `ROLLBACK`, or with an interruption from a crash. 
Ending with a `COMMIT` means all the changes made in the course of the transaction will be preserved 
(fulfilling the consistency requirement of ACID compliance). 
This is true whether the `COMMIT` was explicitly issued to end the transaction, or an implicit `COMMIT` occurred
 — see the section ‘‘Using Transactional Statements’’ earlier in this chapter for more information on statements that perform an implicit COMMIT.

If the transaction ends with a `ROLLBACK` command, all changes made by the transaction need to be undone. 
Changes also need to be undone if the transaction gets interrupted for some reason, 
such as mysqld crashing or the client disconnecting before ending the transaction. 
The **undo log**s store the changes that need to be done. 
The **undo log**s also store the savepoints, and are used when a `ROLLBACK TO SAVEPOINT` statement is issued.

In the crash recovery process, 
after the <u>**redo log** file</u>s are applied 
`mysqld` will need to roll back the transactions that were not committed but had already made changes to the database. 
**Undo log**s are used to roll back these transactional changes.

As an example, imagine running a transaction adding 1,000,000 rows, and the operating system crashes after 800,000 inserts are performed. 
When `mysqld` restarts after the operating system is back up, 
first the **redo log**s are applied to get the database server into a consistent state — with the 800,000 inserts done. 
Then `mysqld` will perform a rollback of the 800,000 inserts using the **undo log**s.

In InnoDB, **undo log**s are stored in the data files, and **redo log**s are stored in the innodb log files. 
For Falcon the **undo** and **redo log**s are stored in the serial log file. 
The binary logs (`bin-log`) are not used in crash recovery and do not contain undo or redo information.  



**8、小思考题：三种redo日志刷盘策略到底选择哪一种？**

今天给大家留一个小的思考题，大家觉得在提交事务的时候，我们对redo日志的刷盘策略应该选择哪一种？每一种刷盘策略的优缺点分别是什么？为什么？



## 04 借着更新语句在InnoDB存储引擎中的执行流程，聊聊binlog是什么？

**1、上一讲思考题解答：redo日志刷盘策略的选择建议**

先给大家解释一下上一讲的思考题，我给大家的一个建议，其实对于redo日志的三种刷盘策略，我们通常建议是设置为1

也就是说，提交事务的时候，redo日志必须是刷入磁盘文件里的。

这样可以严格的保证提交事务之后，数据是绝对不会丢失的，因为有redo日志在磁盘文件里可以恢复你做的所有修改。

如果要是选择0的话，可能你提交事务之后，mysql宕机，那么此时redo日志没有刷盘，导致内存里的redo日志丢失，你提交的事务更新的数据就丢失了；

如果要是选择2的话，如果机器宕机，虽然之前提交事务的时候，redo日志进入os cache了，但是还没进入磁盘文件，此时机器宕机还是会导致os cache里的redo日志丢失。

所以对于数据库这样严格的系统而言，一般建议redo日志刷盘策略设置为1，保证事务提交之后，数据绝对不能丢失。

**2、MySQL binlog到底是什么东西？**

接着我们来看看MySQL binlog到底是个什么东西？

实际上我们之前说的redo log，他是一种**偏向<u>物理</u>性质的**重做日志，因为他里面记录的是类似这样的东西，“对哪个数据页中的什么记录，做了个什么修改”。

而且**redo log本身是属于InnoDB存储引擎特有的一个东西**。

而<u>binlog</u>叫做<u>归档日志</u>，他里面记录的是**偏向于<u>逻辑</u>性的**日志，类似于“对users表中的id=10的一行数据做了更新操作，更新以后的值是什么”。

**binlog**不是InnoDB存储引擎特有的日志文件，**是属于mysql server自己的日志文件**。

**3、提交事务的时候，同时会写入binlog**

所以其实我们上一讲讲到，在我们提交事务的时候，会把redo log日志写入磁盘文件中去。然后其实在<u>提交事务的时候</u>，我们同时还会把这次更新对应的binlog日志写入到磁盘文件中去，如下图所示。

![img](all_in_one.assets/0-165559809839689)

大家可以在这个图里看到一些变动，
就是我把跟InnoDB存储引擎进行交互的组件加入了之前提过的**执行器**这个组件，他会负责跟InnoDB进行交互，包括从磁盘里加载数据到Buffer Pool中进行缓存，包括写入undo日志，包括更新Buffer Pool里的数据，以及写入redo log buffer，redo log刷入磁盘，写binlog，等等。

实际上，**执行器**是非常核心的一个组件，负责跟存储引擎配合完成一个SQL语句在磁盘与内存层面的全部数据更新操作。

而且我们在上图可以看到，我把一次更新语句的执行，拆分为了两个阶段，上图中的1、2、3、4几个步骤，其实本质是你执行这个更新语句的时候干的事。

然后上图中的5和6两个步骤，是从你提交事务开始的，属于提交事务的阶段了。

**4、binlog日志的刷盘策略分析**

对于binlog日志，其实也有不同的刷盘策略，有一个<u>**sync_binlog**参数</u>可以控制binlog的刷盘策略，他的默认值是0，此时你把binlog写入磁盘的时候，其实不是直接进入磁盘文件，而是进入os cache内存缓存。

所以跟之前分析的一样，如果此时机器宕机，那么你在os cache里的binlog日志是会丢失的，我们看下图的示意

![img](all_in_one.assets/0-165559809839690)

如果要是把**sync_binlog**参数设置为1的话，那么此时会强制在提交事务的时候，把binlog直接写入到磁盘文件里去，那么这样提交事务之后，哪怕机器宕机，磁盘上的binlog是不会丢失的，如下图所示

![img](all_in_one.assets/0-165559809839691)

**5、基于binlog和redo log完成事务的提交**

当我们把binlog写入磁盘文件之后，接着就会完成<u>最终的事务提交</u>，此时会**把本次更新对应的binlog文件名称和这次更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标记**。

在完成这个事情之后，才算最终完成了事务的提交，我们看下图的示意。

![img](all_in_one.assets/0-165559809839692)

**6、最后一步在redo日志中写入commit标记的意义是什么？**

这时候肯定有同学会问了，**最后在redo日志中写入commit标记**有什么**意义**呢？

说白了，他其实是**用来保持redo log日志与binlog日志一致**的。

我们来举个例子，假设我们在提交事务的时候，一共有上图中的5、6、7三个步骤，必须是三个步骤都执行完毕，才算是提交了事务。那么在我们刚完成步骤5的时候，也就是redo log刚刷入磁盘文件的时候，mysql宕机了，此时怎么办？

这个时候因为没有最终的事务commit标记在redo日志里，所以此次事务可以判定为不成功。不会说redo日志文件里有这次更新的日志，但是binlog日志文件里没有这次更新的日志，不会出现数据不一致的问题。

如果要是完成步骤6的时候，也就是binlog写入磁盘了，此时mysql宕机了，怎么办？

同理，因为没有redo log中的最终commit标记，因此此时事务提交也是失败的。

**必须是在redo log中写入最终的<u>事务commit标记</u>了，然后此时事务提交成功，**
而且redo log里有本次更新对应的日志，binlog里也有本次更新对应的日志 ，redo log和binlog完全是一致的。

**7、<u>后台IO线程</u>随机将内存更新后的脏数据刷回磁盘**

现在我们假设已经提交事务了，此时一次更新“update users set name='xxx' where id=10”，他已经把内存里的buffer pool中的缓存数据更新了，同时磁盘里有redo日志和binlog日志，都记录了把我们指定的“id=10”这行数据修改了“name='xxx'”。

此时我们会思考一个问题了，但是这个时候磁盘上的数据文件里的“id=10”这行数据的name字段还是等于zhangsan这个旧的值啊！

所以MySQL有一个<u>后台的IO线程</u>，会在之后某个时间里，随机的把内存buffer pool中的修改后的脏数据给刷回到磁盘上的数据文件里去，我们看下图：

![img](all_in_one.assets/0-165559809839693)

当上图中的<u>IO线程</u>把buffer pool里的修改后的脏数据刷回磁盘的之后，磁盘上的数据才会跟内存里一样，都是name=xxx这个修改以后的值了！

在你IO线程把脏数据刷回磁盘之前，哪怕mysql宕机崩溃也没关系，因为重启之后，会根据<u>redo日志</u>恢复之前提交事务做过的修改到内存里去，就是id=10的数据的name修改为了xxx，然后等适当时机，IO线程自然还是会把这个修改后的数据刷到磁盘上的数据文件里去的

**8、基于更新数据的流程，总结一下InnoDB存储引擎的架构原理**

大家通过一次更新数据的流程，就可以清晰地看到，
InnoDB存储引擎主要就是包含了一些buffer pool、redo log buffer等内存里的缓存数据，同时还包含了一些undo日志文件，redo日志文件等东西，
同时mysql server自己还有binlog日志文件。

在你执行更新的时候，每条SQL语句，都会对应修改buffer pool里的缓存数据、写undo日志、写redo log buffer几个步骤；

但是当你提交事务的时候，一定会把redo log刷入磁盘，binlog刷入磁盘，完成redo log中的事务commit标记；
最后后台的IO线程会随机的把buffer pool里的脏数据刷入磁盘里去。

**9、思考题：执行更新操作的时候，为什么不能执行修改磁盘上的数据？**

好了，今天的文章接近尾声，咱们再来思考一个问题：

- 为什么MySQL在更新数据的时候，要大费周章的搞这么多事情，包括buffer pool、redo log、undo log、binlog、事务提交、脏数据。引入了一大堆的概念，有复杂的流程和步骤。
- 为什么他反而最关键的修改磁盘里的数据，要通过IO线程不定时的去执行？
- 为什么他不干脆直接就每次执行SQL语句，直接就更新磁盘里的数据得了？



## 05 生产经验：真实生产环境下的数据库机器配置如何规划？（待?查证?）

**1、当你了解数据库的架构原理之后，就该了解一下自己数据库的规划**

之前我们用了4篇文章给大家整体分析了一下**MySQL数据库的工作原理**，相信很多朋友都已经对数据库的**整体架构原理**有了一定的了解，毕竟在这之前，可能大部分人对MySQL数据库的了解还停留在执行SQL语句的程度。

当我们初步了解了数据库的架构设计原理后，接着其实应该了解的第一件事，就是我们平时在工作中，如何规划生产环境下的数据库。
因为我想很多人如果平时主要是负责一些没什么并发量，用户量也就几十个或者几百个人的系统，那么根本就不会去关注数据库的规划这件事情。

对很多Java工程师而言，要不然是自己找一台linux机器装一个MySQL，然后就让自己的系统连接上去直接就开始使用了，要不然就是让DBA或者运维工程师帮自己去找一台机器装一个MySQL或者Oracle，然后自己就可以直接使用了。

但是在我们的专栏中，我们希望能够教会大家较为专业化的数据库使用经验，包括数据库的整体架构原理，还有就是如何规划生产环境下的数据库，包括当你有一个生产库之后，要做的事情就是设计**压测方案**，包括对你的数据库进行**压测**，包括对你的数据**库部署可视化监控系统**，等等。

当你做好这一系列的事情之后，接着才应该是开发你的Java系统，去操作你的数据库，实现各种各样的业务功能和逻辑。



**2、生产数据库一般用什么配置的机器？**

现在我们来看第一个问题，假设你在生产环境中需要部署一个数据库，此时首先你就需要一个机器来部署这个数据库。
那么我们要考虑的事情就是，部署一个生产环境的数据库，一般需要什么样配置的机器呢？

接下来我们将会给大家说一些我们的<u>经验值</u>，直接告诉大家**什么样配置的机器**部署的MySQL数据库，大致适合**多高的并发访问量**。

当你了解这个经验值之后，未来当你在负责系统的开发，申请数据库的时候，你就知道生产环境下的数据库大致需要什么样的机器配置了，大致可以抗下多少并发访问了。

首先我们先明确一点，如果你负责的系统就是一个没什么并发访问量，用户就几十个人或者几百个人的系统，那么其实你选择什么样的机器去部署数据库，影响都不是很大，哪怕是你用我们自己平时用的个人笔记本电脑去部署一个MySQL数据库，其实也能支撑那种低并发系统的运行。

因为那种系统可能每隔几分钟才会有一波请求发到数据库上去，而且数据库里一张表也许就几百条、几千条或者几万条数据，数据量很小，并发量很小，操作频率很低，用户量很小，并发量很小，只不过可能系统的业务逻辑很复杂而已。对于这类系统的数据库机器选型，就不在我们的考虑范围之内了。

我们主要关注的是有一定并发量的互联网类的系统，对数据库可能会产生<u>每秒几百，每秒几千，甚至每秒上万的并发请求量</u>，对于这类场景下，我们应该选择什么样的机器去部署数据库，才能比较好的抗下我们的<u>系统压力</u>。



**3、普通的<u>Java应用系统</u>部署在机器上能抗多少并发？**

通常来说，根据我们的**经验值**而言，
<u>Java应用系统部署</u>的时候常选用的机器配置大致是**2核4G**和**4核8G**的较多一些，
<u>数据库部署</u>的时候常选用的机器配置最低在**8核16G**以上，正常在**16核32G**。

那么以我们大量的高并发线上系统的**生产经验**观察下来而言，一般<u>Java应用系统</u>部署在**4核8G**的机器上，<u>每秒钟抗下500左右的并发访问量</u>，差不多是比较合适的，当然这个也不一定。
因为你得考虑一下，假设你每个请求花费1s可以处理完，那么你一台机器每秒也许只可以处理100个请求，但是如果你每个请求只要花费100ms就可以处理完，那么你一台机器每秒也许就可以处理几百个请求。

所以**一台机器能抗下每秒多少请求，往往是跟你<u>每个请求处理耗费多长时间</u>是关联的**，但是大体上来说，根据我们大量的经验观察而言，**4核8G**的机器部署<u>普通的Java应用系统</u>，每秒大致就是抗下**几百的并发访问**，从每秒一两百请求到每秒七八百请求，都是有可能的，**关键是看你每个请求处理需要耗费多长时间**。



**4、高并发场景下，数据库应该用什么样的机器？**

对于数据库而言，我们刚才也说过了，通常推荐的数据库至少是选用**8核16G**以的机器，甚至是**16核32G**的机器更加合适一些。

因为大家要考虑一个问题，对于我们的<u>Java应用系统</u>，主要耗费时间的是Java系统和数据库之间的网络通信。
对Java系统自己而言，如果你仅仅只是系统内部运行一些普通的业务逻辑，纯粹在自己内存中完成一些业务逻辑，这个性能是极高极高的。

对于你Java系统接收到的每个请求，耗时最多的还是发送网络请求到数据库上去，等待数据库执行一些SQL语句，返回结果给你。

所以其实我们常说你有一个Java系统压力很大，负载很高，但是其实你要明白一点，你这个Java系统其实主要的压力和复杂都是集中在你依赖的那个MySQL数据库上的！

因为你执行大量的增删改查的SQL语句的时候，MySQL数据库需要对内存和磁盘文件进行大量的IO操作，所以**数据库往往是负载最高的**！
这个问题我们在之前4篇文章里，通过MySQL数据库架构原理的分析，都已经讲解过了。

而你的Java系统一般并不需要你去直接大量的读写本地文件进行耗时的IO操作吧？是不是，想必做过Java开发的朋友一下子就会想明白这个道理。

所以往往对一个数据库而言，都是选用8核16G的机器作为起步，最好是选用16核32G的机器更加合适一些，因为数据库需要执行大量的磁盘IO操作，他的**每个请求都比较耗时一些**，所以机器的配置自然需要高一些了。

然后通过我们之前的经验而言，一般**8核16G**的机器部署的<u>MySQL数据库</u>，**每秒抗个一两千并发请求**是没问题的，
但是如果你的并发量再高一些，假设每秒有几千并发请求，那么可能数据库就会有点危险了，因为数据库的CPU、磁盘、IO、内存的负载都会很高，弄不数据库压力过大就会宕机。

对于**16核32G**的机器部署的MySQL数据库而言，**每秒抗个两三千，甚至三四千的并发请求**也都是可以的，但是如果你达到每秒上万请求，那么数据库的CPU、磁盘、IO、内存的负载瞬间都会飙升到很高，数据库也是可能会扛不住宕机的。

所以这就是对于数据库，我们一般推荐选用的机器的配置，以及他大致可以抗下多高的并发请求量的经验分享。

另外对于数据库而言，如果可以的话，最好是采用SSD固态硬盘而不是普通的机械硬盘，因为数据库最大的复杂就在于大量的磁盘IO，他需要大量的读写磁盘文件，所以如果能使用SSD固态硬盘，那么你的数据库每秒能抗的并发请求量就会更高一些。



**5、今日思考题**

今天想留给大家一个小的思考题：假设你开发的Java系统部署在一台4核8G的机器上，那么我们假设这个Java系统处理一个请求非常非常快，每个请求只需要0.01ms就可以处理完了，那你觉得这一台机器部署的Java系统，可以实现每秒抗下几千并发请求吗？可以实现每秒抗下几万并发请求吗？



## 06 生产经验：互联网公司的生产环境数据库是如何进行性能测试的？

**1、申请了机器之后，你作为Java架构师就要心里有数**

上一篇文章我们讲到了在真实的项目中，第一件事情就是**申请数据库机器**，一般来说我们需要申请**8核16G**或者**16核32G**的高配置机器下来，甚至要机器全部搭配<u>SSD固态硬盘</u>，然后让DBA兄弟在申请下来的机器上安装和部署一个MySQL，同时启动MySQL数据库。

当然如何安装和部署MySQL，以及如何启动MySQL，都是非常简单的，大家网络上随便一搜索就会看到大量类似的东西，那不是我们专栏要讲的东西。然后MySQL在生产环境下的各种纷繁复杂的高级参数的调整，暂时我们还不会立马涉及到，那些是属于MySQL DBA需要搞定的事情。

但是我们后续随着专栏的推进，会讲解一部分MySQL生产环境中的高阶参数的调优和配置，有一些是跟我们开发Java应用系统密切相关的东西，我们作为开发人员，也是需要了解MySQL一些高阶参数的调优的，有时候在我们优化系统性能的时候，可能就需要跟DBA一起配合进行调优。

但是简单来说，我们**作为一个项目的核心Java工程师甚至Java架构师，必须要选择自己的数据库使用<u>什么配置</u>的机器，心里大致明白这个配置的机器部署的数据库，大致能帮我们<u>抗下每秒多少并发请求</u>。**

比如你申请的是**8核16G**的机器来部署MySQL，那你作为项目的Java架构师，心里大致就该知道你这个数据库后续每秒抗个**一两千**请求还是可以的，如果你申请的是**16核32G**的机器，那你心里就知道妥妥可以抗个每秒**两三千，甚至三四千**的请求，你心里就有数了，这是你要做到的



**2、把机器交给专业的DBA，让他部署MySQL**

其次你要知道的是，你申请一台机器下来之后，接着这台机器**在有一定规模的公司里，一定是交给公司专业的DBA去安装、部署和启动MySQL的**，DBA这个时候会按照他过往的经验，用自己的**MySQL生产调优<u>参数模板</u>**，直接放到MySQL里去，然后用一个参数模板去启动这个MySQL，往往这里很多参数都是调优过的。

而且DBA还可能会对**linux机器的一些OS内核参数进**行一定的调整，比如说最大文件句柄之类的参数，这些参数往往也都是需要调整的。

接着当DBA搞定这台机器上的数据库之后，就会交给你来使用，你就知道这台机器的地址和用户名密码，然后你的Java系统就可以直接连接上去，就可以执行各种各样的SQL语句去实现业务逻辑了。



**3、有了数据库之后，还需要先进行压测**

当你手头有一个可以使用的数据库之后，你觉得就可以直接基于他开发Java系统了吗？

并不是这样的！这么做在一个互联网公司里往往会显得比较的业余，因为你首先得先对这个数据库进行一个较为基本的**基准压测**。

也就是说，你得**基于一些工具模拟一个系统**每秒发出1000个请求到数据库上去，**观察**一下他的CPU负载、磁盘IO负载、网络IO负载、内存负载，然后数据库能否每秒处理掉这1000个请求，还是每秒只能处理500个请求？这个过程，就是压测。

你不光用工具每秒发送1000个请求，还可以模拟每秒发送2000个请求，甚至3000个请求，**逐步的测试出来**，这个数据库在目前的机器配置之下，他大致的一个负载压力如何，性能表现如何，每秒最多可以抗多少请求。

可能有的人会提出疑问了，他会说：老师，为什么刚开始就要对数据库搞一个基准压测？你完全可以等Java系统都开发完毕了，然后直接让Java系统连接上MySQL数据库，然后直接对Java系统进行压测啊！

如果有人提出这个问题，那就有所不知了，**数据库的压测和他上面的Java系统的压测，其实是两回事儿，首先你得知道你的数据库最大能抗多大压力，然后你再去看你的Java系统能抗多大压力**。

因为有一种可能是，你的数据库每秒可以抗下2000个请求，但是你的Java系统每秒只能抗下500个请求，这也是有可能的。所以你不能光是针对Java系统去进行压测，在那之前也得先对数据库进行压测，心里得有个数。



**4、傻傻分不清楚：QPS和TPS到底有什么区别？**

既然要压测了，那么肯定得先明白一点，我们压测数据库，最终是想看看这个数据库**在现有的机器配置之下，每秒可以抗下多少个请求**呢？这个每秒抗下多少个请求，其实是有专业术语的，分别是**QPS**和**TPS**。

就QPS而言，他的英文全称是：**Query Per Second**。

其实就是英文字面意思已经很明确了，QPS就是说，你的这个数据库每秒可以处理多少个请求，你大致可以理解为，一次请求就是一条SQL语句，也就是说这个数据库每秒可以处理多少个SQL语句。

对于QPS而言，其实你的一些**Java系统**或者**中间件系统**在进行压测的时候，也可以使用这个指标，也就是说，你的Java系统每秒可以处理多少个请求。

然后另外一个术语是TPS，他的英文全称是：**Transaction Per Second**。其实就是每秒可处理的事务量，这个TPS往往是用在**数据库**中较多一些，其实从字面意思就能看的出来，他就是说数据库每秒会处理多少次事务提交或者回滚。

因为大家应该都对数据库有一个基本的了解，就是他的事务到底是什么？

简单来说，一个事务就会包含多个SQL语句，这些SQL最好要么就是事务提交，大家一起成功了，要么就是最好事务回滚，大家一起失败了，这就是事务。

所以TPS往往指的是一个数据库每秒里有多少个事务执行完毕了，事务提交或者回滚都算是事务执行完毕了，所以<u>TPS衡量的是一个数据库每秒处理完的**事务**的数量</u>。
**有一些人往往会把TPS理解为是数据库每秒钟处理请求的数量，其实这是不太严谨的。**



**5、IO相关的压测性能指标**

接着再给大家讲几个压测的时候要关注的IO相关的性能指标，大家也要对他做一个了解：

**（1）IOPS：**这个指的是机器的**随机IO并发处理的能力**，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个**随机IO读写请求**。

这个指标是很关键的，因为之前我们在数据库架构原理中讲解过，你在内存中更新的脏数据库，最后都会由后台IO线程在不确定的时间，**刷回到磁盘**里去，这就是**随机IO**的过程。如果说IOPS指标太低了，那么会导致你内存里的脏数据刷回磁盘的效率就会不高。

**（2）吞吐量：**这个指的是机器的磁盘存储每秒可以读写多少字节的数据量。

这个指标也是很关键的，因为大家通过之前的学习都知道，我们平时在执行各种SQL语句的时候，提交事务的时候，其实都是大量的会写redo log之类的日志的，这些日志都会直接写磁盘文件。

所以一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。**一般**来说我们写redo log之类的日志，都是对磁盘文件进行**顺序写入**的，也就是一行接着一行的写，不会说进行随机的读写，那么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。

所以**通常而言，机器的磁盘吞吐量都是足够承载高并发请求的**。

**（3）latency：**这个指标说的是往磁盘里写入一条数据的延迟。

这个指标同样很重要，因为我们执行SQL语句和提交事务的时候，都需要顺序写redo log磁盘文件，所以此时你写一条日志到磁盘文件里去，到底是延迟1ms，还是延迟100us，这就对你的数据库的SQL语句执行性能是有影响的。

一般来说，当然是你的磁盘读写延迟越低，那么你的数据库性能就越高，你执行每个SQL语句和事务的时候速度就会越快。



**6、压测的时候要关注的其他性能指标**

除了上面说的QPS、TPS、IOPS、吞吐量、latency这些指标之外，在压测的时候还需要关注机器的其他一些性能指标。

**（1）CPU负载：**CPU负载是一个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标都还正常，但是此时CPU负载特别高，那么也说明你的数据库不能继续往下压测更高的QPS了，否则CPU是吃不消的。

**（2）网络负载：**这个主要是要看看你的机器带宽情况下，在压测到一定的QPS和TPS的时候，每秒钟机器的网卡会输入多少MB数据，会输出多少MB数据，因为有可能你的网络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，网卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了

**（3）内存负载：**这个就是看看在压测到一定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过高了，说明也不能继续压测下去了



**7、后续的压测实战说明**

接下来下一篇文章，我就会在我自己的电脑上安装一个MySQL数据库，然后教给大家如何使用方便的压测工具，对数据库进行一定的压测，压测的同时，应该通过哪些便捷的工具，去观察压测过程中的机器表现和各项指标。



**8、今日思考题**

今天想请每个人思考一下QPS和TPS两个术语，想请大家说说自己在看今天的文章之前，自己对QPS和TPS是怎么理解的，在你们公司里是否有相关的系统和数据库的QPS/TPS的统计？
今天看完这篇文章之后，你对QPS和TPS两个术语的理解是否有所变化呢？

另外，我再给大家出另外一个思考题，假设现在你负责一个交易系统，对于这个交易系统，他拆分为了很多服务，一笔交易的完成需要多个服务协作完成，也就是说一次交易请求需要调用多个服务才能完成。

那么你觉得对于每个服务而言，他每秒处理的请求数量是QPS还是TPS呢？
对于整个交易系统而言，他每秒钟处理的交易笔数是QPS还是TPS呢？
请大家谈谈你的看法。



## 07 生产经验：如何对生产环境中的数据库进行360度无死角压测？

**1、昨日思考题解答**



先给大家分析昨天的第一个小思考题：给你一台4核8G的机器，他可以抗到每秒几千甚至每秒几万的并发请求吗？



其实这个是不一定的，因为一台机器到底每秒钟可以抗下多少并发请求，跟CPU、内存、磁盘IO、网络带宽，都是有关系的。



举个例子，之前在我们的一个项目的生产环境中，据我们观察，一台4核8G的机器如果每秒抗下500+的请求，那么他的CPU负载就已经很高了，基本上最多可能也就是去抗下每秒1000+的请求，而且那个时候CPU负载基本会打满，机器有挂掉的风险。



另外如果你的系统的业务逻辑特别的吃内存，也许你一台4核8G的机器跑到每秒几百的请求，内存使用率就很高了，而且JVM GC频率可能会非常的高，所以此时也很难继续提升并发请求了。



所以其实你一台机器是不可能无限制的让他增加可以抗下的并发请求的。



再来看下一个思考题：关于QPS和TPS的。我上次问大家了，如果一个交易系统拆分为了很多服务，那么每个服务每秒接收的并发请求是QPS还是TPS呢？



这个明显是QPS，因为每个服务就负责干自己的一些事儿，其实对他来说，每秒并发请求数量就是QPS。



那么对于多个服务组成的一个大的交易系统而言，这个交易系统每秒可以完成多少笔交易，这是QPS还是TPS呢？



其实这个你可以认为是TPS的概念，因为一笔交易需要调用多个服务来完成，所以一笔交易的完成其实就类似数据库里的一个事务，他涵盖了很多服务的请求调用，所以每秒完成多少笔交易，你可以用TPS来形容。



比如你说交易系统的TPS是300，就是说每秒可以完成300笔交易。那么比如交易系统中的服务A的QPS是500，就是交易系统中的一个服务A每秒可以处理500个请求。



**2、一款非常好用的数据库压测工具**



上一篇文章给大家讲解了我们在压测的过程中要关注哪些东西，这一篇文章就来带着大家一步一步的利用一个工具进行数据库压测。



先给大家介绍一个非常好用的数据库压测工具，就是**sysbench**，这个工具可以自动帮你在数据库里构造出来大量的数据，你想要多少数据，他就自动给你构造出来多少条数据。



然后这个工具接着可以模拟几千个线程并发的访问你的数据库，模拟使用各种各样的SQL语句来访问你的数据库，包括模拟出来各种事务提交到你的数据库里去，甚至可以模拟出几十万的TPS去压测你的数据库。



所以一般来说，如果你要进行数据库的压测，就是直接使用sysbench工具就可以了，这一篇文章我来带着大家学习一下这个压测工具的使用，大家学习完这一讲，完全可以自己本地装一个MySQL数据库，然后自己压测一下试一试。



**3、在linux上安装sysbench工具**



首先你需要有一台linux机器，如果你只有一个windows笔记本电脑，可以在里面装一个linux的虚拟机，然后你可以用如下的命令设置一下yum repo仓库，接着基于yum来安装sysbench就可以了，安装完成以后验证一下是否成功。



curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash



sudo yum -y install sysbench



sysbench --version



如果上面可以看到sysbench的版本号，就说明安装成功了。



**4、数据库压测的测试用例**



接着我们需要在自己的数据库里创建好一个测试库，我们可以取个名字叫做test_db，同时创建好对应的测试账号，可以叫做test_user，密码也是test_user，让这个用户有权限可以访问test_db。



然后我们将要基于sysbench构建20个测试表，每个表里有100万条数据，接着使用10个并发线程去对这个数据库发起访问，连续访问5分钟，也就是300秒，然后对其进行压力测试。



**5、基于sysbench构造测试表和测试数据**



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable prepare



上面我们构造了一个sysbench命令，给他加入了很多的参数，现在我们来 解释一下这些参数，相信很多参数大家自己看到也就大致明白什么意思了：



1. --db-driver=mysql：这个很简单，就是说他基于mysql的驱动去连接mysql数据库，你要是oracle，或者sqlserver，那自然就是其他的数据库的驱动了
2. --time=300：这个就是说连续访问300秒
3. --threads=10：这个就是说用10个线程模拟并发访问
4. --report-interval=1：这个就是说每隔1秒输出一下压测情况
5. --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user：这一大串，就是说连接到哪台机器的哪个端口上的MySQL库，他的用户名和密码是什么
6. --mysql-db=test_db --tables=20 --table_size=1000000：这一串的意思，就是说在test_db这个库里，构造20个测试表，每个测试表里构造100万条测试数据，测试表的名字会是类似于sbtest1，sbtest2这个样子的
7. oltp_read_write：这个就是说，执行oltp数据库的读写测试
8. --db-ps-mode=disable：这个就是禁止ps模式



最后有一个prepare，意思是参照这个命令的设置去构造出来我们需要的数据库里的数据，他会自动创建20个测试表，每个表里创建100万条测试数据，所以这个工具是非常的方便的。



**6、对数据库进行360度的全方位测试**



测试数据库的综合读写TPS，使用的是oltp_read_write模式（大家看命令中最后不是prepare，是run了，就是运行压测）：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable run



测试数据库的只读性能，使用的是oltp_read_only模式（大家看命令中的oltp_read_write已经变为oltp_read_only了）：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_only --db-ps-mode=disable run



测试数据库的删除性能，使用的是oltp_delete模式：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_delete --db-ps-mode=disable run



测试数据库的更新索引字段的性能，使用的是oltp_update_index模式：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_update_index --db-ps-mode=disable run



测试数据库的更新非索引字段的性能，使用的是oltp_update_non_index模式：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_update_non_index --db-ps-mode=disable run





测试数据库的插入性能，使用的是oltp_insert模式：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_insert --db-ps-mode=disable run



测试数据库的写入性能，使用的是oltp_write_only模式：



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_write_only --db-ps-mode=disable run



使用上面的命令，sysbench工具会根据你的指令构造出各种各样的SQL语句去更新或者查询你的20张测试表里的数据，同时监测出你的数据库的压测性能指标，最后完成压测之后，可以执行下面的cleanup命令，清理数据。



sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable cleanup



**7、压测结果分析**



按照我们上面的命令，我们是让他每隔1秒都会输出一次压测报告的，此时他每隔一秒会输出类似下面的一段东西：



[ 22s ] thds: 10 tps: 380.99 qps: 7312.66 (r/w/o: 5132.99/1155.86/1321.35) lat (ms, 95%): 21.33 err/s: 0.00 reconn/s: 0.00



我来给大家解释一下这是什么意思，首先他说的这是第22s输出的一段压测统计报告，然后是其他的一些统计字段：



1. thds: 10，这个意思就是有10个线程在压测
2. tps: 380.99，这个意思就是每秒执行了380.99个事务
3. qps: 7610.20，这个意思就是每秒可以执行7610.20个请求
4. (r/w/o: 5132.99/1155.86/1321.35)，这个意思就是说，在每秒7610.20个请求中，有5132.99个请求是读请求，1155.86个请求是写请求，1321.35个请求是其他的请求，就是对QPS进行了拆解
5. lat (ms, 95%): 21.33，这个意思就是说，95%的请求的延迟都在21.33毫秒以下
6. err/s: 0.00 reconn/s: 0.00，这两个的意思就是说，每秒有0个请求是失败的，发生了0次网络重连



这个压测结果会根据每个人的机器的性能不同有很大的差距，你要是机器性能特别高，那你可以开很多的并发线程去压测，比如100个线程，此时可能会发现数据库每秒的TPS有上千个，如果你的机器性能很低，可能压测出来你的TPS才二三十个，QPS才几百个，这都是有可能的。



另外在完成压测之后，最后会显示一个总的压测报告，我把解释写在下面了：



SQL statistics:

​	queries performed:

​		read: 1480084 // 这就是说在300s的压测期间执行了148万多次的读请求

​		write: 298457 // 这是说在压测期间执行了29万多次的写请求

​		other: 325436 // 这是说在压测期间执行了30万多次的其他请求

​		total: 2103977 // 这是说一共执行了210万多次的请求

​	// 这是说一共执行了10万多个事务，每秒执行350多个事务

​	transactions: 105180( 350.6 per sec. )

​	// 这是说一共执行了210万多次的请求，每秒执行7000+请求

​	queries: 2103977 ( 7013.26 per sec. )

​	ignored errors: 0 (0.00 per sec.)

​	reconnects: 0 (0.00 per sec.)



// 下面就是说，一共执行了300s的压测，执行了10万+的事务

General staticstics:

​	total time: 300.0052s

​	total number of events: 105180



Latency (ms):

​	min: 4.32 // 请求中延迟最小的是4.32ms

​	avg: 13.42 // 所有请求平均延迟是13.42ms

​	max: 45.56 // 延迟最大的请求是45.56ms

​	95th percentile: 21.33 // 95%的请求延迟都在21.33ms以内



**8、今日作业**



今天希望大家可以完成一个作业，自己准备一台linux机器或者虚拟机，然后装一个mysql数据库，接着使用sysbench工具尝试一下数据库的压测，自己分析一下压测的报告和结果，感受一下你的数据库到底能抗多高的并发。



同时接下来我们还会给大家讲解在压测的过程中，如何去观察机器的其他重要的性能指标，比如说CPU、网络、内存、磁盘IO，等等。



## 08 生产经验：在数据库的压测过程中，如何360度无死角观察机器性能？

**1、除了QPS和TPS以外，我们还需要观察机器的性能**



上一篇文章我们给大家讲解了如何使用sysbench这个工具非常方便的去对数据库进行压测，压测过后其实大家就会看到自己的数据库大概能抗下多少QPS和TPS了。



但是这里还得给大家说另外一个压测时的技巧，就是上一篇文章里我们是使用了10个线程去压测数据库，如果你的机器性能很高，然后你觉得10个线程没法压测出来数据库真实的最高负载能力，你其实可以在sysbench中不停的增加线程的数量，比如使用20个线程，甚至100个线程去并发的访问数据库，直到发现数据库的QPS和TPS上不去了。



当然，这个不停的提高线程数量，不停的让数据库承载更高的QPS的过程，还需要配合我们对机器性能表现的观察来做，不能盲目的不停的增加线程去压测数据库。



这篇文章，我们就是要讲解在压测过程中，如何同时观察机器的性能表现，从而来决定是否要继续增加线程数量去压测数据库。



**2、为什么在不停增加线程数量的时候，要密切关注机器性能？**



我们先来解答一个问题，就是在压测的时候我们需要不停的增加线程的数量去让数据库承载更高的QPS，一直到最后看看数据库到底最高可以承载多高的QPS。



那么在这个过程中，为什么必须要密切的关注机器的性能呢？



我们来给大家举两个例子，相信大家看完就明白这个问题了。



首先，假设数据库当前抗下了每秒2000的QPS，同时这个时候机器的CPU负载、内存负载、网络负载、磁盘IO负载，都在正常的范围内，负载相对较高一些，但是还没有达到这些硬件的极限，那么我们可以认为这台数据库在高峰期抗到每秒2000的QPS，是没有问题的。



但是如果你一直不停的在压测过程中增加sysbench的线程数量，然后数据库此时勉强抗到了每秒5000的QPS了，但是这个时候你发现机器的CPU已经满负荷运行了，内存使用率特别高，内存都快要不够了，然后网络带宽几乎被打满了，磁盘IO的等待时间特别长，这个时候说明机器已经到了极致了，再搞下去，机器都快挂了。



所以这个时候你压测出来的5000 QPS是没什么代表性的，因为在生产环境根本不可能让数据库抗下这么高的QPS，因为到这么高的QPS就说明你的数据库几乎已经快要挂掉了，这是不现实的。



所以说，在压测的过程中，必须是不停的增加sysbench的线程数量，持续的让数据库承载更高的QPS，同时密切关注机器的CPU、内存、磁盘和网络的负载情况，在硬件负载情况比较正常的范围内，哪怕负载相对较高一些，也还是可以继续增加线程数量和提高数据库的QPS的。



然后当你不停的增加线程数量，发现在数据库抗下一个QPS的数值的同时，机器的CPU、内存、网络和磁盘的负载已经比较高了，到了一个有一定风险的临界值的了，此时就不能继续增加线程数量和提高数据库抗下的QPS了。



接着我们今天就来给大家分析一下，在压测的过程中，需要使用哪些linux命令去观察机器的性能情况，以及机器的CPU、内存、磁盘和网络在什么样的负载下是正常的，在什么样的负载下就是比较危险的了。



**3、压测时如何观察机器的CPU负载情况？**



先来看一个最最常用的监测linux机器性能的命令，就是top命令，直接在linux命令行只能够输入top指令就可以了，然后我们这里来给大家解释一下，top指令展示出来的各种信息都是什么意思。



首先我们会看到如下一行信息：



top - 15:52:00 up 42:35, 1 user, load average: 0.15, 0.05, 0.01



先来解释一下这行信息，这行信息是最直观可以看到机器的cpu负载情况的，首先15:52:00指的是当前时间，up 42:35指的是机器已经运行了多长时间，1 user就是说当前机器有1个用户在使用。



最重要的是load average: 0.15, 0.05, 0.01这行信息，他说的是CPU在1分钟、5分钟、15分钟内的负载情况。



这里要给大家着重解释一下这个CPU负载是什么意思，假设我们是一个4核的CPU，此时如果你的CPU负载是0.15，这就说明，4核CPU中连一个核都没用满，4核CPU基本都很空闲，没啥人在用。



如果你的CPU负载是1，那说明4核CPU中有一个核已经被使用的比较繁忙了，另外3个核还是比较空闲一些。要是CPU负载是1.5，说明有一个核被使用繁忙，另外一个核也在使用，但是没那么繁忙，还有2个核可能还是空闲的。



如果你的CPU负载是4，那说明4核CPU都被跑满了，如果你的CPU负载是6，那说明4核CPU被繁忙的使用还不够处理当前的任务，很多进程可能一直在等待CPU去执行自己的任务。



这个就是CPU负载的概念和含义。



所以大家现在知道了，上面看到的load average实际上就是CPU在最近1分钟，5分钟，15分钟内的平均负载数值，上面都是0.15之类的，说明CPU根本就没怎么用。



但是如果你在压测的过程中，发现4核CPU的load average已经基本达到3.5，4了，那么说明几个CPU基本都跑满了，在满负荷运转，那么此时你就不要再继续提高线程的数量和增加数据库的QPS了，否则CPU负载太高是不合理的。



**4、压测时如何观察机器的内存负载情况？**



在你执行top命令之后，中间我们跳过几行内容，可以看到如下一行内容：



Mem: 33554432k total, 20971520k used, 12268339 free, 307200k buffers



这里说的就是当前机器的内存使用情况，这个其实很简单，明显可以看出来就是总内存大概有32GB，已经使用了20GB左右的内存，还有10多G的内存是空闲的，然后有大概300MB左右的内存用作OS内核的缓冲区了。



对于内存而言，同样是要在压测的过程中紧密的观察，一般来说，如果内存的使用率在80%以内，基本都还能接受，在正常范围内，但是如果你的机器的内存使用率到了70%~80%了，就说明有点危险了，此时就不要继续增加压测的线程数量和QPS了，差不多就可以了。



**5、压测时如何观察机器的磁盘IO情况？**



接着我们说说如何在压测的时候观察机器的磁盘IO的情况？



这里会使用dstat命令，我们之前给大家讲过几个磁盘IO相关的指标，包括存储的IO吞吐量、IOPS这些，我们下面就看看这里是如何查看的。



使用dstat -d命令，会看到如下的东西：



-dsk/total -

read writ

103k 211k

 	 0  11k



在上面可以清晰看到，存储的IO吞吐量是每秒钟读取103kb的数据，每秒写入211kb的数据，像这个存储IO吞吐量基本上都不算多的，因为普通的机械硬盘都可以做到每秒钟上百MB的读写数据量。



使用命令：dstat -r，可以看到如下的信息



--io/total-

read writ

0.25 31.9

​	 0  253

​	 0  39.0



他的这个意思就是读IOPS和写IOPS分别是多少，也就是说随机磁盘读取每秒钟多少次，随机磁盘写入每秒钟执行多少次，大概就是这个意思，一般来说，随机磁盘读写每秒在两三百次都是可以承受的。



所以在这里，我们就需要在压测的时候密切观察机器的磁盘IO情况，如果磁盘IO吞吐量已经太高了，都达到极限的每秒上百MB了，或者随机磁盘读写每秒都到极限的两三百次了，此时就不要继续增加线程数量了，否则磁盘IO负载就太高了。



**6、压测时观察网卡的流量情况**



接着我们可以使用dstat -n命令，可以看到如下的信息：



-net/total-

recv send

16k  17k



这个说的就是每秒钟网卡接收到流量有多少kb，每秒钟通过网卡发送出去的流量有多少kb，通常来说，如果你的机器使用的是千兆网卡，那么每秒钟网卡的总流量也就在100MB左右，甚至更低一些。



所以我们在压测的时候也得观察好网卡的流量情况，如果网卡传输流量已经到了极限值了，那么此时你再怎么提高sysbench线程数量，数据库的QPS也上不去了，因为这台机器每秒钟无法通过网卡传输更多的数据了。



**7、今天的一点总结和作业**



今天的文章我们来做一点总结，今天给大家介绍了在数据库压测的过程中，你必须不停的增加sysbench的线程数量，增加数据库抗下的QPS，同时通过各种命令观察机器的CPU、内存、磁盘和网络的负载情况，如果你发现某个硬件负载已经很高了，此时就可以不再提高数据库的QPS了。



**在硬件的一定合理的负载范围内，把数据库的QPS提高到最大，这就是数据库压测的时候最合理的一个极限QPS值**，而不是不管机器的各个硬件的负载，盲目的不停的增加sysbench的线程数量，不停的让数据库增加可以抗下的QPS的数值。



今天同样给大家布置一个小作业，大家可以自己本地笔记本电脑装一个数据库，然后基于sysbench去压测，不停的提高线程数量，不停的提高数据库抗下的QPS，同时观察你的机器的CPU、内存、磁盘和网络的各项负载



## 09 生产经验：如何为生产环境中的数据库部署监控系统？

**1、生产环境的数据库可不能裸奔啊！**



之前我们已经给大家讲解完了数据库的压测相关的知识，想必大家只要利用我们讲解的知识，在自己的公司里，哪怕DBA团队、QA团队都没法给你提供专业的数据库压测技术支持，但是大家手上拿到一个数据库之后，其实自己也可以通过各种工具和命令，非常好的完成一台机器上的数据库的压测了。



你应该可以心里非常有数，一台什么样配置的机器，部署了一个数据库之后，利用sysbench构造了多少个表和数据量，然后模拟了多少个线程压测的时候，机器的各项硬件负载在可以接受的范围内时，数据库的QPS和TPS可以压测到多高。



这个时候你大致就明白你的数据库在高峰时期最多可以让他去承受多少QPS和TPS了。



但是搞定压测之后，难道大家就想直接开始开发你的Java系统？直接让你的系统连接到MySQL上去执行各种CRUD的SQL语句？然后接着就开始拼命写各种Java代码和SQL语句，写好之后就找QA进行测试，然后部署到线上生产环境，接着就万事大吉了，不管数据库了？



这种做法可能目前很多公司和团队都是这样做的，但是如果你仅仅是这么搞是绝对不行的。因为实际上我们需要对线上系统进行完善的监控，不光是对你开发的Java系统进行监控，还得对你的数据库进行监控，包括对CPU、内存、网络、磁盘IO、慢查询、QPS、TPS的监控。



因为如果你不对你的数据库做任何监控，那么有可能你的数据库CPU负载已经很高了，或者磁盘IO已经达到极限了，你都不知道，结果你还是一如既往的运行你的Java系统，有一天可能你的数据库突然挂了你都没反应过来！



所以今天我们就带着大家来一步步搭建一下生产环境数据库的可视化监控平台，我们会基于Prometheus+Grafana来搭建。



当然在公司里，如果要针对数据库搭建一个统一的可视化监控平台，这个活儿往往是DBA团队负责的，但是不管如何，我们这里也要对这个数据库可视化监控的技术有一定的了解。



**2、简单介绍一下Prometheus和Grafana是什么**



我们先给大家简单介绍一下Prometheus和Grafana两个系统分别是什么。



简单来说，Prometheus其实就是一个监控数据采集和存储系统，他可以利用监控数据采集组件（比如mysql_exporter）从你指定的MySQL数据库中采集他需要的监控数据，然后他自己有一个时序数据库，他会把采集到的监控数据放入自己的时序数据库中，其实本质就是存储在磁盘文件里。



我们采集到了MySQL的监控数据还不够，现在我们还要去看这些数据组成的一些报表，所以此时就需要使用Grafana了，Grafana就是一个可视化的监控数据展示系统，他可以把Prometheus采集到的大量的MySQL监控数据展示成各种精美的报表，让我们可以直观的看到MySQL的监控情况。



其实不光是对数据库监控可以采用Prometheus+Grafana的组合，对你开发出来的各种Java系统、中间件系统，都可以使用这套组合去进行可视化的监控，无非就是让Prometheus去采集你的监控数据，然后用Grafana展示成报表而已。



**3、安装和启动Prometheus**



之前给大家说过，让大家自己准备一个linux机器，如果你是windows笔记本电脑，可以自己装一个linux虚拟机。我们就基于一台linux机器来部署Prometheus和Grafana，至于MySQL的安装，这个非常的简单，大家在网上很容易搜索到。



首先大家需要下载3个压缩包，在下面链接：



https://prometheus.io/download/



大家可以下载到下面两个压缩包，这里prometheus就是用来部署监控系统自己的，然后node_exporter是用来采集MySQL数据库所在机器的CPU、内存、网络、磁盘之类的监控数据的：



prometheus-2.1.0.linux-amd64.tar.gz   

node_exporter-0.15.2.linux-amd64.tar.gz  



接着大家可以通过下面的链接下载第三个压缩包：mysqld_exporter-0.10.0.linux-amd64.tar.gz，这个mysqld_exporter就是用来采集MySQL数据库自己的一些监控数据的，比如SQL性能、连接数量之类的：



https://github.com/prometheus/mysqld_exporter/releases/download/v0.10.0/mysqld_exporter-0.10.0.linux-amd64.tar.gz



接着需要解压缩上面的几个包，参照我如下的命令来做就可以了：



mkdir /data

mkdir /root



tar xvf prometheus-2.1.0.linux-amd64.tar -C /data

tar xf node_exporter-0.15.2.linux-amd64.tar -C /root

tar xf mysqld_exporter-0.10.0.linux-amd64.tar.gz -C /root



cd /data

mv prometheus-2.1.0.linux-amd64/ prometheus

cd /prometheus



vi prometheus.yml，接下来修改prometheus的配置文件，其实主要是在scrape_configs下面加入一大段自定义的配置，因为他需要去采集MySQL数据库本身和MySQL所在机器的监控数据：



scrape_configs:

 \- file_sd_configs:

  -files:

   \- host.yml

  job_name: Host

  metrics_path: /metrics

  relabel_configs:

  \- source_labels: [__address__]

   regex: (.*)

   target_label: instance

   replacement: $1

  \- source_labels: [__address__]

   regex: (.*)

   target_label: __address__

   replacement: $1:9100

 \- file_sd_configs:

  \- files:

   \- mysql.yml

  job_name: MySQL

  metrics_path: /metrics

  relabel_configs:

  \- source_labels: [__address__]

   regex: (.*)

   target_label: instance

   replacement: $1

  \- source_labels: [__address__]

   regex: (.*)

   target_label: __address__

   replacement: $1:9104



 \- job_name: prometheus

  static_configs:

  \- targets:

   \- localhost: 9090



上面的配置文件写好之后，就可以启动Prometheus了，不过大家仔细看几遍上面的配置信息，因为我在写文章的时候不太方便，都是直接手敲出来的，可能会有少数配置错误，如果大家有发现配置文件错误的地方，及时在后台评论区告诉我。



接着必须要在/data/prometheus目录中，去执行启动命令：



/data/prometheus/prometheus --storage.tsdb.retention=30d &，这里的30d是说你的监控数据保留30天的。启动之后，就可以在浏览器中访问9090端口号去查看prometheus的主页了。



因为我们部署和安装Prometheus和Grafana的过程比较多，所以拆分为两篇文章，今天同步更新的第二篇文章里，会把剩余的Grafana的安装部署过程，以及监控配置和采集的过程都讲完。



## 10 生产经验：如何为数据库的监控系统部署可视化报表系统？

**1、部署Grafana**



上一篇文章我们讲解到安装好了Prometheus，接着我们来继续 讲解如何安装Grafana，首先要从下面的地址下载grafana-4.6.3.linux-x64.tar.gz，然后一步一步的执行下面的命令，完成他的启动。



https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.3.linux-x64.tar.gz



tar xf grafana-4.6.3.linux-x64.tar.gz -C /data/prometheus

cd /data/prometheus

mv grafana-4.6.3 grafana



cd /data/prometheus/grafana

./bin/grafana-server &



接着就完成了grafana的启动，然后可以通过浏览器访问3000端口，默认的用户名和密码是admin/admin。接着在Grafana左侧菜单栏里有一个Data Sources，点击里面的一个按钮是Add data source，就是添加一个数据源。



然后在界面里输入你的数据源的名字是Prometheus，类型是Prometheus，HTTP URL地址是http://127.0.0.1:9090，其他的都用默认的配置就行了，接下来Grafana就会自动从Prometheus里获取监控数据和展示了。



接着需要安装Grafana的仪表盘组件，首先需要下载grafana-dashboards-1.6.1.tar.gz，用如下的链接即可：https://github.com/percona/grafana-dashboards/archive/v1.6.1.tar.gz。



接着执行一系列的命令去安装grafana-dashboard组件。



tar xvf grafana-dashboards-1.6.1.tar.gz

cd grafana-dashboards-1.6.1

updatedb

locate json |grep dashboards/



这个时候会看到一大堆的json文件，就是各种不同的仪表盘对应的json配置文件，你可以把这些json配置文件通过WinSCP之类的工具从linux机器上拖到你的windows电脑上来，因为需要通过浏览器上传他们。



接着在grafana页面中，可以看到最上面有一个Home按钮，点击一下进入一个界面，你会看到一个Import Dashboard的按钮，就是说可以导入一些仪表盘，这个时候就是要导入刚才看到的一大堆的json文件。



你点击Upload json file按钮，就会出现一个界面让你上传一个一个的json文件，然后你就依次上传，接着grafana中就会出现一大堆的仪表盘了，比如机器的CPU使用率的仪表盘，磁盘性能仪表盘，磁盘空间仪表盘，MySQL监控仪表盘，等等。



**2、添加MySQL机器的监控**



首先我们如果想要让Prometheus去采集MySQL机器的监控数据（CPU、内存、磁盘、网络，等等），然后让Grafana可以展示出来，那么就必须先添加Prometheus对MySQL机器的监控。



首先必须要在MySQL机器上解压缩和启动node_exporter，这启动之后是个linux进程，他会自动采集这台linux机器上的CPU、磁盘、内存、网络之类的各种监控数据，其实本质你可以理解为通过我们之前讲解的那些linux命令，就可以采集到一切你想要的linux机器的监控数据。



tar xf node_exporter-0.15.2.linux-amd64.tar

mv node_exporter-0.15.2.linux-amd64 node_exporter

cd node_exporter

nohup ./node_exporter &



到这一步为止，我们就在MySQL所在的机器上启动了一个node_exporter了，他就会自动采集这台机器的CPU、磁盘、内存、网络的监控数据，但是此时还不够，因为Prometheus上还没加入对这台机器的监控。



此时我们应该还记得，之前在Prometheus的yml配置文件中，我们已经定义了一个host监控项，他就是用来监控机器的，他的配置文件是host.yml，此时我们可以编辑一下这个host.yml配置文件，加入mysql所在机器的地址就可以了



vi host.yml



\- labels:

  service: test

 targets:

 \- 127.0.0.1



接着Prometheus就会跟MySQL机器上部署的node_exporter进行通信，源源不断的获取到这台机器的监控数据，写入自己的时序数据库中进行存储。接着我们就可以打开Grafana的页面，此时你就可以看到这台机器的相关性能监控了。



**3、添加MySQL数据库的监控**



接着我们同样需要在MySQL所在机器上再启动一个mysqld_exporter的组件，他负责去采集MySQL数据库自己的一些监控数据，我们看下面的指令就可以了。



tar xf mysqld_exporter-0.10.0.linux-amd64.tar

mv mysqld_exporter-0.10.0.linux-amd64 mysqld_exporter



接着需要配置一些环境变量，去设置mysqld_exporter要监控的数据库的地址信息，看下面配置了账号、密码以及地址和端口号



export DATA_SOURCE_NAME='root:root@(127.0.0.1:3306)/'

echo "export DATA_SOURCE_NAME='root:root@(127.0.0.1:3306)/'" >> /etc/profile



接着启动mysqld_exporter



cd mysqld_exporter



nohup ./mysqld_exporter --collect.info_schema.processlist --collect.info_schema.innodb_tablespaces --collect.info_schema.innodb_metrics --collect.perf_schema.tableiowaits --collect.perf_schema.indexiowaits --collect.perf_schema.tablelocks --collect.engine_innodb_status --collect.perf_schema.file_events --collect.info_schema.processlist --collect.binlog_size --collect.info_schema.clientstats --collect.perf_schema.eventswaits &



上面的启动命令指定了大量的选项去开启一些监控的采集，这些命令也都是我手敲的，因为目前写作环境的一些不便利的因素，所以只能是如此，如果大家发现有什么小的错误，可以评论区后台告诉我。



接着这个mysqld_exporter进程就会自动采集MySQL自己的监控数据了，然后我们还需要在Prometheus里配置一下他去跟mysqld_exporter通信获取数据以及存储，然后Grafana才能看到对应的报表。



vi /data/prometheus/mysql.yml



\- labels:

  service: mysql_test

 targets:

 \- 127.0.0.1



接着我们在Grafana中就可以看到MySQL的各种监控数据了。



**4、一个作业**



今天我想留给大家一个小作业，希望大家可以参考今天的两篇文章，动手搭建一下数据库的监控系统，然后可以用sysbench做一下压测，在压测过程中，可以直接看看Grafana上的机器以及MySQL的各项监控指标。



这个过程没什么难度，但是可能会遇到一些操作性的问题，如果大家搭建的过程中发现什么问题，不要直接把报错的截图贴在评论区，你可以先去上网查查，错误在哪里



**如果真的有问题的话，我后续会想办法解决一下错误，然后更新出来的。**



另外，我希望大家思考一个问题，大家可以去看看自己公司里的数据库有没有做过压测？可视化监控做了吗？是怎么做的？自己项目的数据库平时的一些机器负载和QPS、TPS都是多少？自己对数据库是否有一个较为全面的掌握？



## 11 从数据的增删改开始讲起，回顾一下Buffer Pool在数据库里的地位

**1、一切从数据的增删改开始讲起**



好了，到这一讲为止，我们实际上已经初步的讲解了一下MySQL的整体架构设计原理，大家对于MySQL内部包含哪些组件，我们平时更新数据以及查询数据的时候，大致都是怎么做的，都已经有一个比较高层次的了解了。



另外现在我们初步的了解了MySQL的架构原理之后，还给大家介绍了一些我们的数据库相关的生产经验，就是对于任何一个项目，数据库都需要选择好合适的机器，同时做好压测，并且有一个完善的可视化监控系统。



现在可以理解为每个人手头都有了一个可用的数据库，而且对数据库的整体架构原理都有了一定的理解了。那么接下来，我们这个专栏一共有100多讲的内容，我们接着当然要细细的讲解数据库的方方面面了



那我们应该从哪个环节开始入手呢？



当然是从数据库的增删改开始了，因为当你手头有了一个数据库之后，你必然就会去开发一个系统，系统就直接基于数据库做各种增删改查的操作，实现各种各样的业务逻辑



而任何一个系统在使用数据库的时候，一定是从插入数据开始的，也就是首先先会对数据进行增删改的操作。



当你的数据库中有了数据之后，接着才会执行各种各样的查询操作。



所以我们专栏的讲解顺序，就按照你手头有了一个经过压测的、有完善监控的数据库之后，你开发的系统使用数据库的顺序来讲解，先讲解系统对数据库执行各种增删改操作时背后对应的内幕原理，以及事务的原理，包括锁的底层机制，然后讲解你有了数据之后，执行各种复杂的查询操作的时候，涉及到的索引底层原理，查询优化的底层原理。



当然这个中间我们会穿插各种各样的生产实践的案例，就跟我之前讲解的《从0开始带你成为JVM实战高手》专栏一样。



然后讲解完这些之后，我们再来讲解平时我们在开发系统的时候，如何进行数据库的建模，在数据库建模的时候，应该如何注意字段类型、索引类型的一些问题，如何保证数据库避免死锁、高性能的运行。



接着我们再讲解一些高阶的数据库架构设计，比如说主从架构设计以及分库分表架构设计，包括一些生产实践的案例。



所以上面的这些就是我们专栏接下来将要讲解的顺序，这里要给大家提前通知一下，我在实际讲解的过程中，会增加很多内容，比如接下来好几讲都是深度分析Buffer Pool的内容，实际上在原来的大纲中都是没有的。



另外我接下来讲解的过程中，还可能随时会对大纲中原有内容的顺序做出调整，比如说我在讲解完Buffer Pool之后，接着可能直接会深入讲解redo log、undo log、binlog这些机制，同时接着讲解事务机制，锁机制，底层数据存储机制。



然后这些都讲完之后，才是讲解索引和查询优化的内容，所以希望大家能明白我们随时会对大纲内容做出额外的扩充，以及我们随时会调整大纲内容的顺序。



好，那么从这篇文章开始，让我们一起来探索数据库的各种底层机制和生产实践案例吧！



**2、回顾一下Buffer Pool是个什么东西？**



现在我们先来回顾一下数据库中的Buffer Pool是个什么东西？其实他是一个非常关键的组件，因为我们通过之前的讲解都知道一点，那就是数据库中的数据实际上最终都是要存放在磁盘文件上的，如下图所示。

​      ![img](all_in_one.assets/0-16558283520353)       

但是我们在对数据库执行增删改操作的时候，不可能直接更新磁盘上的数据的，因为如果你对磁盘进行随机读写操作，那速度是相当的慢，随便一个大磁盘文件的随机读写操作，可能都要几百毫秒。如果要是那么搞的话，可能你的数据库每秒也就只能处理几百个请求了！



之前我们也都讲解过了，你在对数据库执行增删改操作的时候，实际上主要都是针对内存里的Buffer Pool中的数据进行的，也就是你实际上主要是对数据库的内存里的数据结构进行了增删改，如下图所示。

​      ![img](all_in_one.assets/0-16558283520241)       

当然，我们之前都说过，其实每个人都担心一个事，就是你在数据库的内存里执行了一堆增删改的操作，内存数据是更新了，但是这个时候如果数据库突然崩溃了，那么内存里更新好的数据不是都没了吗？



所以其实之前我们开头就用了很多篇幅讲这个问题，MySQL就怕这个问题，所以引入了一个redo log机制，你在对内存里的数据进行增删改的时候，他同时会把增删改对应的日志写入redo log中，如下图。

​      ![img](all_in_one.assets/0-16558283520242)       

万一你的数据库突然崩溃了，没关系，只要从redo log日志文件里读取出来你之前做过哪些增删改操作，瞬间就可以重新把这些增删改操作在你的内存里执行一遍，这就可以恢复出来你之前做过哪些增删改操作了。



当然对于数据更新的过程，他是有一套严密的步骤的，还涉及到undo log、binlog、提交事务、buffer pool脏数据刷回磁盘，等等。我们之前都讲过了，这里不再重复，仅仅是带着大家重新回顾一下数据库中的Buffer Pool这个东西。



**3、Buffer Pool的一句话总结**



所以这里我们简单对Buffer Pool这个东西做一下总结，他其实是数据库中我们第一个必须要搞清楚的核心组件，因为增删改操作首先就是针对这个内存中的Buffer Pool里的数据执行的，同时配合了后续的redo log、刷磁盘等机制和操作。



所以Buffer Pool就是数据库的一个内存组件，里面缓存了磁盘上的真实数据，然后我们的Java系统对数据库执行的增删改操作，其实主要就是对这个内存数据结构中的缓存数据执行的。



这一篇文章我们先对Buffer Pool这个东西的定位做一个简单的回顾，下一篇文章我们来分析一下Buffer Pool这个内存数据结构里到底包含了一些什么东西。



## 12 Buffer Pool这个内存数据结构到底长个什么样子？

**1、如何配置你的Buffer Pool的大小？**



首先我们来看看，我们应该如何配置你的Buffer Pool到底有多大呢？



因为Buffer Pool本质其实就是数据库的一个内存组件，你可以理解为他就是一片内存数据结构，所以这个内存数据结构肯定是有一定的大小的，不可能是无限大的。



这个Buffer Pool默认情况下是128MB，还是有一点偏小了，我们实际生产环境下完全可以对Buffer Pool进行调整。



比如我们的数据库如果是16核32G的机器，那么你就可以给Buffer Pool分配个2GB的内存，使用下面的配置就可以了。



[server]

innodb_buffer_pool_size = 2147483648



如果有的朋友不知道数据库的配置文件在哪里以及如何修改其中的配置，那建议可以先在网上搜索一些MySQL入门的资料去看看，其实这都是最基础和简单的。



我们先来看一下下面的图，里面就画了数据库中的Buffer Pool内存组件。

​      ![img](all_in_one.assets/0-165582840926510)   

**2、数据页：MySQL中抽象出来的数据单位**



接着我们来看下一个问题，假设现在我们的数据库中一定有一片内存区域是Buffer Pool了，那么我们的数据是如何放在Buffer Pool中的？



我们都知道数据库的核心数据模型就是表+字段+行的概念，也就是说我们都知道数据库里有一个一个的表，一个表有很多字段，然后一个表里有很多行数据，每行数据都有自己的字段值。所以大家觉得我们的数据是一行一行的放在Buffer Pool里面的吗？



这就明显不是了，实际上MySQL对数据抽象出来了一个数据页的概念，他是把很多行数据放在了一个数据页里，也就是说我们的磁盘文件中就是会有很多的数据页，每一页数据里放了很多行数据，如下图所示。

​      ![img](all_in_one.assets/0-165582840926511)       

所以实际上假设我们要更新一行数据，此时数据库会找到这行数据所在的数据页，然后从磁盘文件里把这行数据所在的数据页直接给加载到Buffer Pool里去



也就是说，Buffer Pool中存放的是一个一个的数据页，如下图。

​      ![img](all_in_one.assets/0-165582840926612)       

**3、磁盘上的数据页和Buffer Pool中的缓存页是如何对应起来的？**



实际上默认情况下，磁盘中存放的数据页的大小是16KB，也就是说，一页数据包含了16KB的内容。



而Buffer Pool中存放的一个一个的数据页，我们通常叫做缓存页，因为毕竟Buffer Pool是一个缓冲池，里面的数据都是从磁盘缓存到内存去的。



而Buffer Pool中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是16KB。



所以我们看下图，我给图中的Buffer Pool标注出来了他的内存大小，假设他是128MB吧，然后数据页的大小是16KB。

​      ![img](all_in_one.assets/0-165582840926613)       

**4、缓存页对应的描述信息是什么？**



接着我们要了解下一个概念，对于每个缓存页，他实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的



比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂八的东西。



每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面



所以此时我们看下面的图，Buffer Pool实际看起来大概长这个样子。

​      ![img](all_in_one.assets/0-165582840926614)       

而且这里我们要注意一点，Buffer Pool中的描述数据大概相当于缓存页大小的5%左右，也就是每个描述数据大概是800个字节左右的大小，然后假设你设置的buffer pool大小是128MB，实际上Buffer Pool真正的最终大小会超出一些，可能有个130多MB的样子，因为他里面还要存放每个缓存页的描述数据。



**5、今日思考题**



今天想留给大家思考一个问题，就是内存碎片的问题



大家可以想象一下，对于Buffer Pool而言，他里面会存放很多的缓存页以及对应的描述数据，那么假设Buffer Pool里的内存都用尽了，已经没有足够的剩余内存来存放缓存页和描述数据了，此时Buffer Pool里就一点内存都没有了吗？还是说Buffer Pool里会残留一些内存碎片呢？



如果你觉得Buffer Pool里会有内存碎片的话，那么你觉得应该怎么做才能尽可能减少Buffer Pool里的内存碎片呢？



## 13 从磁盘读取数据页到Buffer Pool的时候，free链表有什么用？

**1、数据库启动的时候，是如何初始化Buffer Pool的？**



现在我们已经搞明白一件事儿了，那就是数据库的Buffer Pool到底长成个什么样，大家想必都是理解了



其实说白了，里面就是会包含很多个缓存页，同时每个缓存页还有一个描述数据，也可以叫做是控制数据，但是我个人是比较倾向于叫做描述数据，或者缓存页的元数据，都是可以的。



那么在数据库启动的时候，他是如何初始化Buffer Pool的呢？



其实这个也很简单，数据库只要一启动，就会按照你设置的Buffer Pool大小，稍微再加大一点，去找操作系统申请一块内存区域，作为Buffer Pool的内存区域。



然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的16KB的大小以及对应的800个字节左右的描述数据的大小，在Buffer Pool中划分出来一个一个的缓存页和一个一个的他们对应的描述数据。



然后当数据库把Buffer Pool划分完毕之后，看起来就是之前我们看到的那张图了，如下图所示。



​      ![img](all_in_one.assets/0-165582846870425)       

只不过这个时候，Buffer Pool中的一个一个的缓存页都是空的，里面什么都没有，要等数据库运行起来之后，当我们要对数据执行增删改查的操作的时候，才会把数据对应的页从磁盘文件里读取出来，放入Buffer Pool中的缓存页中。



**2、我们怎么知道哪些缓存页是空闲的呢？**



接着我们来看下一个问题，当你的数据库运行起来之后，你肯定会不停的执行增删改查的操作，此时就需要不停的从磁盘上读取一个一个的数据页放入Buffer Pool中的对应的缓存页里去，把数据缓存起来，那么以后就可以对这个数据在内存里执行增删改查了。



但是此时在从磁盘上读取数据页放入Buffer Pool中的缓存页的时候，必然涉及到一个问题，那就是**哪些缓存页是空闲的？**



因为默认情况下磁盘上的数据页和缓存页是一 一对应起来的，都是16KB，一个数据页对应一个缓存页。



所以我们必须要知道Buffer Pool中哪些缓存页是空闲的状态。



所以数据库会为Buffer Pool设计一个**free链表**，他是一个双向链表数据结构，这个free链表里，每个节点就是一个空闲的缓存页的描述数据块的地址，也就是说，只要你一个缓存页是空闲的，那么他的描述数据块就会被放入这个free链表中。



刚开始数据库启动的时候，可能所有的缓存页都是空闲的，因为此时可能是一个空的数据库，一条数据都没有，所以此时所有缓存页的描述数据块，都会被放入这个free链表中



我们看下图所示

​      ![img](all_in_one.assets/0-165582846870426)       

大家可以看到上面出现了一个free链表，这个free链表里面就是各个缓存页的描述数据块，只要缓存页是空闲的，那么他们对应的描述数据块就会加入到这个free链表中，每个节点都会双向链接自己的前后节点，组成一个双向链表。



除此之外，这个free链表有一个基础节点，他会引用链表的头节点和尾节点，里面还存储了链表中有多少个描述数据块的节点，也就是有多少个空闲的缓存页。



**3、free链表占用多少内存空间？**



可能有的人会以为这个描述数据块，在Buffer Pool里有一份，在free链表里也有一份，好像在内存里有两个一模一样的描述数据块，是么？



其实这么想就大错特错了。



这里要给大家讲明白一点，这个free链表，他本身其实就是由Buffer Pool里的描述数据块组成的，你可以认为是每个描述数据块里都有两个指针，一个是free_pre，一个是free_next，分别指向自己的上一个free链表的节点，以及下一个free链表的节点。



通过Buffer Pool中的描述数据块的free_pre和free_next两个指针，就可以把所有的描述数据块串成一个free链表，大家可以自己去思考一下这个问题。上面为了画图需要，所以把描述数据块单独画了一份出来，表示他们之间的指针引用关系。



对于free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面就存放了free链表的头节点的地址，尾节点的地址，还有free链表里当前有多少个节点。



**4、如何将磁盘上的页读取到Buffer Pool的缓存页中去？**



好了，现在我们可以来解答这一篇文章的最后一个问题了，当你需要把磁盘上的数据页读取到Buffer Pool中的缓存页里去的时候，是怎么做到的？



其实有了free链表之后，这个问题就很简单了。



首先，我们需要从free链表里获取一个描述数据块，然后就可以对应的获取到这个描述数据块对应的空闲缓存页，我们看下图所示。

​      ![img](all_in_one.assets/0-165582846870527)       

接着我们就可以把磁盘上的数据页读取到对应的缓存页里去，同时把相关的一些描述数据写入缓存页的描述数据块里去，比如这个数据页所属的表空间之类的信息，最后把那个描述数据块从free链表里去除就可以了，如下图所示。

​      ![img](all_in_one.assets/0-165582846870528)       

可能有朋友还是疑惑，这个描述数据块是怎么从free链表里移除的呢？



简单，我给你一段伪代码演示一下。



假设有一个描述数据块02，他的上一个节点是描述数据块01，下一个节点是描述数据块03，那么他在内存中的数据结构如下。



![image.png](all_in_one.assets/44788400_1581001683.png)



现在假设block03被使用了，要从free链表中移除，那么此时直接就可以把block02节点的free_next设置为null就可以了，block03就从free链表里失去引用关系了，如下所示。



![image.png](all_in_one.assets/41411000_1581001683.png)



想必看到这里，大家就完全明白，磁盘中的数据页是如何读取到Buffer Pool中的缓存页里去的了，而且这个过程中free链表是用来干什么的。



**5、你怎么知道数据页有没有被缓存？**



接着我们来看下一个问题：你怎么知道一个数据页有没有被缓存呢？



我们在执行增删改查的时候，肯定是先看看这个数据页有没有被缓存，如果没被缓存就走上面的逻辑，从free链表中找到一个空闲的缓存页，从磁盘上读取数据页写入缓存页，写入描述数据，从free链表中移除这个描述数据块。



但是如果数据页已经被缓存了，那么就会直接使用了。



所以其实**数据库还会有一个哈希表数据结构，他会用表空间号+数据页号，作为一个key，然后缓存页的地址作为value。**



当你要使用一个数据页的时候，通过“表空间号+数据页号”作为key去这个哈希表里查一下，如果没有就读取数据页，如果已经有了，就说明数据页已经被缓存了。



我们看下图，又引入了一个数据页缓存哈希表的结构。



也就是说，每次你读取一个数据页到缓存之后，都会在这个哈希表中写入一个key-value对，key就是表空间号+数据页号，value就是缓存页的地址，那么下次如果你再使用这个数据页，就可以从哈希表里直接读取出来他已经被放入一个缓存页了。

​      ![img](all_in_one.assets/0-165582846870529)       

**6、今日思考题**



今天我们给大家留一个思考题，大家去想一个问题，我们要取一个数据的时候，必然会取他所属的一个数据页，而且这个数据必然是属于一个表的，所以我们在上面初步引入了一个表空间的概念



也就是说我们写SQL的时候，只知道表+行的概念，但是在MySQL内部操作的时候，是表空间+数据页的概念。



那么大家觉得这两者之间的区别是什么？他们之间的联系是什么？



## 14 当我们更新Buffer Pool中的数据时，flush链表有什么用？

**1、昨日思考题解答**



我们先解答一下昨日的思考题，昨天是问了大家一个问题，Buffer Pool中会不会有内存碎片？



答案是：当然有



因为Buffer Pool大小是你自己定的，很可能Buffer Pool划分完全部的缓存页和描述数据块之后，还剩一点点的内存，这一点点的内存放不下任何一个缓存页了，所以这点内存就只能放着不能用，这就是内存碎片。



那怎么减少内存碎片呢？



其实也很简单，数据库在Buffer Pool中划分缓存页的时候，会让所有的缓存页和描述数据块都紧密的挨在一起，这样尽可能减少内存浪费，就可以尽可能的减少内存碎片的产生了。



如果你的Buffer Pool里的缓存页是东一块西一块，那么必然导致缓存页的内存之间有很多内存空隙，这就会有大量的内存碎片了。



**2、脏数据页到底为什么会脏？**



接着我们看一个很关键的问题，你在执行增删改的时候，如果发现数据页没缓存，那么必然会基于free链表找到一个空闲的缓存页，然后读取到缓存页里去，但是如果已经缓存了，那么下一次就必然会直接使用缓存页。



反正不管怎么样，你要更新的数据页都会在Buffer Pool的缓存页里，供你在内存中直接执行增删改的操作。



接着你肯定会去更新Buffer Pool的缓存页中的数据，此时一旦你更新了缓存页中的数据，那么缓存页里的数据和磁盘上的数据页里的数据，是不是就不一致了？



这个时候，我们就说缓存页是脏数据，脏页

​      ![img](all_in_one.assets/0-165582851230144)       

**3、哪些缓存页是脏页呢？**



其实通过之前的学习，我们都是知道一点的，最终这些在内存里更新的脏页的数据，都是要被刷新回磁盘文件的。



但是这里就有一个问题了，不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到Buffer Pool里去的，可能根本没修改过！



所以数据库在这里引入了另外一个跟free链表类似的**flush链表**，这个flush链表本质也是通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表。



凡是被修改过的缓存页，都会把他的描述数据块加入到flush链表中去，flush的意思就是这些都是脏页，后续都是要flush刷新到磁盘上去的



所以flush链表的结构如下图所示，跟free链表几乎是一样的。

​      ![img](all_in_one.assets/0-165582851230145)       

**4、flush链表构造的伪代码演示**



我们用一些伪代码来给大家展示一下这个flush链表的构造过程，比如现在缓存页01被修改了数据，那么他就是脏页了，此时就必须把他加入到flush链表中去



此时缓存页01的描述数据块假设如下所示



![image.png](all_in_one.assets/74096300_1581037442.png)



好了，我们可以看到，现在flush链表的基础节点就指向了一个block01的节点，接着比如缓存页02被更新了，他也是脏页了，此时他的描述数据块也要被加入到flush链表中去



此时伪代码如下：



![image.png](all_in_one.assets/82445700_1581037442.png)



大家可以看到，当你更新缓存页的时候，通过变换缓存页中的描述数据块的flush链表的指针，就可以把脏页的描述数据块组成一个双向链表，也就是flush链表，而且flush链表的基础节点会指向起始节点和尾巴节点。



通过这个flush链表，就可以记录下来哪些缓存页是脏页了！



## 15 当Buffer Pool中的缓存页不够的时候，如何基于LRU算法淘汰部分缓存？

**1、如果Buffer Pool中的缓存页不够了怎么办？**



之前我们已经给大家讲解了Buffer Pool中的缓存页的划分，包括free链表的使用，然后磁盘上的数据页是如何加载到缓存页里去的，包括对缓存页修改之后，flush链表是如何用来记载脏数据页的。



今天我们接着来分析Buffer Pool的工作原理，我们来思考一个问题，当你要执行CRUD操作的时候，无论是查询数据，还是修改数据，实际上都会把磁盘上的数据页加载到缓存页里来，这个大家都是没有问题的吧？



那么在加载数据到缓存页的时候，必然是要加载到空闲的缓存页里去的，所以必须要从free链表中找一个空闲的缓存页，然后把磁盘上的数据页加载到那个空闲的缓存页里去，我们看下图的红色箭头的示意。

​      ![img](all_in_one.assets/0-165582855801954)       

那么大家通过之前的学习肯定都知道了，随着你不停的把磁盘上的数据页加载到空闲的缓存页里去，free链表中的空闲缓存页是不是会越来越少？因为只要你把一个数据页加载到一个空闲缓存页里去，free链表中就会减少一个空闲缓存页。



所以，当你不停的把磁盘上的数据页加载到空闲缓存页里去，free链表中不停的移除空闲缓存页，迟早有那么一瞬间，你会发现free链表中已经没有空闲缓存页了



这个时候，当你还要加载数据页到一个空闲缓存页的时候，怎么办呢？如下图。



​      ![img](all_in_one.assets/0-165582855801955)       

**2、如果要淘汰掉一些缓存数据，淘汰谁？**



针对上述的问题，大家来思考下一个问题，如果所有的缓存页都被塞了数据了，此时无法从磁盘上加载新的数据页到缓存页里去了，那么此时你只有一个办法，就是淘汰掉一些缓存页。



那什么叫淘汰缓存页呢？



顾名思义，你必须把一个缓存页里被修改过的数据，给他刷到磁盘上的数据页里去，然后这个缓存页就可以清空了，让他重新变成一个空闲的缓存页。



接着你再把磁盘上你需要的新的数据页加载到这个腾出来的空闲缓存页中去，如下图。

​      ![img](all_in_one.assets/0-165582855801956)       

那么下一个问题来了，如果要把一个缓存页里的数据刷入磁盘，腾出来一个空闲缓存页，那么应该把哪个缓存页的数据给刷入磁盘呢？



**3、缓存命中率概念的引入**



要解答这个问题，我们就得引入一个缓存命中率的概念。



假设现在有两个缓存页，一个缓存页的数据，经常会被修改和查询，比如在100次请求中，有30次都是在查询和修改这个缓存页里的数据。那么此时我们可以说这种情况下，缓存命中率很高



为什么呢？因为100次请求中，30次都可以操作缓存，不需要从磁盘加载数据，这个缓存命中率就比较高了。



另外一个缓存页里的数据，就是刚从磁盘加载到缓存页之后，被修改和查询过1次，之后100次请求中没有一次是修改和查询这个缓存页的数据的，那么此时我们就说缓存命中率有点低，因为大部分请求可能还需要走磁盘查询数据，他们要操作的数据不在缓存中。



所以针对上述两个缓存页，假设此时让你做一个抉择，要把其中缓存页的数据刷入到磁盘去，腾出来一个空闲的缓存页，此时你会选择谁？



那还用想么，当然是选择第二个缓存页刷入磁盘中了！



因为第二个缓存页，压根儿就没什么人来使用他里面的数据，结果这些数据还空占据了一个缓存页，这不是占着茅坑不拉屎么？



**4、引入LRU链表来判断哪些缓存页是不常用的**



接着我们就要解决下一个问题了，就是你怎么知道哪些缓存页经常被访问，哪些缓存页很少被访问？



此时就要引入一个新的LRU链表了，这个所谓的LRU就是Least Recently Used，最近最少使用的意思。



通过这个LRU链表，我们可以知道哪些缓存页是最近最少被使用的，那么当你缓存页需要腾出来一个刷入磁盘的时候，不就可以选择那个LRU链表中最近最少被使用的缓存页了么？



这个LRU链表大致是怎么个工作原理呢？



简单来说，我们看下图，假设我们从磁盘加载一个数据页到缓存页的时候，就把这个缓存页的描述数据块放到LRU链表头部去，那么只要有数据的缓存页，他都会在LRU里了，而且最近被加载数据的缓存页，都会放到LRU链表的头部去。

​      ![img](all_in_one.assets/0-165582855801957)       

然后假设某个缓存页的描述数据块本来在LRU链表的尾部，后续你只要查询或者修改了这个缓存页的数据，也要把这个缓存页挪动到LRU链表的头部去，也就是说最近被访问过的缓存页，一定在LRU链表的头部，如下图。

​      ![img](all_in_one.assets/0-165582855801958)       

那么这样的话，当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘？此时你就直接在LRU链表的尾部找到一个缓存页，他一定是最近最少被访问的那个缓存页！



然后你就把LRU链表尾部的那个缓存页刷入磁盘中，然后把你需要的磁盘数据页加载到腾出来的空闲缓存页中就可以了！



**5、上次思考题解答**



今天我们在末尾解答一下上次留的那个思考题，就是说，我们在SQL语句里都是用到的是表和行的概念，但是之前我们提到的表空间、数据页，他们之间的关系是什么呢？



其实简单来讲，**一个是逻辑概念，一个是物理概念。**



表、列和行，都是逻辑概念，我们只知道数据库里有一个表，表里有几个字段，有多少行，但是这些表里的数据，在数据库的磁盘上如何存储的，你知道吗？我们是不关注的，所以他们都是逻辑上的概念。



表空间、数据页，这些东西，都是物理上的概念，实际上在物理层面，你的表里的数据都放在一个表空间中，表空间是由一堆磁盘上的数据文件组成的，这些数据文件里都存放了你表里的数据，这些数据是由一个一个的数据页组织起来的，这些都是物理层面的概念，这就是他们之间的区别。



## 16 简单的LRU链表在Buffer Pool实际运行中，可能导致哪些问题？

**1、简单回顾一下**



之前我们讲解了Buffer Pool在使用过程中如果缓存页都使用了，没有空闲的缓存页时，可以去LRU链表中的尾部找一个最近最少使用的缓存页，把他的数据刷入磁盘，腾出来一个空闲缓存页，然后加载需要的新的磁盘数据页到空闲缓存页里去。



而LRU链表的机制也很简单，只要是刚从磁盘上加载数据到缓存页里去，这个缓存页就放入LRU链表的头部，后续如果对任何一个缓存页访问了，也把缓存页从LRU链表中移动到头部去。



这样在LRU链表的尾部，一定是最近最少被访问的那个缓存页。



**2、预读带来的一个巨大问题**



但是这样的一个LRU机制在实际运行过程中，是会存在巨大的隐患的。



首先会带来隐患的就是MySQL的预读机制，这个所谓预读机制，说的就是当你从磁盘上加载一个数据页的时候，他可能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去！



举个例子，假设现在有两个空闲缓存页，然后在加载一个数据页的时候，连带着把他的一个相邻的数据页也加载到缓存里去了，正好每个数据页放入一个空闲缓存页！



但是接下来呢，实际上只有一个缓存页是被访问了，另外一个通过预读机制加载的缓存页，其实并没有人访问，此时这两个缓存页可都在LRU链表的前面，如下图。

​      ![img](all_in_one.assets/0-165582859754169)       

我们可以看到，这个图里很清晰的表明了，前两个缓存页都是刚加载进来的，但是此时第二个缓存页是通过预读机制捎带着加载进来的，他也放到了链表的前面，但是他实际没人访问他。



除了第二个缓存页之外，第一个缓存页，以及尾巴上两个缓存页，都是一直有人访问的那种缓存页，只不过上图代表的是刚刚把头部两个缓存页加载进来的时候的一个LRU链表当时的情况。



这个时候，假如没有空闲缓存页了，那么此时要加载新的数据页了，是不是就要从LRU链表的尾部把所谓的“最近最少使用的一个缓存页”给拿出来，刷入磁盘，然后腾出来一个空闲缓存页了？



这个时候，如果你把上图中LRU尾部的那个缓存页刷入磁盘然后清空，你觉得合理吗？他可是之前一直频繁被人访问的啊！只不过在这一个瞬间，被新加载进来的两个缓存页给占据了LRU链表前面的位置，尤其是第二个缓存页，居然还是通过预读机制加载进来的，根本就不会有人访问！



那么这个时候，你要是把LRU链表尾部的缓存页给刷入磁盘，这是绝对不合理的，最合理的反而是把上图中LRU链表的第二个通过预读机制加载进来的缓存页给刷入磁盘和清空，毕竟他几乎是没什么人会访问的！



**3、哪些情况下会触发MySQL的预读机制？**



现在我们已经理解了预读机制一下子把相邻的数据页加载进缓存，放入LRU链表前面的隐患了，预读机制加载进来的缓存页可能根本不会有人访问，结果他却放在了LRU链表的前面，此时可能会把LRU尾部的那些被频繁访问的缓存页刷入磁盘中！



所以我们来看看，到底哪些情况下会触发MySQL的预读机制呢？



**（1）**有一个参数是innodb_read_ahead_threshold，他的默认值是56，意思就是如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓存里去



**（2）**如果Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去



这个机制是通过参数innodb_random_read_ahead来控制的，他默认是OFF，也就是这个规则是关闭的



所以默认情况下，主要是第一个规则可能会触发预读机制，一下子把很多相邻区里的数据页加载到缓存里去，这些缓存页如果一下子都放在LRU链表的前面，而且他们其实并没什么人会访问的话，那就会如上图，导致本来就在缓存里的一些频繁被访问的缓存页在LRU链表的尾部。



这样的话，一旦要把一些缓存页淘汰掉，刷入磁盘，腾出来空闲缓存页，就会如上所述，把LRU链表尾部一些频繁被访问的缓存页给刷入磁盘和清空掉了！这是完全不合理的，并不应该这样！



**4、另外一种可能导致频繁被访问的缓存页被淘汰的场景**



接着我们讲另外一种可能导致频繁被访问的缓存页被淘汰的场景，那就是**全表扫描**



这个所谓的全表扫描，意思就是类似如下的SQL语句：SELECT * FROM USERS



此时他没加任何一个where条件，会导致他直接一下子把这个表里所有的数据页，都从磁盘加载到Buffer Pool里去。



这个时候他可能会一下子就把这个表的所有数据页都一一装入各个缓存页里去！此时可能LRU链表中排在前面的一大串缓存页，都是全表扫描加载进来的缓存页！那么如果这次全表扫描过后，后续几乎没用到这个表里的数据呢？



此时LRU链表的尾部，可能全部都是之前一直被频繁访问的那些缓存页！



然后当你要淘汰掉一些缓存页腾出空间的时候，就会把LRU链表尾部一直被频繁访问的缓存页给淘汰掉了，而留下了之前全表扫描加载进来的大量的不经常访问的缓存页！



**5、总结**



所以我们来对今天讲到的内容做一点小小的总结，如果你使用简单的LRU链表的机制，其实是漏洞百出的，因为很可能预读机制，或者全表扫描的机制，都会一下子把大量未来可能不怎么访问的数据页加载到缓存页里去，然后LRU链表的前面全部是这些未来可能不怎么会被访问的缓存页！



而真正之前一直频繁被访问的缓存页可能此时都在LRU链表的尾部了！



如果此时此刻，需要把一些缓存页刷入磁盘，腾出空间来加载新的数据页，那么此时就只能把LRU链表尾部那些一直频繁被访问的缓存页给刷入磁盘了！



最后我们再看一下下面的图示，想必大家是很好理解的。

​      ![img](all_in_one.assets/0-165582859754170)       

**6、今日思考题**



今天希望大家思考一下：

- 为什么MySQL要设计预读这个机制？
- 他加载一个数据页到缓存里去的时候，为什么要把一些相邻的数据页也加载到缓存里去呢？这么做的意义在哪里？
- 是为了应对什么样的一个场景？



## 17 MySQL是如何基于冷热数据分离的方案，来优化LRU算法的？

**1、昨日思考题解答**



先给大家解答一下上次给大家布置的思考题，上回我们给大家提了一个问题：为什么MySQL要设计一个预读机制，为什么有时候要把相邻的一些数据页一次性读入到Buffer Pool缓存里去？



道理很简单，说白了还不是为了提升性能么。假设你读取了数据页01到缓存页里去，那么好，接下来有可能会接着顺序读取数据页01相邻的数据页02到缓存页里去，这个时候，是不是可能在读取数据页02的时候要再次发起一次磁盘IO？



所以为了优化性能，MySQL才设计了预读机制，也就是说如果在一个区内，你顺序读取了好多数据页了，比如数据页01~数据页56都被你依次顺序读取了，MySQL会判断，你可能接着会继续顺序读取后面的数据页。



那么此时他就干脆提前把后续的一大堆数据页（比如数据页57~数据页72）都读取到Buffer Pool里去，那么后续你再读取数据页60的时候，是不是就可以直接从Buffer Pool里拿到数据了？



当然理想是上述那样，很丰满，但是现实可能很骨感。你预读的一大堆数据页要是占据了LRU链表的前面部分，可能这些预读的数据页压根儿后续没人会使用，那你这个预读机制就是在捣乱了。



**2、基于冷热数据分离的思想设计LRU链表**



所以为了解决上一讲我们说的简单的LRU链表的问题，真正MySQL在设计LRU链表的时候，采取的实际上是冷热数据分离的思想。



之前一系列的问题，说白了，不都是因为所有缓存页都混在一个LRU链表里，才导致的么？



所以真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由innodb_old_blocks_pct参数控制的，他默认是37，也就是说冷数据占比37%。



这个时候，LRU链表实际上看起来是下面这样子的。

​      ![img](all_in_one.assets/0-165582864175475)

**3、数据页第一次被加载到缓存的时候**



好，既然我们知道LRU链表已经按照一定的比例被拆分为了冷热两块区域了，那么接下来就来看看在运行期间，冷热两个区域是如何使用的。



首先数据页第一次被加载到缓存的时候，这个时候缓存页会被放在LRU链表的哪个位置呢？



实际上这个时候，缓存页会被放在冷数据区域的链表头部，我们看下面的图，也就是第一次把一个数据页加载到缓存页之后，这个缓存页实际上是被放在下图箭头的位置，也就是冷数据区域的链表头部位置。

​      ![img](all_in_one.assets/0-165582864175476)    

**4、冷数据区域的缓存页什么时候会被放入到热数据区域？**



接着我们来思考一个问题，第一次被加载了数据的缓存页，都会不停的移动到冷数据区域的链表头部，如上图所示



那么你要知道，冷数据区域的缓存页肯定是会被使用的，那么冷数据区域的缓存页什么时候会放到热数据区域呢？



实际上肯定很多人会想，只要对冷数据区域的缓存页进行了一次访问，就立马把这个缓存页放到热数据区域的头部行不行呢？如下图所示。  ![img](all_in_one.assets/0-165582864175477)       

其实这也是不合理的，如果你刚加载了一个数据页到那个缓存页，他是在冷数据区域的链表头部，然后立马（在1ms以内）就访问了一下这个缓存页，之后就再也不访问他了呢？难道这种情况你也要把那个缓存页放到热数据区域的头部吗？



所以MySQL设定了一个规则，他设计了一个innodb_old_blocks_time参数，默认值1000，也就是1000毫秒



也就是说，必须是一个数据页被加载到缓存页之后，在1s之后，你访问这个缓存页，他才会被挪动到热数据区域的链表头部去。



因为假设你加载了一个数据页到缓存去，然后过了1s之后你还访问了这个缓存页，说明你后续很可能会经常要访问它，这个时间限制就是1s，因此只有1s后你访问了这个缓存页，他才会给你把缓存页放到热数据区域的链表头部去。



所以我们看下面的图，文字说明做了一点改动，是数据加载到缓存页之后过了1s，你再访问这个缓存页，他就会被放入热数据区域的链表头部，如果是你数据刚加载到缓存页，在1s内你就访问缓存页，此时他是不会把这个缓存页放入热数据区域的头部的。

   ![img](all_in_one.assets/0-165582864175578)       

**5、思考题**



今天给大家留一个思考题，大家思考一下，现在我们已经知道了，数据页第一次被加载到缓存页之后，这个缓存页是放在LRU链表的冷数据区域的头部的，然后必须是1s过后访问换个缓存页，他才会被移动到热数据区域的链表头部。



好，那么基于这套冷热数据隔离的方案，LRU链表的冷数据区域放的都是什么样的缓存页？这个问题有点像脑筋急转弯一样，大家脑子一转，就能思考出来了。



## 18 基于冷热数据分离方案优化后的LRU链表，是如何解决之前的问题的？

**1、对于预读以及全表扫描加载进来的一大堆缓存页**



现在我们已经看完了LRU链表的冷热数据分离的方案，那么我们接着看这个冷热数据分离之后的LRU链表，他是如何解决之前遇到的一大堆问题的？



首先我们思考一下，在这样的一个LRU链表方案下，预读机制以及全表扫描加载进来的一大堆缓存页，他们会放在哪里？



明显是放在LRU链表的冷数据区域的前面啊！



假设这个时候热数据区域已经有很多被频繁访问的缓存页了，你会发现热数据区域还是存放被频繁访问的缓存页的，只要热数据区域有缓存页被访问，他还是会被移动到热数据区域的链表头部去。



所以此时你看下图，你会发现，预读机制和全表扫描加载进来的一大堆缓存页，此时都在冷数据区域里，跟热数据区域里的频繁访问的缓存页，是没关系的！

​      ![img](all_in_one.assets/0-16558506601972) 

**2、预读机制和全表扫描加载进来的缓存页，能进热数据区域吗？**



接着我们看第二个问题，预读机制和全表扫描机制加载进来的缓存页，什么时候能进热数据区域呢？



如果你仅仅是一个全表扫描的查询，此时你肯定是在1s内就把一大堆缓存页加载进来，然后就访问了这些缓存页一下，通常这些操作1s内就结束了。



所以基于目前的一个机制，可以确定的是，这种情况下，那些缓存页是不会从冷数据区域转移到热数据区域的！



除非你在冷数据区域里的缓存页，在1s之后还被人访问了，那么此时他们就会判定为未来可能会被频繁访问的缓存页，然后移动到热数据区域的链表头部去！



**3、如果此时缓存页不够了，需要淘汰一些缓存，会怎么样？**

接着我们看，假设此时缓存页不够了，需要淘汰一些缓存页，此时会怎么做？



那就很简单了，直接就是可以找到LRU链表中的冷数据区域的尾部的缓存页，他们肯定是之前被加载进来的，而且加载进来1s过后都没人访问过，说明这个缓存页压根儿就没人愿意去访问他！他就是冷数据！



所以此时就直接淘汰冷数据区域的尾部的缓存页，刷入磁盘，就可以了，我们看下图。

![img](all_in_one.assets/0-16558506601931)      

**4、之前的一大堆问题解决了吗？**



在这样的一套缓存页分冷热数据的加载方案，以及冷数据转化为热数据的时间限制方案，还有就是淘汰缓存页的时候优先淘汰冷数据区域的方案，基于这套方案，大家会发现，之前发现的问题，完美的被解决了。



因为那种预读机制以及全表扫描机制加载进来的数据页，大部分都会在1s之内访问一下，之后可能就再也不访问了，所以这种缓存页基本上都会留在冷数据区域里。然后频繁访问的缓存页还是会留在热数据区域里。



当你要淘汰缓存的时候，优先就是会选择冷数据区域的尾部的缓存页，这就是非常合理的了！他不会让刚加载进来的缓存页占据LRU链表的头部，频繁访问的缓存页在LRU链表的尾部，淘汰的时候淘汰尾部的频繁访问的缓存页了！



问题完美的被解决了。



这就是LRU链表冷热数据分离的一套机制。



**5、总结**



通过这几篇文章的学习，我们已经彻底搞定了LRU链表的设计机制，刚加载数据的缓存页都是放冷数据区域的头部的，1s过后被访问了才会放热数据区域的头部，热数据区域的缓存页被访问了，就会自动放到头部去。



这样的话，实际上冷数据区域放的都是加载进来的缓存页，最多在1s内被访问过，之后就再也没访问过的冷数据缓存页！



而加载进来之后在1s过后还经常被访问的缓存页，都放在了热数据区域里，他们进行了冷热数据的隔离！



这样的话，在淘汰缓存的时候，一定是优先淘汰冷数据区域几乎不怎么被访问的缓存页的！也希望大家好好吸收这种冷热数据隔离的思想，尽可能让热数据和冷数据分开，避免冷数据影响热数据的访问！



**6、一个发散思考问题**



今天给大家留一个发散思考的问题，大家觉得对于这种缓存中同时包含冷热数据的场景，如果你是在Redis中放了你业务系统的很多缓存数据，其中也是冷热数据都有的，此时可能会有什么问题？



那么针对这样的一个问题，你是否可以考虑在你自己的缓存设计中，运用冷热隔离的思想来优化重构呢？



## 19 MySQL是如何将LRU链表的使用性能优化到极致的？

**1、昨日第一个思考题的解答**



昨天第一个思考题，我们是让大家思考一下，在LRU链表的冷数据区域中的都是什么样的数据呢？



其实大家脑筋一转就知道了，大部分应该都是预读加载进来的缓存页，加载进来1s之后都没人访问的，然后包括全表扫描或者一些大的查询语句，加载一堆数据到缓存页，结果都是1s之内访问了一下，后续就不再访问这些表的数据了。



类似这些数据，统统都会放在冷数据区域里。



**2、昨日第二个思考题的解答**



接着我们来说一下昨日第二个思考题的解答，昨天第二个思考题是让大家想了一下，对于我们开发的Java系统，如果在Redis里存放了很多缓存数据，那么此时会不会有类似冷热数据的问题？应该如何优化和解决呢？



**答案是：那必然是存在一些问题的。**



常见的一个场景就是电商系统里的商品缓存数据，假设你有1亿个商品，然后只要查询商品的时候发现商品不在缓存里，就给他放到缓存里去，你要这么搞的话，必然导致大量的不怎么经常访问的商品会被放在Redis缓存里！



经常被访问的商品其实就是热数据，不经常被访问的商品其实就是冷数据，我们应该尽量让Redis里放的都是经常访问的热数据，而不是大量的冷数据。因为你放一大堆不怎么经常访问的商品在Redis里，那么他占用了很多内存，而且后续还不怎么会访问到他们！



所以我们在设计缓存机制的时候，经常会考虑**热数据的缓存预加载**



也就是说，每天统计出来哪些商品被访问的次数最多，然后晚上的时候，系统启动一个定时作业，把这些热门商品的数据，预加载到Redis里。那么第二天是不是对热门商品的访问就自然会优先走Redis缓存了？



**3、LRU链表的热数据区域是如何进行优化的？**



接着我们来看看LRU链表的热数据区域的一个性能优化的点，就是说，在热数据区域中，如果你访问了一个缓存页，是不是应该要把他立马移动到热数据区域的链表头部去？



我们看下面的图示。

​      ![img](all_in_one.assets/0-16558507309167)       

但是你要知道，热数据区域里的缓存页可能是经常被访问的，所以这么频繁的进行移动是不是性能也并不是太好？也没这个必要。



所以说，LRU链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后3/4部分的缓存页被访问了，才会给你移动到链表头部去。



如果你是热数据区域的前面1/4的缓存页被访问，他是不会移动到链表头部去的。



举个例子，假设热数据区域的链表里有100个缓存页，那么排在前面的25个缓存页，他即使被访问了，也不会移动到链表头部去的。但是对于排在后面的75个缓存页，他只要被访问，就会移动到链表头部去。



这样的话，他就可以尽可能的减少链表中的节点移动了。



**4、一个脑筋急转弯的思考题**



今天给大家出一个脑筋急转弯的小思考题，大家看了以后都可以在评论区里回答一下，如果回答错误的同学，那真的得接受一点惩罚了！



这个问题就是：如果一个缓存页在冷数据区域的尾巴上，已经超过1s了，此时这个缓存页被访问了一下，那么他此时会移动到冷数据区域的链表头部吗？**注意，是冷数据区域的链表头部！**



## 20 对于LRU链表中尾部的缓存页，是如何淘汰他们刷入磁盘的？

**1、Buffer Pool的缓存页以及几个链表的使用回顾**



接着我们来讲讲，你的Buffer Pool在运行中被使用的时候，实际上会频繁的从磁盘上加载数据页到他的缓存页里去，然后free链表、flush链表、lru链表都会在使用的时候同时被使用



比如数据加载到一个缓存页，free链表里会移除这个缓存页，然后lru链表的冷数据区域的头部会放入这个缓存页。



然后如果你要是修改了一个缓存页，那么flush链表中会记录这个脏页，lru链表中还可能会把你从冷数据区域移动到热数据区域的头部去。



如果你是查询了一个缓存页，那么此时就会把这个缓存页在lru链表中移动到热数据区域去，或者在热数据区域中也有可能会移动到头部去。



总之，MySQL在执行CRUD的时候，首先就是大量的操作缓存页以及对应的几个链表。然后在缓存页都满的时候，必然要想办法把一些缓存页给刷入磁盘，然后清空这几个缓存页，接着把需要的数据页加载到缓存页里去！



我们已经知道，他是根据LRU链表去淘汰缓存页的，那么他到底是什么时候把LRU链表的冷数据区域中的缓存页刷入磁盘的呢？实际上他有几个时机。



**2、定时把LRU尾部的部分缓存页刷入磁盘**



首先第一个时机，并不是在缓存页满的时候，才会挑选LRU冷数据区域尾部的几个缓存页刷入磁盘，而是有一个后台线程，他会运行一个定时任务，这个定时任务每隔一段时间就会把LRU链表的冷数据区域的尾部的一些缓存页，刷入磁盘里去，清空这几个缓存页，把他们加入回free链表去！



所以实际上在缓存页没用完的时候，可能就会清空一些缓存页了，我们看下面的图示。

​      ![img](all_in_one.assets/0-165585080042410)

所以大家会发现，只要有这个后台线程定时运行，可能你的缓存页都没用完呢，人家就给你把一批冷数据的缓存页刷入磁盘，清空出来一批缓存页，那么你就多了一批可以使用的空闲缓存页了！



所以如果在一个动态的运行效果中思考，大概就是你不停的加载数据到一些空闲的缓存页里去，然后这些缓存页可能被使用，会在lru链表中各种移动。然后同时有一个后台线程还不停的把冷数据区域的一些不用的缓存页刷入磁盘中，清空一些缓存页出来。



只要有缓存页被刷人磁盘，大家可以想象一下，那么这个缓存页必然会加入到free链表中，从flush链表中移除，从lru链表中移除。



**3、把flush链表中的一些缓存页定时刷入磁盘**



如果仅仅是把LRU链表中的冷数据区域的缓存页刷入磁盘，大家觉得够吗？



明显不够啊，因为在lru链表的热数据区域里的很多缓存页可能也会被频繁的修改，难道他们永远都不刷入磁盘中了吗？



所以这个后台线程同时也会在MySQL不怎么繁忙的时候，找个时间把flush链表中的缓存页都刷入磁盘中，这样被你修改过的数据，迟早都会刷入磁盘的！



只要flush链表中的一波缓存页被刷入了磁盘，那么这些缓存页也会从flush链表和lru链表中移除，然后加入到free链表中去！



所以你可以理解为，你一边不停的加载数据到缓存页里去，不停的查询和修改缓存数据，然后free链表中的缓存页不停的在减少，flush链表中的缓存页不停的在增加，lru链表中的缓存页不停的在增加和移动。



另外一边，你的后台线程不停的在把lru链表的冷数据区域的缓存页以及flush链表的缓存页，刷入磁盘中来清空缓存页，然后flush链表和lru链表中的缓存页在减少，free链表中的缓存页在增加。



这就是一个动态运行起来的效果！



**4、实在没有空闲缓存页了怎么办？**



那么实在没有空闲缓存页了怎么办呢？



此时可能所有的free链表都被使用了，然后flush链表中有一大堆被修改过的缓存页，lru链表中有一大堆的缓存页，根据冷热数据进行了分离，大致是如此的效果。



这个时候如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从LRU链表的冷数据区域的尾部找到一个缓存页，他一定是最不经常使用的缓存页！然后把他刷入磁盘和清空，然后把数据页加载到这个腾出来的空闲缓存页里去！



这就是MySQL的Buffer Pool缓存机制的一整套运行原理！我们已经完整的讲完了缓存页的加载和使用，以及free链表、flush链表、lru链表是怎么使用的，包括缓存页是如何刷入磁盘腾出来空闲缓存页的，以及缓存页没有空闲的时候应该怎么处理。



大家首先理解了最近几篇文章之后，就应该完全理解了，MySQL在执行CRUD操作的时候，是如何尽可能基于内存中的缓存来处理的。



**5、今日思考题**



今天我们来给大家一个思考题，大家发现没有，如果你在执行CRUD的时候要从磁盘加载数据页到Buffer Pool的缓存页的时候，一旦此时没有空闲的缓存页，就必须从LRU链表的冷数据区域的尾部把一个缓存页刷入磁盘，然后腾出来一个空闲的缓存页，接着你才能基于缓存数据来执行这个CRUD的操作。



但是如果频繁的出现这样的一个情况，那你的很多CRUD执行的时候，难道都要先刷一个缓存页到磁盘上去？然后再从磁盘上读取一个数据页到空闲的缓存页里来？这样岂不是每次CRUD操作都要执行两次磁盘IO？那么性能岂不是会极差？



所以我们来思考一个问题：**你的MySQL的内核参数，应该如何优化，优化哪些地方的行为，才能够尽可能的避免在执行CRUD的时候，经常要先刷一个缓存页到磁盘上去，才能读取一个磁盘上的数据页到空闲缓存页里来？**



## 21 生产经验：如何通过多个Buffer Pool来优化数据库的并发性能？

**1、Buffer Pool在访问的时候需要加锁吗？**



前面我们已经把Buffer Pool的整体工作原理和设计原理都已经给大家分析的比较清楚了，基本上目前大家都能够很好的理解，我们对MySQL执行CRUD操作时候的第一步，就是利用Buffer Pool里的缓存来更新或者查询。



那么既然已经把Buffer Pool的原理都讲的差不多了，接着我们就可以来给大家说说Buffer Pool在实际生产环境运行中的一些经验，应该如何对Buffer Pool进行一些配置上的优化，来提升他的访问性能呢？



首先我们来看第一个问题，大家都知道，Buffer Pool其实本质就是一大块内存数据结构，由一大堆的缓存页和描述数据块组成的，然后加上了各种链表（free、flush、lru）来辅助他的运行。



好，那么这个时候假设MySQL同时接收到了多个请求，他自然会用多个线程来处理这多个请求，每个线程会负责处理一个请求，对吧？



然后这多个线程是不是应该会同时去访问Buffer Pool呢？就是同时去操作里面的缓存页，同时操作一个free链表、flush链表、lru链表，是吗？



我们看下图，就是一个多线程并发访问Buffer Pool的示意图。

​      ![img](all_in_one.assets/0-165585104542113)

那么大家思考一下，现在多个线程来并发的访问这个Buffer Pool了，此时他们都是在访问内存里的一些共享的数据结构，比如说缓存页、各种链表之类的，那么此时是不是必然要进行加锁？



对，多线程并发访问一个Buffer Pool，必然是要加锁的，然后让一个线程先完成一系列的操作，比如说加载数据页到缓存页，更新free链表，更新lru链表，然后释放锁，接着下一个线程再执行一系列的操作。



**2、多线程并发访问加锁，数据库的性能还能好吗？**



既然我们已经解决了第一个问题，就是多线程并发访问一个Buffer Pool的时候必然会加锁，然后很多线程可能要串行着排队，一个一个的依次执行自己要执行的操作，那么此时我问大家第二个问题，此时数据库的性能还能好吗？



应该这么说，即使就一个Buffer Pool，即使多个线程会加锁串行着排队执行，其实性能也差不到哪儿去。



因为大部分情况下，每个线程都是查询或者更新缓存页里的数据，这个操作是发生在内存里的，基本都是微秒级的，很快很快，包括更新free、flush、lru这些链表，他因为都是基于链表进行一些指针操作，性能也是极高的。



所以即使每个线程排队加锁，然后执行一系列操作，数据库的性能倒也是还可以的。



但是再怎么可以，你毕竟也是每个线程加锁然后排队一个一个操作，这也不是特别的好，特别是有的时候你的线程拿到锁之后，他可能要从磁盘里读取数据页加载到缓存页里去，这还发生了一次磁盘IO呢！所以他要是进行磁盘IO的话，也许耗时就会多一些，那么后面排队等他的线程自然就多等一会儿了！



**3、MySQL的生产优化经验：多个Buffer Pool优化并发能力**



因此这里我们给大家介绍一个MySQL的生产环境优化经验，就是可以给MySQL设置多个Buffer Pool来优化他的并发能力。



一般来说，MySQL默认的规则是，如果你给Buffer Pool分配的内存小于1GB，那么最多就只会给你一个Buffer Pool。



但是如果你的机器内存很大，那么你必然会给Buffer Pool分配较大的内存，比如给他个8G内存，那么此时你是同时可以设置多个Buffer Pool的，比如说下面的MySQL服务器端的配置。



[server]

innodb_buffer_pool_size = 8589934592

innodb_buffer_pool_instances = 4



我们给buffer pool设置了8GB的总内存，然后设置了他应该有4个Buffer Pool，此时就是说，每个buffer pool的大小就是2GB



这个时候，MySQL在运行的时候就会有4个Buffer Pool了！每个Buffer Pool负责管理一部分的缓存页和描述数据块，有自己独立的free、flush、lru等链表。



这个时候，假设多个线程并发过来访问，那么不就可以把压力分散开来了吗？有的线程访问这个buffer pool，有的线程访问那个buffer pool。



我们看下图：

​      ![img](all_in_one.assets/0-165585104542214)   

所以这样的话，一旦你有了多个buffer pool之后，你的多线程并发访问的性能就会得到成倍的提升，因为多个线程可以在不同的buffer pool中加锁和执行自己的操作，大家可以并发来执行了！



所以这个在实际生产环境中，设置多个buffer pool来优化高并发访问性能，是mysql一个很重要的优化技巧。



## 22 生产经验：如何通过chunk来支持数据库运行期间的Buffer Pool动态调整？

**1、buffer pool这种大块头，能在运行期间动态调整大小吗？**



上一篇文章给大家分析了一下buffer pool在多线程并发访问的时候的一些问题，以及通过多个buffer pool是如何优化多线程并发访问性能的。



那么这一篇文章我们接着分析下一个问题，那就是buffer pool这种大块头数据结构，在数据库运行期间，可以动态的调整他的大小吗？



其实如果就我们讲的这套原理的话，buffer pool在运行期间是不能动态的调整自己的大小的



为什么呢？因为动态调整buffer pool大小，比如buffer pool本来是8G，运行期间你给调整为16G了，此时是怎么实现的呢？



就是需要这个时候向操作系统申请一块新的16GB的连续内存，然后把现在的buffer pool中的所有缓存页、描述数据块、各种链表，都拷贝到新的16GB的内存中去。这个过程是极为耗时的，性能很低下，是不可以接受的！



所以就目前讲解的这套原理，buffer pool是绝对不能支持运行期间动态调整大小的。



**2、如何基于chunk机制把buffer pool给拆小呢？**



但是MySQL自然会想办法去做一些优化的，他实际上设计了一个chunk机制，也就是说buffer pool是由很多chunk组成的，他的大小是innodb_buffer_pool_chunk_size参数控制的，默认值就是128MB。



所以实际上我们可以来做一个假设，比如现在我们给buffer pool设置一个总大小是8GB，然后有4个buffer pool，那么每个buffer pool就是2GB，此时每个buffer pool是由一系列的128MB的chunk组成的，也就是说每个buffer pool会有16个chunk。



然后每个buffer pool里的每个chunk里就是一系列的描述数据块和缓存页，每个buffer pool里的多个chunk共享一套free、flush、lru这些链表，此时的话，看起来可能大致如下图所示。

![img](all_in_one.assets/0-165585107793419)

在上面的图里，可以清晰的看到，每个buffer pool里已经有了多个chunk，每个chunk就是一系列的描述数据块和缓存页，这样的话，就是把buffer pool按照chunk为单位，拆分为了一系列的小数据块，但是每个buffer pool是共用一套free、flush、lru的链表的。



**3、基于chunk机制是如何支持运行期间，动态调整buffer pool大小的？**



那么现在有了上面讲的这套chunk机制，就可以支持动态调整buffer pool大小了。



比如我们buffer pool现在总大小是8GB，现在要动态加到16GB，那么此时只要申请一系列的128MB大小的chunk就可以了，只要每个chunk是连续的128MB内存就行了。然后把这些申请到的chunk内存分配给buffer pool就行了。



有个这个chunk机制，此时并不需要额外申请16GB的连续内存空间，然后还要把已有的数据进行拷贝。



给大家讲解这个chunk机制，倒不是让大家在数据库运行的时候动态调整buffer pool大小，其实这不是重点，重点是大家要了解数据库的buffer pool的真实的数据结构，是可以由多个buffer pool组成的，每个buffer pool是多个chunk组成的，然后你只要知道他运行期间可以支持动态调整大小就可以了。



**4、昨日思考题解答**



现在我们来解答一下昨天的思考题，昨天让大家思考了一下，到底如何避免你执行crud的时候，频繁的发现缓存页都用完了，完了还得先把一个缓存页刷入磁盘腾出一个空闲缓存页，然后才能从磁盘读取一个自己需要的数据页到缓存页里来。



如果频繁这么搞，那么很多crud操作，每次都要执行两次磁盘IO，一次是缓存页刷入磁盘，一次是数据页从磁盘里读取出来，性能是很不高的。



其实结合我们了解到的buffer pool的运行原理就可以知道，如果要避免上述问题，说白了就是避免缓存页频繁的被使用完毕。那么我们知道实际上你在使用缓存页的过程中，有一个后台线程会定时把LRU链表冷数据区域的一些缓存页刷入磁盘中。



所以本质上缓存页一边会被你使用，一边会被后台线程定时的释放掉一批。



所以如果你的缓存页使用的很快，然后后台线程释放缓存页的速度很慢，那么必然导致你频繁发现缓存页被使用完了。但是缓存页被使用的速度你是没法控制的，因为那是由你的Java系统访问数据库的并发程度来决定的，你高并发访问数据库，缓存页必然使用的很快了！



然后你后台线程定时释放一批缓存页，这个过程也很难去优化，因为你要是释放的过于频繁了，那么后台线程执行磁盘IO过于频繁，也会影响数据库的性能。



所以这里的关键点就在于，你的buffer pool有多大！



如果你的数据库要抗高并发的访问，那么你的机器必然要配置很大的内存空间，起码是32GB以上的，甚至64GB或者128GB。此时你就可以给你的buffer pool设置很大的内存空间，比如20GB，48GB，甚至80GB。



这样的话，你会发现高并发场景下，数据库的buffer pool缓存页频繁的被使用，但是你后台线程也在定时释放一些缓存页，那么综合下来，空闲的缓存页还是会以一定的速率逐步逐步的减少。



因为你的buffer pool内存很大，所以空闲缓存页是很多很多的，即使你的空闲缓存页逐步的减少，也可能需要较长时间才会发现缓存页用完了，此时才会出现一次crud操作执行的时候，先刷缓存页到磁盘，再读取数据页到缓存页来，这种情况是不会出现的太频繁的！



而一旦你的数据库高峰过去，此时缓存页被使用的速率下降了很多很多，然后后台线程会定是基于flush链表和lru链表不停的释放缓存页，那么你的空闲缓存页的数量又会在数据库低峰的时候慢慢的增加了。



所以线上的MySQL在生产环境中，buffer pool的大小、buffer pool的数量，这都是要用心设置和优化的，因为对MySQL的性能和并发能力，都会有较大的影响。



**5、实践思考题**



请每位同学，去看看自己负责的系统的buffer pool大小、buffer pool数量、chunk大小，然后看看自己的数据库的机器配置，思考一下，当前设置是否合理？为什么要这样设置？



## 23 生产经验：在生产环境中，如何基于机器配置来合理设置Buffer Pool？

**1、生产环境中应该给buffer pool设置多少内存？**



今天这篇文章我们接着上一次讲解的Buffer Pool的一些内存划分的原理，来给大家最后总结一下，在生产环境中到底应该如何设置Buffer Pool的大小呢。



首先考虑第一个问题，我们现在数据库部署在一台机器上，这台机器可能有个8G、16G、32G、64G、128G的内存大小，那么此时buffer pool应该设置多大呢？



有的人可能会想，假设我有32G内存，那么给buffer pool设置个30GB得了，这样的话，MySQL大量的crud操作都是基于内存来执行的，性能那是绝对高！



但是这么想就大错特错了，你要知道，虽然你的机器有32GB的内存，但是你的操作系统内核就要用掉起码几个GB的内存！



然后你的机器上可能还有别的东西在运行，是不是也要内存？然后你的数据库里除了buffer pool是不是还有别的内存数据结构，是不是也要内存？所以上面那种想法是绝对不可取的！



如果你胡乱设置一个特别大的内存给buffer，会导致你的mysql启动失败的，他启动的时候就发现操作系统的内存根本不够用了！



所以通常来说，我们建议一个比较合理的、健康的比例，是给buffer pool设置你的机器内存的50%~60%左右



比如你有32GB的机器，那么给buffer设置个20GB的内存，剩下的留给OS和其他人来用，这样比较合理一些。



假设你的机器是128GB的内存，那么buffer pool可以设置个80GB左右，大概就是这样的一个规则。



**2、buffer pool总大小=(chunk大小 \* buffer pool数量)的2倍数**



接着确定了buffer pool的总大小之后，就得考虑一下设置多少个buffer pool，以及chunk的大小了



此时要记住，有一个很关键的公式就是：buffer pool总大小=(chunk大小 * buffer pool数量)的倍数



比如默认的chunk大小是128MB，那么此时如果你的机器的内存是32GB，你打算给buffer pool总大小在20GB左右，那么你得算一下，此时你的buffer pool的数量应该是多少个呢？



假设你的buffer pool的数量是16个，这是没问题的，那么此时chunk大小 * buffer pool的数量 = 16 * 128MB = 2048MB，然后buffer pool总大小如果是20GB，此时buffer pool总大小就是2048MB的10倍，这就符合规则了。



当然，此时你可以设置多一些buffer pool数量，比如设置32个buffer pool，那么此时buffer pool总大小（20GB）就是（chunk大小128MB * 32个buffer pool）的5倍，也是可以的。



那么此时你的buffer pool大小就是20GB，然后buffer pool数量是32个，每个buffer pool的大小是640MB，然后每个buffer pool包含5个128MB的chunk，算下来就是这么一个结果了。



**3、一点总结**



我们再来做一点总结，就是说你的数据库在生产环境运行的时候，你必须根据机器的内存设置合理的buffer pool的大小，然后设置buffer pool的数量，这样的话，可以尽可能的保证你的数据库的高性能和高并发能力。



然后在线上运行的时候，buffer pool是有多个的，每个buffer pool里多个chunk但是共用一套链表数据结构，然后执行crud的时候，就会不停的加载磁盘上的数据页到缓存页里来，然后会查询和更新缓存页里的数据，同时维护一系列的链表结构。



然后后台线程定时根据lru链表和flush链表，去把一批缓存页刷入磁盘释放掉这些缓存页，同时更新free链表。



如果执行crud的时候发现缓存页都满了，没法加载自己需要的数据页进缓存，此时就会把lru链表冷数据区域的缓存页刷入磁盘，然后加载自己需要的数据页进来。



整个buffer pool的结构设计以及工作原理，就是上面我们总结的这套东西了，大家只要理解了这个，首先你对MySQL执行crud的时候，是如何在内存里查询和更新数据的，你就彻底明白了。



接着我们后面继续探索undo log、redo log、事务机制、事务隔离、锁机制，这些东西，一点点就把MySQL他的数据更新、事务、锁这些原理，全部搞清楚了，同时中间再配合穿插一些生产经验、实战案例。



**4、SHOW ENGINE INNODB STATUS**



当你的数据库启动之后，你随时可以通过上述命令，去查看当前innodb里的一些具体情况，执行SHOW ENGINE INNODB STATUS就可以了。此时你可能会看到如下一系列的东西：



Total memory allocated xxxx;

Dictionary memory allocated xxx

Buffer pool size  xxxx

Free buffers    xxx

Database pages   xxx

Old database pages xxxx

Modified db pages  xx

Pending reads 0

Pending writes: LRU 0, flush list 0, single page 0

Pages made young xxxx, not young xxx

xx youngs/s, xx non-youngs/s

Pages read xxxx, created xxx, written xxx

xx reads/s, xx creates/s, 1xx writes/s

Buffer pool hit rate xxx / 1000, young-making rate xxx / 1000 not xx / 1000

Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s

LRU len: xxxx, unzip_LRU len: xxx

I/O sum[xxx]:cur[xx], unzip sum[16xx:cur[0]



下面我们给大家解释一下这里的东西，主要讲解这里跟buffer pool相关的一些东西。



（1）Total memory allocated，这就是说buffer pool最终的总大小是多少

（2）Buffer pool size，这就是说buffer pool一共能容纳多少个缓存页

（3）Free buffers，这就是说free链表中一共有多少个空闲的缓存页是可用的

（4）Database pages和Old database pages，就是说lru链表中一共有多少个缓存页，以及冷数据区域里的缓存页数量

（5）Modified db pages，这就是flush链表中的缓存页数量

（6）Pending reads和Pending writes，等待从磁盘上加载进缓存页的数量，还有就是即将从lru链表中刷入磁盘的数量、即将从flush链表中刷入磁盘的数量

（7）Pages made young和not young，这就是说已经lru冷数据区域里访问之后转移到热数据区域的缓存页的数量，以及在lru冷数据区域里1s内被访问了没进入热数据区域的缓存页的数量

（8）youngs/s和not youngs/s，这就是说每秒从冷数据区域进入热数据区域的缓存页的数量，以及每秒在冷数据区域里被访问了但是不能进入热数据区域的缓存页的数量

（9）Pages read xxxx, created xxx, written xxx，xx reads/s, xx creates/s, 1xx writes/s，这里就是说已经读取、创建和写入了多少个缓存页，以及每秒钟读取、创建和写入的缓存页数量

（10）Buffer pool hit rate xxx / 1000，这就是说每1000次访问，有多少次是直接命中了buffer pool里的缓存的

（11）young-making rate xxx / 1000 not xx / 1000，每1000次访问，有多少次访问让缓存页从冷数据区域移动到了热数据区域，以及没移动的缓存页数量

（12）LRU len：这就是lru链表里的缓存页的数量

（13）I/O sum：最近50s读取磁盘页的总数

（14）I/O cur：现在正在读取磁盘页的数量



**5、今日实践思考题**



今天留给大家的作业，就是每个人都对自己线上在运行的数据库执行上述命令，然后分析一下数据库的buffer pool的使用情况



这里要尤为关注的是free、lru、flush几个链表的数量的情况，然后就是lru链表的冷热数据转移的情况，然后你的缓存页的读写情况，这些代表了你当前buffer  pool的使用情况。



最关键的是两个东西，一个是你的buffer pool的千次访问缓存命中率，这个命中率越高，说明你大量的操作都是直接基于缓存来执行的，性能越高。



第二个是你的磁盘IO的情况，这个磁盘IO越多，说明你数据库性能越差。



## 24 我们写入数据库的一行数据，在磁盘上是怎么存储的？

**1、承上启下：在Buffer Pool之后，为什么要学习MySQL物理数据模型？**



之前的一些文章我们已经深入的给大家分析了当你执行crud操作的时候，MySQL是如何把磁盘上的数据页加载到内存中的Buffer Pool的缓存页里去的，以及对Buffer Pool是如何进行一整套复杂的管理机制的。



相信现在每个人都对缓存页加载到Buffer Pool中，更新和读取缓存页里的数据，这个过程中的free链表、flush链表以及lru链表的维护，都有了一个深刻的理解，包括后台线程是如何定时根据flush链表以及lru链表将部分被更新的缓存页刷入磁盘的，以及缓存页都用完了以后是如何根据lru链表将一些冷数据缓存页刷入磁盘的。



按理来说，在讲解完上述内容之后，我们下一步就应该是要给大家讲解undo log和redo log以及事务机制了，但是现在还不行，实际上我们在理解了MySQL中的数据缓存机制以及内存数据更新机制，包括缓存到磁盘的数据刷新机制之后，我们还得来理解一下MySQL中的物理数据结构。



之前很多朋友可能会发现我在文章里提到了表空间、区、数据页、一个区中的连续数据页、表空间号以及数据页号，这些概念，这些概念，我们之前即使不理解，其实也不妨碍我们去理解MySQL的Buffer Pool缓存机制。



因为大家之前可能脑子里大致都有一个概念，就是数据页这个概念，起码知道每一行数据都是放在数据页里的，我们是按照数据页为单位把磁盘上的数据加载到内存的缓存页里来，也是按照页为单位，把缓存页的数据刷入磁盘上的数据页中。



但是我之前也问过大家，我们平时写SQL语句的时候脑子里都有一个表、行和字段的概念，但是为什么跑到MySQL内部，就出现了一堆表空间、数据区、数据页这些概念呢？



其实很多人都说了，表、行和字段是逻辑上的概念，而表空间、数据区和数据页其实已经落实到物理上的概念了。



实际上表空间、数据页这些东西，都对应到了MySQL在磁盘上的一些物理文件了。



所以接下来，我们要用一些文章来逐步逐步的讲解MySQL的表空间、数据区、数据页、磁盘上的物理文件这些概念。当大家看明白这些东西之后，你就会理解，当我们执行SQL语句的时候，是从MySQL机器上的哪些磁盘文件里加载数据页到缓存页里来的，数据页是如何由数据区这个概念来组织起来的，表空间这个概念是怎么回事



很多朋友之前还在评论区提问，你一个SQL语句仅仅指定了你要查询或者更新哪个表的哪些数据，那你怎么知道这些数据在哪个表空间里？在哪个数据区里？在哪些数据页里？对应是在MySQL机器上的哪些磁盘文件里呢？



当我们学习完接下来的一部分内容后，上述问题的答案都会迎刃而解。



**2、之前遗留思考题解答：为什么不能直接更新磁盘上的数据？**



之前我们留过一个思考题，让大家思考一下，为什么MySQL要设计这么一套复杂的数据存取机制，要基于内存、日志、磁盘上的数据文件来完成数据的读写呢？为什么对insert、update请求，不直接更新磁盘文件里的数据呢？



很多人都在评论区给出了自己的思考和回答，我觉得每个人的思考都特别的好，大家可以多去评论区里看看别人的思考以及进行交流。



这里我简单一句话总结，为什么不能直接更新磁盘上的数据，因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据，虽然技术上是可以做到的，但是那必然导致执行请求的性能极差。



因为磁盘随机读写的性能是最差的，所以直接更新磁盘文件，必然导致我们的数据库完全无法抗下任何一点点稍微高并发一点的场景。



所以MySQL才设计了如此复杂的一套机制，通过内存里更新数据，然后写redo log以及事务提交，后台线程不定时刷新内存里的数据到磁盘文件里



通过这种方式保证，你每个更新请求，尽量就是更新内存，然后顺序写日志文件。



更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是比较高的，因为顺序写磁盘文件，他的性能要远高于随机读写磁盘文件。



也正是通过这套机制，才能让我们的MySQL数据库在较高配置的机器上，每秒可以抗下几千的读写请求。



**3、复习巩固：MySQL为什么要引入数据页这个概念？**



首先我们先考虑一下，刚才是不是已经给大家讲过，当我们要执行update之类的SQL语句的时候，必然涉及到对数据的更新操作？那么此时对数据是在哪里更新的？



此时并不是直接去更新磁盘文件，而是要把磁盘上的一些数据加载到内存里来，然后对内存里的数据进行更新，同时写redo log到磁盘上去，我们看下图回忆一下。

​      ![img](all_in_one.assets/0-165585209323122)     

但是这里就有一个问题了，难道我们每次都是把磁盘里的一条数据加载到内存里去进行更新，然后下次要更新别的数据的时候，再从磁盘里加载另外一条数据到内存里去？



这样每次都是一条数据一条数据的加载到内存里去更新，大家觉得效率高吗？



很明显是不高的



所以innodb存储引擎在这里引入了一个**数据页**的概念，也就是把数据组织成一页一页的概念，每一页有16kb，然后每次加载磁盘的数据到内存里的时候，是至少加载一页数据进去，甚至是多页数据进去，我们看下图

​      ![img](all_in_one.assets/0-165585209323223)       

假设我们有一次要更新一条id=1的数据：



update xxx set xxx=xxx where id=1



那么此时他会把id=1这条数据所在的一页数据都加载到内存里去，这一页数据里，可能还包含了id=2，id=3等其他数据。



然后我们更新完id=1的数据之后，接着更新id=2的数据，那么此时是不是就不用再次读取磁盘里的数据了？



因为id=2本身就跟id=1在一页里，之前这一页数据就加载到内存里去了，你直接更新内存里的数据页中的id=2这条数据就可以了。



我们看下图，这就是数据页的意义，磁盘和内存之间的数据交换通过数据页来执行，包括内存里更新后的脏数据，刷回磁盘的时候，也是至少一个数据页刷回去。

​      ![img](all_in_one.assets/0-165585209323224)       

我们再看下图，要明白的一点是，我们不是一直在内存里更新各种数据吗？当IO线程把内存里的脏数据刷到磁盘上去的时候，也是以数据页为单位来刷回去的



下图中有这个刷数据的图示：

​      ![img](all_in_one.assets/0-165585209323225)       

**4、初涉MySQL物理数据存储格式：一行数据在磁盘上是如何存储的？**



那么接着我们可以来思考一下，对数据页中的每一行数据，他在磁盘上是怎么存储的？



其实这里涉及到一个概念，就是行格式。我们可以对一个表指定他的行存储的格式是什么样的，比如我们这里用一个COMPACT格式。



CREATE TABLE table_name (columns) ROW_FORMAT=COMPACT

ALTER TABLE table_name ROW_FORMAT=COMPACT



你可以在建表的时候，就指定一个行存储的格式，也可以后续修改行存储的格式。这里指定了一个COMPACT行存储格式，在这种格式下，每一行数据他实际存储的时候，大概格式类似下面这样：



变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......



对于每一行数据，他其实存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上他这一行数据每一列的具体的值，这就是所谓的行格式。除了COMPACT以外，还有其他几种行存储格式，基本都大同小异。



大家可能对一行数据实际存储的时候，他里面的一些东西到底都是什么含义，感觉都很好奇，大可不必着急，我们明天的文章会继续讲解的。



**5、今天学习的要点总结**



今天我们主要是做了一些承上启下的复习和巩固，告诉了大家innodb存储引擎在存储数据的时候，是通过数据页的方式来组织数据的。



然后我们初步的开始尝试切入了MySQL的物理数据存储格式，讲解了对于数据页中的每一行数据，其实他都有对应的行格式。



## 25 对于VARCHAR这种变长字段，在磁盘上到底是如何存储的？

**1、一行数据在磁盘上存储的时候，包含哪些东西？**



上一讲我们已经告诉了大家，一行数据在磁盘上存储的时候，其实不仅仅是包含我们想象的那一点数据，他还包含了很多其他的信息，之前告诉大家，一行数据的存储格式大致如下所示。



变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......



说白了，就是除了每一个字段的值以外，他还包含了一些额外的信息，这些额外的信息就是用来描述这一行数据的。今天我们就详细给大家说说这些额外的信息里都是放了什么东西。



**2、变长字段在磁盘中是怎么存储的？**



大家都知道，在MySQL里有一些字段的长度是变长的，是不固定的，比如VARCHAR(10)之类的这种类型的字段，实际上他里面存放的字符串的长度是不固定的，有可能是“hello”这么一个字符串，也可能是“a”这么一个字符串。



好，那么现在我们来假设一下，现在有一行数据，他的几个字段的类型为VRACHAR(10)，CHAR(1)，CHAR(1)，那么他第一个字段是VARCHAR(10)，这个长度是可能变化的，所以这一行数据可能就是类似于：hello a a，这样子，第一个字段的值是“hello”，后面两个字段的值都是一个字符，就是一个a



然后另外一行数据，同样也是这几个字段，他的第一个字段的值可能是“hi”，后面两个字段也是“a”，所以这一行数据可能是类似于：hi a a。一共三个字段，第一个字段的长度是是不固定的，后面两个字段的长度都是固定的1个字符。



想必这个道理大家都能理解吧？



那么现在，我们来假设你把上述两条数据写入了一个磁盘文件里，两行数据是挨在一起的，那么这个时候在一个磁盘文件里可能有下面的两行数据：



hello a a hi a a



大家可以看到，两行数据在底层磁盘文件里是不是挨着存储的？



没错！其实平时你看到的表里的很多行数据，最终落地到磁盘里的时候，都是上面那种样子的，一大坨数据放在一个磁盘文件里都挨着存储的。



**3、存储在磁盘文件里的变长字段，为什么难以读取？**



现在我们来继续思考一个问题，假设现在我们要读取上面的磁盘文件里的数据，要读取出来hello a a这一行数据。那你觉得是那么容易的吗？



当然不是了！这个过程比你想象的可能要困难一些。



假如现在你要读取hello a a这行数据，第一个问题就是，从这个磁盘文件里读取的时候，到底哪些内容是一行数据？我不知道啊！



因为这个表里的第一个字段是VARCHAR(10)类型的，第一个字段的长度是多少我们是不知道的！



所以有可能你读取出来“hello a a hi”是一行数据，也可能是你读取出来“hello a”是一行数据，你在不知道一行数据的每个字段到底是多少长度的情况下，胡乱的去读取是不现实的，根本不知道磁盘文件里混成一坨的数据里，哪些数据是你要读取的一行？



**4、引入变长字段的长度列表，解决一行数据的读取问题**



所以说才要在存储每一行数据的时候，都保存一下他的变长字段的长度列表，这样才能解决一行数据的读取问题。



也就是说，你在存储“hello a a”这行数据的时候，要带上一些额外的附加信息，比如第一块就是他里面的变长字段的长度列表



也就是说，这个hello是VARCHAR(10)类型的变长字段的值，那么这个“hello”字段值的长度到底是多少？



我们看到“hello”的长度是5，十六进制就是0x05，所以此时会在“hello a a”前面补充一些额外信息，首先就是变长字段的长度列表，你会看到这行数据在磁盘文件里存储的时候，其实是类似如下的格式：0x05 null值列表 数据头 hello a a。



你这行数据存储的时候应该是如上所示的！



这个时候假设你有两行数据，还有一行数据可能就是：0x02 null值列表 数据头 hi a a，两行数据放在一起存储在磁盘文件里，看起来是如下所示的：



0x05 null值列表 数据头 hello a a 0x02 null值列表 数据头 hi a a



**5、引入变长字段长度列表后，如何解决变长字段的读取问题？**



所以假设此时你要读取“hello a a”这行数据，你首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1) CHAR(1)，那么此时你先要读取第一个字段的值，那么第一个字段是变长的，到底他的实际长度是多少呢？



此时你会发现第一行数据的开头有一个变长字段的长度列表，里面会读取到一个0x05这个十六进制的数字，发现第一个变长字段的长度是5，于是按照长度为5，读取出来第一个字段的值，就是“hello”



接着你知道后续两个字段都是CHAR(1)，长度都是固定的1个字符，于是此时就依次按照长度为1读取出来后续两个字段的值，分别是“a”“a”，于是最终你会读取出来“hello a a”这一行数据！



接着假设你要读取第二行数据，你先看一下第二行数据后的变长字段长度列表，发现他第一个变长字段的长度是0x02，于是就读取长度为2的字段值，就是“hi”，再读取两个长度固定为1的字符值，都是“a”，此时读取出来“hi a a”这行数据。



**6、如果有多个变长字段，如何存放他们的长度？**



接着我们假设，如果说有多个变长字段，如何存放他们的长度？



比如一行数据有VARCHAR(10) VARCHAR(5) VARCHAR(20) CHAR(1) CHAR(1)，一共5个字段，其中三个是变长字段，此时假设一行数据是这样的：hello hi hao a a



此时在磁盘中存储的，必须在他开头的变长字段长度列表中存储几个变长字段的长度，一定要注意一点，他这里是逆序存储的！



也就是说先存放VARCHAR(20)这个字段的长度，然后存放VARCHAR(5)这个字段的长度，最后存放VARCHAR(10)这个字段的长度。



现在hello hi hao三个字段的长度分别是0x05 0x02 0x03，但是实际存放在变长字段长度列表的时候，是逆序放的，所以一行数据实际存储可能是下面这样的：



0x03 0x02 0x05 null值列表 头字段 hello hi hao a a



**7、今日思考题**



今天让大家思考一个问题，为什么MySQL在把一行一行的数据存储在磁盘上的时候，要采取这种“0x05 null值列表 数据头 hello a a 0x02 null值列表 数据头 hi a a”很多行数据都紧紧挨在一起的方式？



为什么MySQL不能用Java里面的序列化的那种方式？把很多行的数据做成一个大的对象，然后给他序列化一下写入到磁盘文件里，从磁盘里读取的时候压根儿不用care什么行存储格式，直接反序列化一下，把数据就可以从磁盘文件里拿回来了。



## 26 一行数据中的多个NULL字段值在磁盘上怎么存储？

**1、为什么一行数据里的NULL值不能直接存储？**



之前我们已经给大家讲了在数据库里一行数据中如果有VARCHAR(10)之类的变长字段，那么他的存储和读取会有什么问题，以及为了解决这个问题，为什么要给磁盘上存储的每一行数据都加入变长字段长度列表。



今天我们继续给大家讲解在磁盘上存储的一行数据里另外一块特殊的数据区域，就是NULL值列表。



这个所谓的NULL值列表，顾名思义，说的就是你一行数据里可能有的字段值是NULL，比如你有一个name字段，他是允许为NULL的，那么实际上在存储的时候，如果你没给他赋值，他这个字段的值就是NULL。



好，那么假设这个字段的NULL值我们在磁盘上存储的时候，就是按照“NULL”这么个字符串来存储，是不是很浪费存储空间？



本来他就是个NULL，说明什么值都没有，你还给他存个“NULL”字符串，你说你这是干什么呢？



所以实际在磁盘上存储数据的时候，一行数据里的NULL值是肯定不会直接按照字符串的方式存放在磁盘上浪费空间的。



**2、NULL值是以二进制bit位来存储的**



我们接着看，那么NULL值列表在磁盘上到底应该如何存储呢？



很简单，对所有的NULL值，不通过字符串在磁盘上存储，而是通过二进制的bit位来存储，一行数据里假设有多个字段的值都是NULL，那么这多个字段的NULL，就会以bit位的形式存放在NULL值列表中。



现在我们来给大家举个例子，假设你有一张表，他的建表语句如下所示：



CREATE TABLE customer (

​		name VARCHAR(10) NOT NULL,

​		address VARCHAR(20),

​		gender CHAR(1),

​		job VARCHAR(30),

​		school VARCHAR(50)

) ROW_FORMAT=COMPACT;



上面那个表就是一个假想出来的客户表，里面有5个字段，分别为name、address、genderjob、school，就代表了客户的姓名、地址、性别、工作以及学校。



其中有4个变长字段，还有一个定长字段，然后第一个name字段是声明了NOT NULL的，就是不能为NULL，其他4个字段都可能是NULL的。



那么现在我们来假设这个表里有如下一行数据，现在来看看，他在磁盘上是怎么来存储的：“jack NULL m NULL xx_school”，他的5个字段里有两个字段都是NULL





**3、结合小小案例来思考一行数据的磁盘存储格式**



接着我们来思考上面那个表里的那行案例数据，在磁盘上应该如何存储呢，因为他有多个变长字段，还有多个字段允许为NULL。首先我们先回顾一下，一行数据在磁盘上的存储格式应该是下面这样的：



变长字段长度列表 NULL值列表 头信息 column1=value1 column2=value2 ... columnN=valueN



所以先看变长字段长度列表应该放什么东西，他一共有4个变长字段，那么按照我们上次说的，是不是应该按照逆序的顺序，先放school字段的长度，再放job、address、name几个字段的值长度？



说起来是这样，但是其实这里要区分一个问题，那就是如果这个变长字段的值是NULL，就不用在变长字段长度列表里存放他的值长度了，所以在上面那行数据中，只有name和school两个变长字段是有值的，把他们的长度按照逆序放在变长字段长度列表中就可以了，如下所示：



0x09 0x04 NULL值列表 头信息 column1=value1 column2=value2 ... columnN=valueN



接着来看NULL值列表，这个NULL值列表是这样存放的，你所有允许值为NULL的字段，注意，是允许值为NULL，不是说一定值就是NULL了，只要是允许你为NULL的字段，在这里每个字段都有一个二进制bit位的值，如果bit值是1说明是NULL，如果bit值是0说明不是NULL。



比如上面4个字段都允许为NULL，每个人都会有一个bit位，这一行数据的值是“jack NULL m NULL xx_school”，然后其中2个字段是null，2个字段不是null，所以4个bit位应该是：1010



但是实际放在NULL值列表的时候，他是按逆序放的，所以在NULL值列表里，放的是：0101，整体这一行数据看着是下面这样的



0x09 0x04 0101 头信息 column1=value1 column2=value2 ... columnN=valueN



另外就是他实际NULL值列表存放的时候，不会说仅仅是4个bit位，他一般起码是8个bit位的倍数，如果不足8个bit位就高位补0，所以实际存放看起来是如下的：



0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN



**4、磁盘上的一行数据到底如何读取出来的？**



我们结合上面的磁盘上的数据存储格式来思考一下，一行数据到底是如何读取出来的呢？



再看上面的磁盘数据存储格式：



0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN



首先他必然要把变长字段长度列表和NULL值列表读取出来，通过综合分析一下，就知道有几个变长字段，哪几个变长字段是NULL，因为NULL值列表里谁是NULL谁不是NULL都一清二楚。



此时就可以从变长字段长度列表中解析出来不为NULL的变长字段的值长度，然后也知道哪几个字段是NULL的，此时根据这些信息，就可以从实际的列值存储区域里，把你每个字段的值读取出来了。



如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道他是个NULL，没有值存储，如果是定长字段，就按照定长长度来读取，这样就可以完美的把你一行数据的值都读取出来了！



**5、今日思考题**



昨天让大家思考，为什么数据要按照这种紧凑的格式来在磁盘里存储，今天我们不公布答案，再次问大家一个问题，为什么NULL值列表要按照二进制bit位的方式来存储？



他跟直接用NULL字符串的方式来存储，会有多少存储空间的差距呢？



## 27 磁盘文件中， 40个bit位的数据头以及真实数据是如何存储的？

之前我们已经给大家讲到了在磁盘上存储数据的时候，每一行数据都会有变长字段长度列表，逆序存放这行数据里的变长字段的长度，然后会有NULL值列表，对于允许为NULL的字段都会有一个bit位标识那个字段是否为NULL，也是逆序排列的。



今天我们接着给大家讲每一行数据存储的时候，还得有40个bit位的数据头，这个数据头是用来描述这行数据的。



这40个bit位里，第一个bit位和第二个bit位，都是预留位，是没任何含义的。



然后接下来有一个bit位是**delete_mask**，他标识的是这行数据是否被删除了，其实看到这个bit位，很多人可能已经反映过来了，这么说在MySQL里删除一行数据的时候，未必是立马把他从磁盘上清理掉，而是给他在数据头里搞1个bit标记他已经被删了？



没错，其实大家现在看这些数据头，只要先留有一个印象就可以了，知道每一行数据都有一些数据头，不同的数据头都是用来描述这行数据的一些状态和附加信息的。



然后下一个bit位是**min_rec_mask**，这个bit位大家现在先不用去关注，他的含义以后我们讲到对应的内容的时候再说，他其实就是说在B+树里每一层的非叶子节点里的最小值都有这个标记。



接下来有4个bit位是**n_owned**，这个暂时我们也先不用去管他，他其实就是记录了一个记录数，这个记录数的作用，后续我们讲到对应的概念时会告诉大家的。



接着有13个bit位是**heap_no**，他代表的是当前这行数据在记录堆里的位置，现在大家可能也很难去理解他，这些概念都要结合后续的一些内容才能理解的，这里只能是初步的给大家介绍下。



然后是3个bit位的record_type，这就是说这行数据的类型



0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据



很多朋友可能也不理解这些什么意思，其实我们也现在不用在乎他，因为很多这些概念都是往后在讲解索引之类的技术的时候才会涉及到的。



最后是16个bit的next_record，这个是指向他下一条数据的指针。



## 28 我们每一行的实际数据在磁盘上是如何存储的？

之前我们已经给大家讲过了，一行数据在磁盘文件里存储的时候，实际上首先会包含自己的变长字段的长度列表，然后是NULL值列表，接着是数据头，然后接着才是真实数据，所以这一次我们就讲讲真实数据是如何存储的。



首先我们在存储真实数据的时候，并没什么特别的，无非就是按照我们那个字段里的数据值去存储就行了



比如我们之前说了一个例子，有一行数据是“jack NULL m NULL xx_school”，那么他真实存储大致如下所示：



0x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school



刚开始先是他的变长字段的长度，用十六进制来存储，然后是NULL值列表，指出了谁是NULL，接着是40个bit位的数据头，然后是真实的数据值，就放在后面。



在读取这个数据的时候，他会根据变长字段的长度，先读取出来jack这个值，因为他的长度是4，就读取4个长度的数据，jack就出来了；



然后发现第二个字段是NULL，就不用读取了；



第三个字段是定长字段，直接读取1个字符就可以了，就是m这个值；



第四个字段是NULL，不用读取了；



第五个字段是变长字段长度是9，读取出来xx_school就可以了。



但是等等，大家觉得真正在磁盘上存储的时候，我们那些字符串就是直接这么存储在磁盘上吗？



显然不是的！



实际上字符串这些东西都是根据我们数据库指定的字符集编码，进行编码之后再存储的，所以大致看起来一行数据是如下所示的：



0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262



大家会看到上面，我们的字符串和其他类型的数值最终都会根据字符集编码，搞成一些数字和符号存储在磁盘上



所以其实一行数据是如何存储的，我相信大家就都已经了解的很清晰了，那么我们今天来给大家简单提一下，在实际存储一行数据的时候，会在他的真实数据部分，加入一些隐藏字段，这个隐藏字段跟后续的一些内容是有关联的，大家先了解一下。



首先有一个DB_ROW_ID字段，这就是一个行的唯一标识，是他数据库内部给你搞的一个标识，不是你的主键ID字段。如果我们没有指定主键和unique key唯一索引的时候，他就内部自动加一个ROW_ID作为主键。



接着是一个DB_TRX_ID字段，这是跟事务相关的，他是说这是哪个事务更新的数据，这是事务ID，这个后续我们讲解到事务的时候会跟大家说的。



最后是DB_ROLL_PTR字段，这是回滚指针，是用来进行事务回滚的，也是我们后续在讲解事务的时候再详细说。



所以如果你加上这几个隐藏字段之后，实际一行数据可能看起来如下所示：



0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR）  616161 636320 6262626262



我给上面几个隐藏字段都加了括号说明了，上面那基本就是最终在磁盘上一行数据是长成什么样的了



我们再看看下面的图，大家回忆一下之前我们给大家讲解的，当你执行crud的时候，先会把磁盘上的数据加载到Buffer Pool里缓存，然后更新的时候也是更新Buffer Pool的缓存，同时维护一堆链表。



然后定时或者不定时的，根据flush链表和lru链表，Buffer Pool里的更新过的脏数据就会刷新到磁盘上去。

​      ![0.jpg](all_in_one.assets/55067700_1582532903.jpg)

好，现在我们再结合最近讲解的一些内容思考一下，那么在磁盘上的数据，每一行数据是不是就是类似“0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR）  616161 636320 6262626262”这样的东西？



所以现在我们就初步的把磁盘上的数据和内存里的数据给关联起来了，他每一行数据的真实存储结构我们就了解了，希望大家能在头脑里屡清楚这个他们之间的关系，其实这些都是有机一体的。



## 29 理解数据在磁盘上的物理存储之后，聊聊行溢出是什么东西？

上一篇文章我们已经理解清楚了一行数据在磁盘上的物理存储结构了，其实理解了这个，你也就理解了每一行数据在磁盘上是如何存储的，以及他被加载到缓存里来的时候，一行数据都包含哪些东西了。



今天我们来聊聊行数据的物理存储的一个高阶的话题，就是行溢出到底是个什么东西？



我们之前已经初步了解到，实际上我们每一行数据都是放在一个数据页里的，这个数据页默认的大小是16KB，那么之前就有人在后台提过一个问题：万一 一行数据的大小超过了页的大小怎么办呢？



比如有一个表的字段类型是VARCHAR(65532)，意思就是最大可以包含65532个字符，那也就是65532个字节，这就远大于16kb的大小了，也就是说这一行数据的这个字段都远超一个数据页的大小了！



这个时候实际上会在那一页里存储你这行数据，然后在那个字段中，仅仅包含他一部分数据，同时包含一个20个字节的指针，指向了其他的一些数据页，那些数据页用链表串联起来，存放这个VARCHAR(65532)超大字段里的数据。



我们看下图，就给出了这个示意。

![2.jpg](all_in_one.assets/39404800_1582532968.jpg)       

上面说的这个过程，其实就叫做**行溢出**，就是说一行数据存储的内容太多了，一个数据页都放不下了，此时只能溢出这个数据页，把数据溢出存放到其他数据页里去，那些数据页就叫做溢出页。



包括其他的一些字段类型都是一样的，比如TEXT、BLOB这种类型的字段，都有可能出现溢出，然后一行数据就会存储在多个数据页里。



讲到这里，其实就已经把我们的行数据的物理存储相关的内容都已经讲完了，很多琐碎和细节的东西，其实不需要我们在这里来死扣他，大家其实要理解的，就是一行数据的物理存储结构，然后这个数据其实是在一个数据页里的，如果一个数据页里放不下一行数据，就会有行溢出问题，存放到多个数据页里去。



讲到这里，我们可以做一点总结，当我们在数据库里插入一行数据的时候，实际上是在内存里插入一个有复杂存储结构的一行数据，然后随着一些条件的发生，这行数据会被刷到磁盘文件里去。



在磁盘文件里存储的时候，这行数据也是按照复杂的存储结构去存放的。



而且每一行数据都是放在数据页里的，如果一行数据太大了，就会产生行溢出问题，导致一行数据溢出到多个数据页里去，那么这行数据在Buffer Pool可能就是存在于多个缓存页里的，刷入到磁盘的时候，也是用磁盘上的多个数据页来存放这行数据的。



希望大家能够把最近几天学到的行数据物理存储结构，与之前学到的Buffer Pool缓存机制结合起来去理解，把他们有机的融合为一体。



接下来，我们就会开始讲解数据页的物理存储结构，然后是表空间的物理存储结构，最后是讲解这些数据以物理存储结构的方式，在磁盘上存储的时候，是放在哪些磁盘文件里的。



只要把后续那些内容讲完，那么大家就对数据库的Buffer Pool缓冲读写机制，以及磁盘上的物理存储机制，就完全理解了，而且这两个机制都是有机结合在一起的，Buffer Pool的数据是从磁盘上读取出来的，Buffer Pool里更新的数据又会刷新到磁盘上去。



在这个过程中，整个数据的物理存储机制，包括行数据、数据页、表空间、磁盘文件，这些概念，大家也都会理解了，到时候自然理解了数据在磁盘上如何存储的，加载到Buffer Pool缓存页之后如何存储的。



## 30 用于存放磁盘上的多行数据的数据页到底长个什么样子？

之前我们老是给大家提到一个概念，就是数据页，大家都知道平时我们执行crud的时候，都会从磁盘上加载数据页到Buffer Pool的缓存页里去，然后更新了缓存页后，又会刷新回磁盘上的数据页里去。



所以其实MySQL中进行数据操作的最小单位应该是数据页，那么我们之前已经给大家分析过了一行一行的数据在磁盘和缓存中存储的时候，他真正的格式是什么样子的



现在我们都知道，一行一行的数据是放在数据页里的，所以接下来就该分析分析，数据页到底是长什么样子的了。



之前介绍过，每个数据页，实际上是默认有16kb的大小，那么这16kb的大小就是存放大量的数据行吗？



明显不是的，其实一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部。



我下面有一个图，在图里包含了一个数据页的各个部分，大家可以看一下

![1.jpg](all_in_one.assets/82758600_1582627491.jpg)

其中文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节。



看完了这个数据页的结构，是不是觉得很神奇？居然冒出了这么多稀奇古怪的概念出来。



其实也没什么好奇怪的，说白了，这个数据页就跟每一行数据一样，都是由MySQL开发人员设计出来的一个特殊的存储格式。



也就是说通过这种特殊的存储格式在磁盘文件里去存放一个又一个的数据页，每个数据页在磁盘里实际存储的时候，就是包含了上述一些特殊的数据，然后每个数据页里还有专门的区域包含了多个数据行，至于每个数据行，那就是用我们之前讲解的那套存储格式来存储的了。



接着我们给大家讲一下这个把数据插入数据页的一个过程，因为大家都知道，刚开始一个数据页可能是空的，没有一行数据的，此时这个数据页实际上是没有数据行那个区域的



也就是说，此时看起来一个空的数据页就是下面图里那样的。

​      ![2.jpg](all_in_one.assets/33789900_1582627503.jpg)

然后我们来思考一下，假设我们现在要插入一行数据，此时数据库里可是一行数据都没有的，那么此时是不是应该先是从磁盘上加载一个空的数据页到缓存页里去？



此时空的数据页就是如上图所示，至于加载的过程，则如下图所示。

​      ![3.jpg](all_in_one.assets/25291100_1582627515.jpg)       

接着我们是不是应该在Buffer Pool中的一个空的缓存页里插入一条数据？



记住，缓存页跟数据页是一 一对应的，他在磁盘上的时候就是数据页，数据页加载到缓存页里了，我们就叫他缓存页了！



所以此时在缓存页里插入一条数据，实际上就是在数据行那个区域里插入一行数据，然后空闲区域的空间会减少一些，此时当缓存页里插入了一行数据之后，其实缓存页此时看起来如下图所示。

​      ![4.jpg](all_in_one.assets/72850700_1582627522.jpg)

接着你就可以不停的插入数据到这个缓存页里去，直到他的空闲区域都耗尽了，就是这个页满了，此时数据行区域内可能有很多行数据，如下图所示，空闲区域就没了。

​      ![5.jpg](all_in_one.assets/24839700_1582627531.jpg)

而且大家都知道，在更新缓存页的同时，其实他在lru链表里的位置会不停的变动，而且肯定会在flush链表里，所以最终他一定会通过后台IO线程根据lru链表和flush链表，把这个脏的缓存页刷到磁盘上去，如下图所示。

​      ![6.jpg](all_in_one.assets/55934900_1582627538.jpg)

因此对于数据页的整体存储结构的初步介绍，以及MySQL实际运行过程中，数据页的使用，我们今天就介绍完了，接下来我们会继续去了解表空间、数据区、数据段这些物理存储中的概念。



## 31 表空间以及划分多个数据页的数据区，又是什么概念？

上一次我们讲完了数据页的具体存储结构，当然里面有很多的细节我们还没讲，实际上现在也确实没必要去说那些细节，因为很多数据页的一些细节性的东西，都是要在后续讲解的内容中涉及到的，比如说数据的删除，查询的一些原理。



现在我们在大致了解了数据页的结构和使用之后，我们可以继续来了解下一个概念，就是表空间和数据区的概念



首先我们先说一下，什么是表空间？



简单来说，就是我们平时创建的那些表，其实都是有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的一个磁盘数据文件



所以其实在物理层面，表空间就是对应一些磁盘上的数据文件。



有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个“表名.ibd”数据文件。



然后在表空间的磁盘文件里，其实会有很多很多的数据页，因为大家都知道一个数据页不过就是16kb而已，总不可能一个数据页就是一个磁盘文件吧。



所以一个表空间的磁盘文件里，其实是有很多的数据页的。



但是现在有一个问题，就是一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个**数据区**的概念，英文就是**extent**



一个数据区对应着连续的64个数据页，每个数据页是16kb，所以一个数据区是1mb，然后256个数据区被划分为了一组。



对于表空间而言，他的第一组数据区的第一个数据区的前3个数据页，都是固定的，里面存放了一些描述性的数据。比如FSP_HDR这个数据页，他里面就存放了表空间和这一组数据区的一些属性。



IBUF_BITMAP数据页，里面存放的是这一组数据页的所有insert buffer的一些信息。



INODE数据页，这里也是存放了一些特殊的信息



大家暂时先不用了解这些东西具体是干什么的，你只要知道每一个组数据区的第一个数据区的前3个数据页，都是存放一些特殊的信息的。



然后这个表空间里的其他各组数据区，每一组数据区的第一个数据区的头两个数据页，都是存放特殊信息的，比如XDES数据页就是用来存放这一组数据区的一些相关属性的，其实就是很多描述这组数据区的东西，现在大家也不用去知道是什么。



其实今天的内容讲到这里就差不多了，讲太多大家可能就被绕晕了，大家只要知道，**我们平时创建的那些表都是有对应的表空间的，每个表空间就是对应了磁盘上的数据文件，在表空间里有很多组数据区，一组数据区是256个数据区，每个数据区包含了64个数据页，是1mb**



然后表空间的第一组数据区的第一个数据区的头三个数据页，都是存放特殊信息的；



表空间的其他组数据区的第一个数据区的头两个数据页，也都是存放特殊信息的。大家今天只要了解到这个程度就可以了。



所以磁盘上的各个表空间的数据文件里是通过数据区的概念，划分了很多很多的数据页的，因此**当我们需要执行crud操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用。**



我下面给出了一张图，图里就给出了一个表空间内部的存储结构，包括一组一组的数据区，每一组数据区是256个数据区，然后一个数据区是64个数据页。



请大家牢记下图：

​      ![226.jpg](all_in_one.assets/6865200_1582721462.jpg)



## 32 一文总结初步了解到的MySQL存储模型以及数据读写机制

今天我们来用一篇文章初步总结一下我们近期学习到的MySQL存储模型以及对应的读写机制，其实大家通过近期的学习也仅仅是初步了解了MySQL底层数据的存储模型而已，因为后续我们还要讲解MySQL的增删改查执行背后的深入底层的各种存储数据读写细节，现在仅仅是初步把存储模型的结构给建立起来罢了。



好，那么我们现在应该都知道了，最终MySQL的数据都是放在磁盘文件里的，这个大家应该都没什么问题吧



那么数据在磁盘文件里是怎么存放的呢？我们都知道我们平时数据都是插入一个一个的表中的，而表是个逻辑概念，其实在物理层面，他对应的是**表空间**这个概念。



所以其实在MySQL的磁盘上，表空间就对应着磁盘文件，在磁盘文件里就存放着数据！



那么这个表空间的磁盘文件里，数据是如何组织的呢？



这个就非常的复杂了！因为你可以想象一下，假如让你把数据直接一行一行的写入一个磁盘文件，当然很简单了！



但是问题是你现在要存储的是数据库里的如此复杂的数据！他里面是有各种字段类型的，还有索引这个概念，当后面我们讲到索引的时候，就会详细分析这个索引在磁盘里的数据组织结构，这也是相当的复杂。



所以其实在磁盘文件里存放的数据，他从最基本的角度来看的话，就是被拆分为一个一个的数据区（extent）分组，以后我们干脆就用他的英文名叫做extent组好了，每个extent组中包含256个extent，然后每个extent里包含64个数据页！然后每个数据页里都包含了一行一行的数据！如下图所示。

​      ![0.jpg](all_in_one.assets/16902500_1582810125.jpg)       

大家听到这里，是不是觉得特别的简单，其实绝对不是的



在实际存储的时候，我们之前稍微给大家介绍过一点点，在数据行里都有很多附加的信息，在数据页、数据区里，都有很多附加的特殊信息。各种各样的特殊信息，就可以让我们在简简单单的磁盘文件里实现B+树索引、事务之类的非常复杂的机制。



关于这些存储结构中的特殊信息是如何用于支撑实现很多高级的复杂功能的，我们后续会给大家讲解的！



那么现在问题来了，我们都知道，当我们在数据库中执行crud的时候，你必须先把磁盘文件里的一个数据页加载到内存的Buffer Pool的一个缓存页里去，然后我们增删改查都是针对缓存页里的数据来执行的！



所以假设此时我们要插入一条数据，那么是选择磁盘文件里的哪个数据页加载到缓存页里去呢？



大家注意，这里要划重点了，其实这个时候会看看你往哪个表里插入数据？然后肯定得根据表找到一个表空间啊！



找到表空间之后，就可以定位到对应的磁盘文件啊！有了磁盘文件之后，就可以从里面找一个extent组，找一个extent，接着从里面找一个数据页出来！这个数据也可能是空的，也可能已经放了一些数据行了！



然后就可以把这个数据页从磁盘里完整加载出来，放入Buffer Pool的缓存页里了！



我们看下图的示意

​      ![1.jpg](all_in_one.assets/54077700_1582810133.jpg)       

当然，这个时候有人会问了，这个从磁盘文件里读取一个数据页，是怎么读取的啊？



其实这个很简单了，你可以想一下，磁盘文件里放的数据都是紧挨在一起的，类似于下面的那种样子。



0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds

0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds



其实上述字符完全无任何意义，就是我为了演示随便搞出来的一段东西而已，但是大致来说磁盘里存放的数据看起来就是那样的，可能先是有一个extent组开始的一些东西，然后里面是一个一个的extent，每个extent开始的时候会写一些特殊的信息，然后再是一个一个的数据页，里面是一个一个的数据行。



那么在读取一个数据页的时候，你就可以通过随机读写的方式来了，举个例子，我们下面有一个伪代码，大家看看。就是设置一下要从一个数据文件的哪个位置开始读取，一直到哪个位置就结束。



dataFile.setStartPosition(25347)

dataFile.setEndPosition(28890)

dataPage = dataFile.read()



通过上面伪代码那种方式，你指定磁盘文件里的开始和截止的位置，就能读取出来指定位置的一段数据，比如读取出来一大坨东西：psfds0xdfs343939。也许这坨东西就是一个数据页包含的内容了。



然后把数据页放到内存的缓存页里即可。



接着crud操作都可以直接针对缓存页去执行了，会自动把更新的缓存页加入flush链表，然后更新他在lru链表里的位置，包括更新过的缓存页会从free链表里拿出来，等等，后续一系列操作，都是之前我们分析过的了。



此时对于那些被更新过的缓存页来说，都会由后台线程刷入磁盘的，那么刷磁盘的时候是怎么刷呢？我们也是写一段伪代码给大家看看。



dataFile.setStartPosition(25347)

dataFile.setEndPosition(28890)

dataFile.write(cachePage)



因为一个数据页的大小其实是固定的，所以一个数据页固定就是可能在一个磁盘文件里占据了某个开始位置到结束位置的一段数据，此时你写回去的时候也是一样的，选择好固定的一段位置的数据，直接把缓存页的数据写回去，就覆盖掉了原来的那个数据页了，就如上面的伪代码示意。



今天通过一篇总结文章，就给大家讲清楚了我们初步了解到的存储模型是如何跟Buffer Pool缓存机制配合起来实现crud的，接着我们会给大家讲解几个数据库优化的案例了！



我们的风格就是讲一些理论的知识，就配合一些实战案例，让大家理论和实战相结合起来。



## 33 MySQL数据库的日志顺序读写以及数据文件随机读写的原理

之前我们花了很多篇幅去讲解MySQL的底层数据存储结构，其实那些知识是极为枯燥的，因为大部分时候，MySQL在底层如何存储数据的一些细节，比如什么数据头、附加信息之类的极为复杂，大家直接那么研究是很痛苦的。



所以我之前也就初步的给大家介绍了一下数据行、数据页、extent、extent分组、表空间、磁盘文件这些概念，主要是让大家把物理数据结构与Buffer Pool缓存的结合使用，有一个理解就行了。



掌握到之前的一些知识，基本上MySQL稍微进一步的原理，大家也就有一定的了解了。其实暂时来说这就足够了，更加细节的一些知识，比如表空间的存储结构细节，extent的存储结构细节，都要结合未来的索引优化原理、数据删除原理，结合这些东西去分析，大家从自己日常都接触的一些场景出发，去看一些技术细节，才能真正很好理解。



那么今天开始，我们将要用连续几天的时间，给大家介绍一个**真实的生产优化案例**，这个案例主要用到的知识，其实大家之前都学过了



所以这也是我一如既往的专栏风格，讲一些理论，同时插入一些我们生产环境的真实案例分析，让大家理论和实战结合起来。



在讲解这个真实的生产案例之前，有一些前置的知识要给大家介绍一下



首先今天要讲解的就是MySQL数据库和底层的操作系统之间的交互原理，理解了这个原理后，我们再一步步剖析一个生产环境的MySQL数据库每隔一两个月性能就会出现急剧抖动的案例。



先给大家剖析一下MySQL在实际工作时候的两种数据读写机制，一种是对redo log、binlog这种日志进行的磁盘顺序读写，一种是对表空间的磁盘文件里的数据页进行的磁盘随机读写。



简单来说，MySQL在工作的时候，尤其是执行增删改操作的时候，肯定会先从表空间的磁盘文件里读取数据页出来，这个过程其实就是典型的磁盘随机读操作



我们先看下面的图，图里有一个磁盘文件的示意，里面有很多数据页，然后你可能需要在一个随机的位置读取一个数据页到缓存，这就是**磁盘随机读**

   ![01.jpg](all_in_one.assets/59051200_1583118569.jpg)       

因为你要读取的这个数据页可能在磁盘的任意一个位置，所以你在读取磁盘里的数据页的时候只能是用随机读的这种方式。



磁盘随机读的性能是比较差的，所以不可能每次更新数据都进行磁盘随机读，必须是读取一个数据页之后放到Buffer Pool的缓存里去，下次要更新的时候直接更新Buffer Pool里的缓存页。



对于磁盘随机读来说，主要关注的性能指标是IOPS和响应延迟



IOPS之前给大家介绍过，就是说底层的存储系统每秒可以执行多少次磁盘读写操作，比如你底层磁盘支持每秒执行1000个磁盘随机读写操作和每秒执行200个磁盘随机读写操作，对你的数据库的性能影响其实是非常大的。



这个IOPS指标如何观察，之前也讲过了，大家在压测的时候可以观察一下。这个指标实际上对数据库的crud操作的QPS影响是非常大的，因为他在某种程度上几乎决定了你每秒能执行多少个SQL语句，底层存储的IOPS越高，你的数据库的并发能力就越高。



另外一个就是磁盘随机读写操作的响应延迟，也是对数据库的性能有很大的影响。因为假设你的底层磁盘支持你每秒执行200个随机读写操作，但是每个操作是耗费10ms完成呢，还是耗费1ms完成呢，这个其实也是有很大的影响的，决定了你对数据库执行的单个crud SQL语句的性能。



比如你一个SQL语句发送过去，他磁盘要执行随机读操作加载多个数据页，此时每个磁盘随机读响应时间是50ms，那么此时可能你的SQL语句要执行几百ms，但是如果每个磁盘随机读仅仅耗费10ms，可能你的SQL就执行100ms就行了。



所以其实一般对于核心业务的数据库的生产环境机器规划，我们都是推荐用SSD固态硬盘的，而不是机械硬盘，因为SSD固态硬盘的随机读写并发能力和响应延迟要比机械硬盘好的多，可以大幅度提升数据库的QPS和性能。



接着我们来看磁盘顺序读写，之前我们都知道，当你在Buffer Pool的缓存页里更新了数据之后，必须要写一条redo log日志，这个redo log日志，其实就是走的顺序写



所谓顺序写，就是说在一个磁盘日志文件里，一直在末尾追加日志，我们看下图。

​      ![02.jpg](all_in_one.assets/38880800_1583118576.jpg)       

所以上图可以清晰看到，写redo log日志的时候，其实是不停的在一个日志文件末尾追加日志的，这就是磁盘顺序写。



磁盘顺序写的性能其实是很高的，某种程度上来说，几乎可以跟内存随机读写的性能差不多，尤其是在数据库里其实也用了os cache机制，就是redo log顺序写入磁盘之前，先是进入os cache，就是操作系统管理的内存缓存里。



所以对于这个写磁盘日志文件而言，最核心关注的是磁盘每秒读写多少数据量的吞吐量指标，就是说每秒可以写入磁盘100MB数据和每秒可以写入磁盘200MB数据，对数据库的并发能力影响也是极大的。



因为数据库的每一次更新SQL语句，都必然涉及到多个磁盘随机读取数据页的操作，也会涉及到一条redo log日志文件顺序写的操作。所以磁盘读写的IOPS指标，就是每秒可以执行多少个随机读写操作，以及每秒可以读写磁盘的数据量的吞吐量指标，就是每秒可以写入多少redo log日志，整体决定了数据库的并发能力和性能。



包括你磁盘日志文件的顺序读写的响应延迟，也决定了数据库的性能，因为你写redo log日志文件越快，那么你的SQL语句性能就越高。



所以今天就先给大家在之前知识的基础之上，讲解一下数据库运行过程中，磁盘随机读写和磁盘顺序读写的两个机制的原理。



## 34 生产经验：Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理

接着上一篇文章的讲解，我们继续来讲解MySQL数据库在执行底层磁盘读写IO操作的原理，这其实就涉及到了Linux操作系统的磁盘IO原理了，不管是MySQL执行磁盘随机读写，还是磁盘顺序读写，其实在底层的Linux层面，原理几乎都是一致的。



同时我们还会针对这块内容，连带讲解一下生产环境中，针对MySQL数据库的IO调度优化的建议。



大家都知道，所谓的操作系统，无论是Linux也好，还是Windows也好，说白了他们自己本身就是软件系统，之所以需要操作系统，是因为我们不可能直接去操作CPU、内存、磁盘这些硬件，所以必须要用操作系统来管理CPU、内存、磁盘、网卡这些硬件设备。



操作系统除了管理硬件设备以外，还会提供一个操作界面给我们，比如Windows之所以在全世界大获成功，其实就是他提供了一个比较简便易用的可视化的界面，让我们可以普通人都能操作台式电脑或者笔记本电脑内部的内存、CPU、磁盘和网卡。



我们只要打开windows操作系统的电脑，就可以随意编辑文件，上网，聊天，使用各种软件，这些软件运行的时候本质底层都是在使用计算机的CPU、内存、磁盘和网卡，比如基于CPU执行你的文件编辑的操作，基于内存缓冲你对文件的编辑，基于磁盘存储你在文件里输入的内容，基于网卡去进行网络通信，让你进行QQ聊天什么的。



至于说linux操作系统，其实也是类似的，只不过一般我们用linux操作系统，他是不给我们提供可视化界面的，只有命令行的界面，我们需要输入各种各样的命令去执行文件编辑、系统部署和运行，本质linux操作系统在底层其实也是利用CPU、内存、磁盘和网卡这些硬件在工作。



所以，简单来说，我们今天要讲解的就是Linux操作系统的存储系统，Linux利用这套存储系统去管理我们的机器上的机械硬盘、SSD固态硬盘，这些存储设备，可以在里面读取数据，或者是写入数据。



理解了这个，你就理解了MySQL执行的数据页随机读写，redo log日志文件顺序读写的磁盘IO操作，在Linux的存储系统中是如何执行的。



简单来说，Linux的存储系统分为VFS层、文件系统层、Page Cache缓存层、通用Block层、IO调度层、Block设备驱动层、Block设备层，如下图：

![0.jpg](all_in_one.assets/3907500_1583145173.jpg)       

当MySQL发起一次数据页的随机读写，或者是一次redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给Linux操作系统的VFS层



这一层的作用，就是根据你是对哪个目录中的文件执行的磁盘IO操作，把IO请求交给具体的文件系统。



举个例子，在linux中，有的目录比如/xx1/xx2里的文件其实是由NFS文件系统管理的，有的目录比如/xx3/xx4里的文件其实是由Ext3文件系统管理的，那么这个时候VFS层需要根据你是对哪个目录下的文件发起的读写IO请求，把请求转交给对应的文件系统，如下图所示。

​      ![1.jpg](all_in_one.assets/68722600_1583145188.jpg)       

接着文件系统会先在Page Cache这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读写，如果没有就继续往下一层走，此时这个请求会交给通用Block层，在这一层会把你对文件的IO请求转换为Block IO请求，如下图所示。

![2.jpg](all_in_one.assets/63467500_1583145200.jpg)       

接着IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这一层里默认是用CFQ公平调度算法的



也就是说，可能假设此时你数据库发起了多个SQL语句同时在执行IO操作。



有一个SQL语句可能非常简单，比如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的一个block里的数据就可以了



但是有的SQL语句，比如说select * from xx where xx1 like "%xx%"可能需要IO读取磁盘上的大量数据。



那么此时如果基于公平调度算法，就会导致他先执行第二个SQL语句的读取大量数据的IO操作，耗时很久，然后第一个仅仅更新少量数据的SQL语句的IO操作，就一直在等待他，得不到执行的机会。



所以在这里，其实一般建议MySQL的生产环境，需要调整为deadline IO调度算法，他的核心思想就是，任何一个IO操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。



所以基于deadline算法，上面第一个SQL语句的更新少量数据的IO操作可能在等待一会儿之后，就会得到执行的机会，这也是一个生产环境的IO调度优化经验。



我们看下图，此时IO请求被转交给了IO调度层。

​      ![3.jpg](all_in_one.assets/44882800_1583145212.jpg)       

最后IO完成调度之后，就会决定哪个IO请求先执行，哪个IO请求后执行，此时可以执行的IO请求就会交给Block设备驱动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，如下图所示。

​      ![4.jpg](all_in_one.assets/76719100_1583145218.jpg)       

然后硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上面的层级反向依次返回，最终MySQL可以得到本次IO读写操作的结果



这就是MySQL跟Linux存储系统交互的的一个原理剖析，包括里面的IO调度算法那块的一个优化的点，大家可以仔细理解一下今天的内容。



## 35 生产经验：数据库服务器使用的RAID存储架构初步介绍

今天我们继续给大家讲解生产环境下的MySQL数据库的一些存储技术的原理，之前已经给大家解释了MySQL的磁盘随机读写和顺序读写的场景和原理，包括Linux操作系统的存储系统的原理，那么我们接着就要继续讲解Linux操作系统再底层的存储硬件层面的一些原理



只有把这些都理解透了，才能给大家最终讲清楚一次线上生产环境的MySQL数据库的性能抖动的故障原因。



实际上MySQL数据库就是个软件，大家都知道，他其实就是用编程语言写的一套数据库管理软件而已，底层就是磁盘来存储数据，基于内存来提升数据读写性能，然后设计了复杂的数据模型，帮助我们高效的存储和管理数据。



所以MySQL数据库软件都是安装在一台linux服务器上的，然后启动MySQL的进程，就是启动了一个MySQL数据库



MySQL运行过程中，他需要使用CPU、内存、磁盘和网卡这些硬件，但是不能直接使用，都是通过调用操作系统提供的接口，依托于操作系统来使用和运行的，然后linux操作系统负责操作底层的硬件。



我们下面画了一个图，来给大家表示一下，他们之间的一个关系。

​      ![1.jpg](all_in_one.assets/55710400_1583231421.jpg)   

所以之前我们已经把MySQL层面的磁盘读写操作讲完了，同时也把Linux操作系统层面的存储系统的原理讲完了，上一讲不就讲到Linux操作系统的存储系统把IO请求交给机器上的存储硬件了么？



那么今天我们接着来讲讲存储硬件这块的东西。



一般来说，很多数据库部署在机器上的时候，存储都是搭建的RAID存储架构，其实这个RAID很多人以为非常的深奥，确实这个概念比较难以理解，而且说深了其实里面的技术含量很高，但是如果简单说一下，也是每个人都能理解的。



说白了，RAID就是一个磁盘冗余阵列，什么意思呢？



假设我们的服务器里的磁盘就一块，那万一 一块磁盘的容量不够怎么办？此时是不是就可以再搞几块磁盘出来放在服务器里



现在多搞了几块磁盘，机器里有很多块磁盘了，不好管理啊，怎么在多块磁盘上存放数据呢？



所以就是针对这个问题，在存储层面往往会在机器里搞多块磁盘，然后引入RAID这个技术，大致理解为用来管理机器里的多块磁盘的一种磁盘阵列技术！



有了他以后，你在往磁盘里读写数据的时候，他会告诉你应该在哪块磁盘上读写数据，如下图。

​      ![2.jpg](all_in_one.assets/99848100_1583231426.jpg)      

有了RAID这种多磁盘阵列技术之后，我们是不是就可以在一台服务器里加多块磁盘，扩大我们的磁盘存储空间了？



当我们往磁盘里写数据的时候，通过RAID技术可以帮助我们选择一块磁盘写入，在读取数据的时候，我们也知道从哪块磁盘去读取。



除此之外，RAID技术很重要的一个作用，就是他还可以实现**数据冗余机制**



所谓的数据冗余机制，就是如果你现在写入了一批数据在RAID中的一块磁盘上，然后这块磁盘现在坏了，无法读取了，那么岂不是你就丢失了一波数据？如下图所示

![3.jpg](all_in_one.assets/70471300_1583231437.jpg)       

所以其实有的RAID磁盘冗余阵列技术里，是可以把你写入的同样一份数据，在两块磁盘上都写入的，这样可以让两块磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的，不需要你操心，如下图。

​      ![4.jpg](all_in_one.assets/45738100_1583231444.jpg)       

所以RAID技术实际上就是管理多块磁盘的一种磁盘阵列技术，他有软件层面的东西，也有硬件层买的东西，比如有RAID卡这种硬件设备。



具体来说，RAID还可以分成不同的技术方案，比如RAID 0、RAID 1、RAID 0+1、RAID2，等等，一直到RAID 10，很多种不同的多磁盘管理技术方案。



大家如果有兴趣的，可以自行去搜索对应的资料学习里面的技术细节，但是对于我们来说，这篇文章点到为止



**大家只要了解一下RAID这种多磁盘冗余阵列技术的基本思想就可以了，我们毕竟不是专门讲解存储这块的。**



对于存储的深入学习，主要也是一些运维工程师会去做的。



## 36 生产经验：数据库服务器上的RAID存储架构的电池充放电原理

上一篇文章我们初步给大家介绍了一下RAID多磁盘冗余阵列技术是什么东西，这一篇文章我们继续给大家讲解RAID存储架构的电池充放电原理，把这个理解了之后，我们下一篇文章就可以给大家讲一个真实的生产案例了。



服务器使用多块磁盘组成的RAID阵列的时候，一般会有一个RAID卡，这个RAID卡是带有一个缓存的，这个缓存不是直接用我们的服务器的主内存的那种模式，他是一种跟内存类似的SDRAM，当然，你大致就认为他也是基于内存来存储的吧！



然后我们可以把RAID的缓存模式设置为write back，这样的话，所有写入到磁盘阵列的数据，先会缓存在RAID卡的缓存里，后续慢慢再写入到磁盘阵列里去，这种写缓冲机制，可以大幅度提升我们的数据库磁盘写的性能。



我们看下图，他说的就是这个RAID卡的缓存机制。

​      ![361.jpg](all_in_one.assets/78911700_1583342204.jpg)       

那么现在有一个问题来了，假设突然断电了，或者是服务器自己故障关闭了，那么是不是这个RAID卡的缓存里的数据会突然丢失？那你MySQL写入磁盘的数据不就没了吗？我们看下图。

​      ![362.jpg](all_in_one.assets/52884000_1583342218.jpg)       

所以正是因为如此，为了解决这个问题，RAID卡一般都配置有自己独立的锂电池或者是电容，如果服务器突然掉电了，无法接通电源了，RAID卡自己是基于锂电池来供电运行的，然后他会赶紧把缓存里的数据写入到阵列中的磁盘上去，如下图所示。

​      ![363.jpg](all_in_one.assets/92095600_1583342223.jpg)       

但是锂电池是存在性能衰减问题的，所以一般来说锂电池都是要配置定时充放电的，也就是说每隔30天~90天（不同的锂电池厂商是不一样的），就会自动对锂电池充放电一次，这可以延长锂电池的寿命和校准电池容量。



如果你要是不这么做的话，那么可能锂电池用着用着就会发现容量不够了，可能容纳的电量在你服务器掉电之后，都没法一次性把缓存里的数据写回磁盘上去，那就会导致数据丢失了！



所以在锂电池充放电的过程中，RAID的缓存级别会从write back变成write through，我们通过RAID写数据的时候，IO就直接写磁盘了，如果写内存的话，性能也就是0.1ms这个级别，但是直接写磁盘，就性能退化10倍到毫秒级了！



所以说，对于那些在生产环境的数据库部署使用了RAID多磁盘阵列存储技术的公司来说，通常都会开启RAID卡的缓存机制，但是此时就一定要注意这个RAID的锂电池自动充放电的问题，因为只要你用了RAID缓存机制，那么锂电池就必然会定时进行充放电去延长寿命，保证服务器掉电的时候可以把缓存数据写回磁盘，数据不会丢失。



所以这个时候一旦RAID锂电池自动充放电，往往会导致你的数据库服务器的RAID存储定期的性能出现几十倍的抖动，间接导致你的数据库每隔一段时间就会出现性能几十倍的抖动！



## 37 案例实战：RAID锂电池充放电导致的MySQL数据库性能抖动的优化

前面经过了几天的生产经验的一些铺垫，包括MySQL磁盘读写的机制，Linux存储系统的原理，RAID磁盘阵列的介绍，RAID锂电池定时充放电的原理，今天终于可以切入真正的生产案例的讲解了！



其实只要大家理解了之前的内容，今天真正讲解案例的时候，你会发现理解起来是非常轻松的，几乎都不用画什么图，而且讲解起来也会非常的顺畅。



其实简单来说，就是曾经我们有一个非常核心的业务，他的数据库是部署在高配置服务器上的，磁盘就是用的RAID 10的阵列技术，用了6块磁盘组成了RAID 10磁盘阵列架构，具体RAID 10是什么，我们也简单的介绍一下。



其实RAID 0的意思，就是我们之前一幅图里画的，你有很多磁盘组成了一个阵列，然后你所有的数据是分散写入不同磁盘的，因为有多块磁盘，所以你的磁盘阵列的整体容量就很大，而且同时写入多块磁盘，让你的磁盘读写并发能力很强，如下图。

​      ![371.jpg](all_in_one.assets/62861000_1583342240.jpg)       

然后但是这种模式下，最大的问题就是万一你磁盘坏了一块，那么就会丢失一部分数据了！所以一般如果你要严格保证磁盘数据不丢失的话，就得用RAID 1，这个RAID 1的意思，就是两块磁盘为镜像关系，你写的所有数据，在两块磁盘上都有，形成了数据冗余，一块磁盘坏了，另外一块磁盘上还有数据。



一块磁盘如果压力很大，可以让读请求路由到另外一块磁盘上去，分担压力，反正他俩的数据都是冗余的，是一样的，如下图所示。

​      ![372.jpg](all_in_one.assets/73821400_1583342250.jpg)       

然后所谓的RAID 10，就是RAID 0 + RAID 1组合起来，就是说当时生产环境的服务器部署，我们有6块磁盘组成了一个RAID 10的阵列，那么其实就是每2块磁盘组成一个RAID 1互为镜像的架构，存放的数据是冗余一样的，一共有3组RAID 1，然后对于每一组RAID 1写入数据的时候，是用RAID 0的思路，就是不同组的磁盘的数据是不一样的，但是同一组内的两块磁盘的数据是冗余一致的，如下图。

​      ![373.jpg](all_in_one.assets/5023400_1583342261.jpg)       

所以对于这样的一个使用了RAID 10架构的服务器，他必然内部是有一个锂电池的，然后这个锂电池的厂商设定的默认是30天进行一次充放电，每次锂电池充放电就会导致RAID写入时不经过缓存，性能会急剧下降，所以我们发现线上数据库每隔30天就会有一次剧烈性能抖动，数据库性能下降了10倍。



当时为了排查这个问题，我们使用linux命令查看了RAID硬件设备的日志，这个具体什么命令不说了，因为你用不同的厂商的RAID设备，这个命令实际上是不一样的，发现RAID就是每隔30天有一次充放电的日志，所以就是由于这个定期的充放电导致了线上数据库的性能定期抖动！



那么后续如何解决这个问题呢？对于RAID锂电池充放电问题导致的存储性能抖动，一般有**三种解决方案：**



1. 给RAID卡把锂电池换成电容，电容是不用频繁充放电的，不会导致充放电的性能抖动，还有就是电容可以支持透明充放电，就是自动检查电量，自动进行充电，不会说在充放电的时候让写IO直接走磁盘，但是更换电容很麻烦，而且电容比较容易老化，这个其实一般不常用
2. 手动充放电，这个比较常用，包括一些大家知道的顶尖互联网大厂的数据库服务器的RAID就是用了这个方案避免性能抖动，就是关闭RAID自动充放电，然后写一个脚本，脚本每隔一段时间自动在晚上凌晨的业务低峰时期，脚本手动触发充放电，这样可以避免业务高峰期的时候RAID自动充放电引起性能抖动
3. 充放电的时候不要关闭write back，就是设置一下，锂电池充放电的时候不要把缓存级别从write back修改为write through，这个也是可以做到的，可以和第二个策略配合起来使用



这周通过一些生产经验的讲解以及一些底层技术的分析，同时结合一个真实的我们在大厂里的时候发现的一个数据库的性能抖动的案例，让大家能够把之前学到的数据库的理论知识以及底层技术，包括生产优化，都结合起来，希望大家能认真体会。



## 38 案例实战：数据库无法连接故障的定位，Too many connections

今天要给大家分析另外一个真实的大家都经常会碰到的数据库生产故障，就是数据库无法连接的问题



大家会看到的异常信息往往是“ERROR 1040(HY000): Too many connections”，这个时候就是说数据库的连接池里已经有太多的连接了，不能再跟你建立新的连接了！



不知道大家是否还记得我们最早讲过的数据库的整体架构原理，数据库自己其实是有一个连接池的，你的每个系统部署在一台机器上的时候，你那台机器上部署的系统实例/服务实例自己也是有一个连接池的，你的系统每个连接Socket都会对应着数据库连接池里的一个连接Socket，这就是TCP网络连接，如下图所示。

​      ![381.jpg](all_in_one.assets/78049200_1583725004.jpg)       

所以当数据库告诉你Too many connections的时候，就是说他的连接池的连接已经满了，你业务系统不能跟他建立更多的连接了！



曾经在我们的一个生产案例中，数据库部署在64GB的大内存物理机上，机器配置各方面都很高，然后连接这台物理机的Java系统部署在2台机器上，Java系统设置的连接池的最大大小是200，也就是说每台机器上部署的Java系统，最多跟MySQL数据库建立200个连接，一共最多建立400个连接，我们看下图示意。



*（另外给大家说明一点，最近狸猫技术窝的所有专栏都统一调整了画图工具，现在我们都使用下图的这种风格来进行绘图了）*

​      ![382.jpg](all_in_one.assets/48720000_1583725011.jpg)      

但是这个时候如果MySQL报异常说Too many Connections，就说明目前MySQL甚至都无法建立400个网络连接？这也太少了吧！毕竟是高配置的数据库机器！



于是我们检查了一下MySQL的配置文件，my.cnf，里面有一个关键的参数是max_connections，就是MySQL能建立的最大连接数，设置的是800。



那奇怪了，明明设置了MySQL最多可以建立800个连接，为什么居然两台机器要建立400个连接都不行呢？



这个时候我们可以用命令行或者一些管理工具登录到MySQL去，可以执行下面的命令看一下：



show variables like 'max_connections'



此时你可以看到，当前MySQL仅仅只是建立了214个连接而已！



所以我们此时就可以想到，是不是MySQL根本不管我们设置的那个mac_connections，就是直接强行把最大连接数设置为214了？于是我们可以去检查一下MySQL的启动日志，可以看到如下的字样：



Could not increase number of max_open_files to more than mysqld (request: 65535)

Changed limits: max_connections: 214 (requested 2000)

Changed limits: table_open_cache: 400 (requested 4096)



所以说，看看日志就很清楚了，MySQL发现自己无法设置max_connections为我们期望的800，只能强行限制为214了！



这是为什么呢？简单来说，就是因为底层的linux操作系统把进程可以打开的文件句柄数限制为了1024了，导致MySQL最大连接数是214！



可能有的人会疑惑说，为什么linux的文件句柄数量被限制了，MySQL最大连接数就被限制了呢？



其实这个问题你先不用操心了，因为这都是linux的知识，你现在只要知道有这么一件事儿就可以了，看下图的示意。      ![383.jpg](all_in_one.assets/59318500_1583725017.jpg)



## 39 案例实战：如何解决经典的Too many connections故障？背后原理是什么

今天我们继续讲解昨天的那个案例背景，其实就是经典的Too many connections故障，他的核心就是linux的文件句柄限制，导致了MySQL的最大连接数被限制，那么今天来讲讲怎么解决这个问题。



其实核心就是一行命令：



ulimit -HSn 65535



然后就可以用如下命令检查最大文件句柄数是否被修改了



cat /etc/security/limits.conf

cat /etc/rc.local



如果都修改好之后，可以在MySQL的my.cnf里确保max_connections参数也调整好了，然后可以重启服务器，然后重启MySQL，这样的话，linux的最大文件句柄就会生效了，MySQL的最大连接数也会生效了。



然后此时你再尝试业务系统去连接数据库，就没问题了！



另外再给大家解释一个问题，有人还是疑惑说，为什么linux的最大文件句柄限制为1024的时候，MySQL的最大连接数是214呢？



这个其实是MySQL源码内部写死的，他在源码中就是有一个计算公式，算下来就是如此罢了！



然后再给大家说一下，这个linux的ulimit命令是干嘛用的，其实说白了，linux的话是默认会限制你每个进程对机器资源的使用的，包括可以打开的文件句柄的限制，可以打开的子进程数的限制，网络缓存的限制，最大可以锁定的内存大小。



因为linux操作系统设计的初衷，就是要尽量避免你某个进程一下子耗尽机器上的所有资源，所以他默认都是会做限制的。



那么对于我们来说，常见的一个问题，其实就是文件句柄的限制。



因为如果linux限制你一个进程的文件句柄太少的话，那么就会导致我们没办法创建大量的网络连接，此时我们的系统进程就没法正常工作了



举个例子，比如MySQL运行的时候，其实就是linux上的一个进程，那么他其实是需要跟很多业务系统建立大量的连接的，结果你限制了他的最大文件句柄数量，那么他就不能建立太多连接了！



所以说，往往你在生产环境部署了一个系统，比如数据库系统、消息中间件系统、存储系统、缓存系统之后，都需要调整一下linux的一些内核参数，这个文件句柄的数量是一定要调整的，通常都得设置为65535



还有比如Kafka之类的消息中间件，在生产环境部署的时候，如果你不优化一些linux内核参数，会导致Kafka可能无法创建足够的线程，此时也是无法运行的。



所以我们平时可以用ulimit命令来设置每个进程被限制使用的资源量，用ulimit -a就可以看到进程被限制使用的各种资源的量



比如 core file size 代表的进程崩溃时候的转储文件的大小限制，max locked memory就是最大锁定内存大小，open files就是最大可以打开的文件句柄数量，max user processes就是最多可以拥有的子进程数量。



设置之后，我们要确保变更落地到/etc/security/limits.conf文件里，永久性的设置进程的资源限制



所以执行ulimit -HSn 65535命令后，要用如下命令检查一下是否落地到配置文件里去了。



cat /etc/security/limits.conf

cat /etc/rc.local



## 40 重新回顾redo日志对于事务提交后，数据绝对不会丢失的意义

之前我们在给大家介绍了大量的MySQL底层原理知识之后，理论结合实践，给大家讲解了两个真实的生产环境的数据库优化案例，一个是数据库所在服务器的RAID存储系统的锂电池充放电导致的性能抖动问题，一个是数据库底层的linux操作系统的文件句柄限制导致的无法连接问题，相信大家在学习了理论知识之后，再来看这些真实的实战案例，会有不错的感觉。



那么接着在学习了两个实战案例之后，我们就要继续进行深入底层的MySQL原理剖析了，我们之前都知道，在我们执行增删改操作的时候，首先会在Buffer Pool中更新缓存页，那么缓存页和底层的物理磁盘上的数据页的原理，之前都已经详细讲解过了



接着我们都知道，在更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。



redo log可以保证我们事务提交之后，如果事务中的增删改SQL语句更新的缓存页还没刷到磁盘上去，此时MySQL宕机了，那么MySQL重启过后，就可以把redo log重做一遍，恢复出来事务当时更新的缓存页，然后再把缓存页刷到磁盘就可以了



redo log本质是保证事务提交之后，修改的数据绝对不会丢失的。



所以接下来一段时间我们会深入研究redo log的底层实现原理，今天我们就承上启下，给大家简单回顾一下redo log这个机制存在的意义。



首先我们都知道，执行增删改SQL语句的时候，都是针对一个表中的某些数据去执行的，此时的话，首先必须找到这个表对应的表空间，然后找到表空间对应的磁盘文件，接着从磁盘文件里把你要更新的那批数据所在的数据页从磁盘读取出来，放到Buffer Pool的缓存页里去，如下图所示。

​      ![401.jpg](all_in_one.assets/93959300_1583895024.jpg) 

接着实际上你的增删改SQL语句就会针对Buffer Pool中的缓存页去执行你的更新逻辑，比如插入一行数据，或者更新一行数据，或者是删除一行数据。



当然，删除数据的逻辑我们还没讲，后续很快就要讲到了。至于说数据页和数据行的格式，就不用我多说了，其实都是MySQL自己定义的，之前都讲过了，大家现在对这些都知道了，如下图。

​      ![402.jpg](all_in_one.assets/42890000_1583895032.jpg)       

那么学习过之前的Buffer Pool底层原理之后都知道，其实你更新缓存页的时候，会更新free链表、flush链表、lru链表，然后有专门的后台IO线程，不定时的根据flush链表、lru链表，会把你更新过的缓存页刷新回磁盘文件的数据页里去，如下图所示。

​      ![403.jpg](all_in_one.assets/46947400_1583895039.jpg)所以大家都知道这个机制里最大的漏洞就在于，万一你一个事务里有增删改SQL更新了缓存页，然后事务提交了，结果万一你还没来得及让IO线程把缓存页刷新到磁盘文件里，此时MySQL宕机了，然后内存数据丢失，你事务更新的数据就丢失了！



但是也不可能每次你事务一提交，就把你事务更新的缓存页都刷新回磁盘文件里去，因为大家之前也都知道，缓存页刷新到磁盘文件里，是随机磁盘读写，性能是相当的差！这会导致你数据库性能和并发能力都很弱的！



所以此时才会引入一个redo log机制，这个机制就是说，你提交事务的时候，绝对是保证把你对缓存页做的修改以日志的形式，写入到redo log日志文件里去的



这种日志大致的格式如下：对表空间XX中的数据页XX中的偏移量为XXXX的地方更新了数据XXX。如下图所示

​      ![404.jpg](all_in_one.assets/41780500_1583895067.jpg)       

只要你事务提交的时候保证你做的修改以日志形式写入redo log日志，那么哪怕你此时突然宕机了，也没关系！



因为你MySQL重启之后，把你之前事务更新过做的修改根据redo log在Buffer Pool里重做一遍就可以了，就可以恢复出来当时你事务对缓存页做的修改，然后找时机再把缓存页刷入磁盘文件里去。



那么有人会问了，你事务提交的时候把修改过的缓存页都刷入磁盘，跟你事务提交的时候把你做的修改的redo log都写入日志文件，他们不都是写磁盘么？差别在哪里？



这是本文一个关键的问题。



实际上，如果你把修改过的缓存页都刷入磁盘，这首先缓存页一个就是16kb，数据比较大，刷入磁盘比较耗时，而且你可能就修改了缓存页里的几个字节的数据，难道也把完整的缓存页刷入磁盘吗？



而且你缓存页刷入磁盘是随机写磁盘，性能是很差的，因为他一个缓存页对应的位置可能在磁盘文件的一个随机位置，比如偏移量为45336这个地方。



但是如果是写redo log，第一个一行redo log可能就占据几十个字节，就包含表空间号、数据页号、磁盘文件偏移量、更新值，这个写入磁盘速度很快。



此外，redo log写日志，是顺序写入磁盘文件，每次都是追加到磁盘文件末尾去，速度也是很快的。



所以你提交事务的时候，用redo log的形式记录下来你做的修改，性能会远远超过刷缓存页的方式，这也可以让你的数据库的并发能力更强。



## 41 在Buffer Pool执行完增删改之后，写入日志文件的redo log长什么样？

昨天我们简单给大家回顾了一下在数据库里执行增删改操作的时候，redo log是用来干什么的，为什么需要这个东西，如果没有他会怎么样，有了他之后又能有什么样的效果，想必大家现在都对redo log这个东西有一定的理解了。



那么接下来我们就要深入研究一下redo log的一些技术细节了，今天就来看看写入磁盘上的日志文件的redo log，大致长个什么样，里面都包含一些什么东西。



之前略微给大家提到过，就是redo log里本质上记录的就是在对某个表空间的某个数据页的某个偏移量的地方修改了几个字节的值，具体修改的值是什么，他里面需要记录的就是**表空间号+数据页号+偏移量+修改几个字节的值+具体的值**



所以根据你修改了数据页里的几个字节的值，redo log就划分为了不同的类型，MLOG_1BYTE类型的日志指的就是修改了1个字节的值，MLOG_2BYTE类型的日志指的就是修改了2个字节的值，以此类推，还有修改了4个字节的值的日志类型，修改了8个字节的值的日志类型。



当然，如果你要是一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，就是代表你一下子在那个数据页的某个偏移量的位置插入或者修改了一大串的值。



所以其实一条redo log看起来大致的结构如下所示：



日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，具体修改的数据



大致就是一条redo log中依次排列上述的一些东西，这条redo log表达的语义就很明确了，他的类型是什么，类型就告诉了你他这次增删改操作修改了多少字节的数据；



然后在哪个表空间里操作的，这个就是跟你SQL在哪个表里执行的是对应的；接着就是在这个表空间的哪个数据页里执行的，在数据页的哪个偏移量开始执行的，具体更新的数据是哪些呢。



有了上述信息，就可以精准完美的还原出来一次数据增删改操作做的变动了。



只不过如果是MLOG_WRITE_STRING类型的日志，因为不知道具体修改了多少字节的数据，所以其实会多一个修改数据长度，就告诉你他这次修改了多少字节的数据，如下所示他的格式：



日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据



因此今天就简单给大家讲解一下redo log的日志的格式，其实没大家想的那么复杂，当然如果往深了说，那可能也比你想的复杂很多，比如redo log日志里面可能会记录你更新了哪些索引之类的，那就复杂了去了，但是这些东西就等我们讲到索引那块的时候再说好了！



现在大家对redo log日志的格式了解到这个程度其实就可以了，你脑子里应该更加清晰了一些，就是执行增删改的时候，在Buffer Pool里通过复杂的缓存页机制完成更新，然后就会以今天讲解的这种格式写入一条redo log日志记录本次修改。



## 42 redo log是直接一条一条写入文件的吗？非也，揭秘redo log block！

之前我们已经给大家讲解了redo log自己的一些基本的结构，今天我们就来讲解下一个问题，就是redo log是一条一条的直接就往磁盘文件里写入吗？



可能有一些朋友会认为就是如此简单粗暴的往磁盘文件里写，但其实并没那么简单！



接下来几天我们就会揭秘一下这个redo log写磁盘的过程。



首先大家看下面的图，学习到现在，我想任何一个朋友一看下面的图就知道是怎么回事了



平时我们执行CRUD的时候，从磁盘加载数据页到buffer pool的缓存页里去，然后对缓存页执行增删改，同时还会写redo log到日志文件里去，后续不定时把缓存页刷回磁盘文件里去，大概就是这个原理，如下图所示：

​      ![0.jpg](all_in_one.assets/37000400_1584584105.jpg)       

那么上次我们也介绍了一下每一条redo log长什么样子，说白了，他就是记录了：



表空间号+数据页号+数据页内偏移量+修改了几个字节的数据+实际修改数据



就是简简单单这么一条日志罢了



所以大家可以想一下，redo log就是按照上述格式，一条一条的直接就写入到磁盘上的日志文件里去了吗？



显然不是的！



其实MySQL内有另外一个数据结构，叫做**redo log block**，大概你可以理解为，平时我们的数据不是存放在数据页了的么，用一页一页的数据页来存放数据。



那么对于redo log也不是单行单行的写入日志文件的，他是用一个redo log block来存放多个单行日志的。



一个redo log block是512字节，这个redo log block的512字节分为3个部分，一个是12字节的header块头，一个是496字节的body块体，一个是4字节的trailer块尾



如下图所示

​      ![1.jpg](all_in_one.assets/53388300_1584584116.jpg)       

在这里面，12字节的header头又分为了4个部分。



1. 包括4个字节的block no，就是块唯一编号；
2. 2个字节的data length，就是block里写入了多少字节数据；
3. 2个字节的first record group。这个是说每个事务都会有多个redo log，是一个redo log group，即一组redo log。那么在这个block里的第一组redo log的偏移量，就是这2个字节存储的；
4. 4个字节的checkpoint on



我们看下图，这个header可以进行进一步的区分。

​      ![2.jpg](all_in_one.assets/91762800_1584584123.jpg)       

所以我们看到上图就知道，其实对于我们的redo log而言，他确实是不停的追加写入到redo log磁盘文件里去的，但是其实每一个redo log都是写入到文件里的一个redo log block里去的，一个block最多放496自己的redo log日志。



此时可能有人会有疑问了，到底一个一个的redo log block在日志文件里是怎么存在的？那么一条一条的redo log又是如何写入日志文件里的redo log block里去的呢？估计很多人都很奇怪这个问题。



所以我们接下来就给大家解答这个问题。



大家先想一下，假设你有一个redo log日志文件，平时我们往里面写数据，你大致可以认为是从第一行开始，从左往右写，可能会有很多行，比如下面那样子，你看看是不是你理解的那样？

![3.jpg](all_in_one.assets/68808300_1584584129.jpg)

好，那么所以现在既然如此，假设你要写第一个redo log了，是不是应该起码是先在内存里把这个redo log给弄到一个redo log block数据结构里去？



然后似乎你应该是等内存里的一个redo log block的512字节都满了，再一次性把这个redo log block写入磁盘文件？



如下图所示

​      ![4.jpg](all_in_one.assets/22519400_1584584135.jpg)   

然后其实按照我们所说的，一个redo log block就是512字节，那么是不是真正写入的时候，把这个redo log block的512字节的数据，就写入到redo log文件里去就可以了？那么redo log文件里就多了一个block，如下图所示。



​      ![5.jpg](all_in_one.assets/59038400_1584584142.jpg)

所以大家看到上图演示之后，对于这个所谓的redo log和redo log block的关系，以及redo log block如何进入日志文件，日志文件里是如何存放一个又一个的redo log block的，应该都很清楚了！



其实有一定开发经验的朋友都知道，写文件的时候，可以按照字节，一个字节一个字节的写入的，文件里存放的东西就是很多很多字节，依次排开，然后其中可能512个字节组合起来，就固定代表了一个redo log block。



这其实就是任何一个中间件系统，数据库系统，底层依赖磁盘文件存储数据的一个共同的原理，所以大家也不用把这个复杂数据写入磁盘文件想象的太复杂了。



那么如果依次在磁盘文件里的末尾追加不停的写字节数据，就是磁盘顺序写；但是假设现在磁盘文件里已经有很多很多的redo log block了，此时要在磁盘里某个随机位置找到一个redo log block去修改他里面几个字节的数据，这就是磁盘随机写，看下图。

​      ![6.jpg](all_in_one.assets/51811500_1584584148.jpg)       

好了，今天把redo log block的数据结构和他与磁盘文件的关系都讲的很清楚了，明天我们继续讲解redo log buffer，就是redo log是如何通过一个内存缓冲数据结构之后，再进入到磁盘文件的！



## 43 直接强行把redo log写入磁盘？非也，揭秘redo log buffer！

上一讲我们给大家说了一下redo log block这个概念，大家现在都知道平时我们执行完增删改之后，要写入磁盘的redo log，其实应该是先进入到redo log block这个数据结构里去的，然后再进入到磁盘文件里，如下图所示。

​      ![1.jpg](all_in_one.assets/33293100_1584612939.jpg)

那么今天我们就来讲讲，这个redo log到底是如何通过内存缓冲之后，再进入磁盘文件里去的，这就涉及到了一个新的组件，redo log buffer，他就是MySQL专门设计了用来缓冲redo log写入的。



这个redo log buffer其实就是MySQL在启动的时候，就跟操作系统申请的一块连续内存空间，大概可以认为相当于是buffer pool吧。那个buffer pool是申请之后划分了N多个空的缓存页和一些链表结构，让你把磁盘上的数据页加载到内存里来的。



redo log buffer也是类似的，他是申请出来的一片连续内存，然后里面划分出了N多个空的redo log block，如下图所示。

![2.jpg](all_in_one.assets/21067800_1584612948.jpg)       

通过设置mysql的innodb_log_buffer_size可以指定这个redo log buffer的大小，默认的值就是16MB，其实已经够大了，毕竟一个redo log block才512字节而已，每一条redo log其实也就几个字节到几十个字节罢了。



所以大家看到这里就明白了，上一讲我们就说了，其实redo log都是先写入内存里的redo log block数据结构里去的，然后完事儿了才会把redo log block写入到磁盘文件里去的



这里我们看到了redo log buffer的结构，就很清晰的知道，当你要写一条redo log的时候，就会先从第一个redo log block开始写入，如下图。

​      ![3.jpg](all_in_one.assets/9570300_1584612955.jpg)

写满了一个redo log block，就会继续写下一个redo log block，以此类推，直到所有的redo log block都写满。



那么此时肯定有人会问了，万一要是redo log buffer里所有的redo log block都写满了呢？



那此时必然会强制把redo log block刷入到磁盘中去的！



我们上一次讲到了redo log block刷入磁盘文件中的示意，其实就是把512字节的redo log block追加到redo log日志文件里去就可以了



看下面的图，里面就画的很清楚，在磁盘文件里不停的追加一个又一个的redo block。

​      ![4.jpg](all_in_one.assets/72318500_1584612961.jpg)       

另外还要给大家讲一点的是，其实在我们平时执行一个事务的过程中，每个事务会有多个增删改操作，那么就会有多个redo log，这多个redo log就是一组redo log，其实每次一组redo log都是先在别的地方暂存，然后都执行完了，再把一组redo log给写入到redo log buffer的block里去的。



如果一组redo log实在是太多了，那么就可能会存放在两个redo log block中，我们看下图示意。

​      ![5.jpg](all_in_one.assets/47898300_1584612968.jpg)       

但是反之，如果说一个redo log group比较小，那么也可能多个redo log group是在一个redo log block里的，如下图所示。

​      ![6.jpg](all_in_one.assets/97882400_1584612974.jpg)       

想必今天的内容学习完，大家对于平时我们一个一个的事务里产生的多条redo log ，是如何形成一个redo log组的，一组redo log是如何写入redo log buffer中的redo log block的，然后redo block是如何写入redo log磁盘文件的，这个全流程就有了一个清晰地理解和认识了！



下周我们要继续探索的，就是这个redo log buffer里的redo log block们到底是如何写入到磁盘文件里去的？



一定要等待redo log block全部写满了才会刷入磁盘吗？还有哪些其他的时机会把redo log block刷入磁盘吗？



## 44 redo log buffer中的缓冲日志，到底什么时候可以写入磁盘？

之前我们给大家讲解了一下redo log buffer的缓冲机制，大家现在应该都知道了，redo log在写的时候，都是一个事务里的一组redo log，先暂存在一个地方，完事儿了以后把一组redo log写入redo log buffer。



写入redo log buffer的时候，是写入里面提前划分好的一个一个的redo log block的，选择有空闲空间的redo log block去写入，然后redo log block写满之后，其实会在某个时机刷入到磁盘里去，如下图。

​      ![1.jpg](all_in_one.assets/81670600_1584930161.jpg)       

那么今天我们就来研究一下，到底redo log buffer里的redo log block什么时候可以刷入到磁盘文件里去呢？



另外，磁盘上到底有几个redo log日志文件？不可能大量的redo log日志都放一个文件里吧？磁盘空间会占用的越来越多吗？



首先，我们先来看看redo log block是哪些时候会刷入到磁盘文件里去：



**（1）**如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在缓冲里了，此时就会把他们刷入到磁盘文件里去



**（2）**一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改



*（PS：当然，之前最早最早的时候，我们讲过，这个redo log哪怕事务提交的时候写入磁盘文件，也是先进入os cache的，进入os的文件缓冲区里，所以是否提交事务就强行把redo log刷入物理磁盘文件中，这个需要设置对应的参数，我们之前都讲过的 ，大家回过头去看看 ）*



**（3）**后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去



**（4）**MySQL关闭的时候，redo log block都会刷入到磁盘里去



忽略上面的第四条不说，因为关闭MySQL的时候必然会刷redo log到磁盘，其他三条其实我们都看到了，也就是说，如果你瞬间执行大量的高并发的SQL语句，1秒内就产生了超过8MB的redo log，此时占据了redo log buffer一半的空间了，必然会直接把你的redo log刷入磁盘里去，如下图。

​      ![2.jpg](all_in_one.assets/16193300_1584930162.jpg)       

上面这种redo log刷盘的情况，在MySQL承载高并发请求的时候比较常见，比如每秒执行上万个增删改SQL语句，每个SQL产生的redo log假设有几百个字节，此时却是会在瞬间生成超过8MB的redo log日志，必然会触发立马刷新redo log到磁盘。



其次，第二种情况，其实就是平时执行一个事务，这个事务一般都是在几十毫秒到几百毫秒执行完毕的，说实在的，一般正常性能情况下，MySQL单事务性能一般不会超过1秒，否则数据库操作就太慢了。



那么如果在几十毫秒，或者几百毫秒的时候，执行完毕了一个事务，此时必然会立马把这个事务的redo log都刷入磁盘，如下图。

​      ![3.jpg](all_in_one.assets/41991000_1584930162.jpg)       

第一种情况其实是不常见的，第二种情况是比较常见的，往往redo log刷盘都是以一个短事务提交时候发生的，第三种情况就是后台线程每秒自动刷新redo log到磁盘去，这个就是说假设没有别的情况触发，后台线程自己都会不停的刷新redo log到磁盘。



但是不管怎么说，主要是保证一个事务执行的时候，redo log都进入redo log buffer，提交事务的时候，事务对应的redo log必须是刷入磁盘文件，接着才算是事务提交成功，否则事务提交就是失败，保证这一点，就能确保事务提交之后，数据不会丢，有redo log在磁盘里就行了。



当然，绝对保证数据不丢，还得配置一个参数，提交事务把redo log刷入磁盘文件的os cache之后，还得强行从os cache刷入物理磁盘。



最后给大家说一下redo log日志文件的问题，我们都知道平时不停的执行增删改，那么MySQL会不停的产生大量的redo log写入日志文件，那么日志文件就用一个写入全部的redo log？对磁盘占用空间越来越大怎么办？



别担心，这些问题都可以解决，实际上默认情况下，redo log都会写入一个目录中的文件里，这个目录可以通过show variables like 'datadir'来查看，可以通过innodb_log_group_home_dir参数来设置这个目录的。



然后redo log是有多个的，写满了一个就会写下一个redo log，而且可以限制redo log文件的数量，通过innodb_log_file_size可以指定每个redo log文件的大小，默认是48MB，通过innodb_log_files_in_group可以指定日志文件的数量，默认就2个。



所以默认情况下，目录里就两个日志文件，分别为ib_logfile0和ib_logfile1，每个48MB，最多就这2个日志文件，就是先写第一个，写满了写第二个。那么如果第二个也写满了呢？别担心，继续写第一个，覆盖第一个日志文件里原来的redo log就可以了。



所以最多这个redo log，mysql就给你保留了最近的96MB的redo log而已，不过这其实已经很多了，毕竟redo log真的很小，一条通常就几个字节到几十个字节不等，96MB足够你存储上百万条redo log了！



如果你还想保留更多的redo log，其实调节上述两个参数就可以了，比如每个redo log文件是96MB，最多保留100个redo log文件。下面图里，给大家展示出来了多个redo log文件循环写入的示意。

​      ![4.jpg](all_in_one.assets/75121400_1584930162.jpg)       

我想讲到这里，大家对redo log机制就理解更加深刻了，对于事务产生的redo log如何进入内存缓冲，如何进入block，什么时候刷入磁盘，磁盘上有几个redo log日志文件，这些机制都了解的很清晰了。



## 45 如果事务执行到一半要回滚怎么办？再探undo log回滚日志原理！

之前我们已经给大家深入讲解了在执行增删改操作时候的redo log的重做日志原理，其实说白了，就是你对buffer pool里的缓存页执行增删改操作的时候，必须要写对应的redo log记录下来你做了哪些修改



如下图所示，redo log都是先进入redo log buffer中的一个block，然后事务提交的时候就会刷入磁盘文件里去。

​      ![1.jpg](all_in_one.assets/6711600_1585033113.jpg)       

这样万一要是你提交事务了，结果事务修改的缓存页还没来得及刷入磁盘上的数据文件，此时你MySQL关闭了或者是宕机了，那么buffer pool里被事务修改过的数据就全部都丢失了！



但是只要有redo log，你重启MySQL之后完全是可以把那些修改了缓存页，但是缓存页还没来得及刷入磁盘的事务，他们所对应的redo log都加载出来，在buffer pool的缓存页里重做一遍，就可以保证事务提交之后，修改的数据绝对不会丢！



相信之前讲解了redo log日志之后，大家对这块都理解的更加深刻了，那么今天我们就带着大家来探索另外一种日志，就是undo log日志，也就是回滚日志，这种日志要应对的场景，就是事务回滚的场景！



那么首先大家先思考一个问题，假设现在我们一个事务里要执行一些增删改的操作，那么必然是先把对应的数据页从磁盘加载出来放buffer pool的缓存页里，然后在缓存页里执行一通增删改，同时记录redo log日志，对吧？如下图。

​      ![2.jpg](all_in_one.assets/31750900_1585033113.jpg)      

但是现在问题来了，万一要是一个事务里的一通增删改操作执行到了一半，结果就回滚事务了呢？



比如一个事务里有4个增删改操作，结果目前为止已经执行了2个增删改SQL了，已经更新了一些buffer pool里的数据了，但是还有2个增删改SQL的逻辑还没执行，此时事务要回滚了怎么办？看图

​      ![3.jpg](all_in_one.assets/56541300_1585033113.jpg)       

这个时候就很尴尬了，如果你要回滚事务的话，那么必须要把已经在buffer pool的缓存页里执行的增删改操作给回滚了



但是怎么回滚呢？毕竟无论是插入，还是更新，还是删除，该做的都已经做了啊！



所以在执行事务的时候，才必须引入另外一种日志，就是undo log回滚日志



这个回滚日志，他记录的东西其实非常简单，比如你要是在缓存页里执行了一个insert语句，那么此时你在undo log日志里，对这个操作记录的回滚日志就必须是有一个主键和一个对应的delete操作，要能让你把这次insert操作给回退了。



那么比如说你要是执行的是delete语句，那么起码你要把你删除的那条数据记录下来，如果要回滚，就应该执行一个insert操作把那条数据插入回去。



如果你要是执行的是update语句，那么起码你要把你更新之前的那个值记录下来，回滚的时候重新update一下，把你之前更新前的旧值给他更新回去。



如果你要是执行的是select语句呢？不好意思，select语句压根儿没有在buffer pool里执行任何修改，所以根本不需要undo log！



好，所以我们来看下图，其实你在执行事务期间，之前我们最开始的几篇文章就讲过，你除了写redo log日志还必须要写undo log日志，这个undo log日志是至关重要的，没有他，你根本都没办法回滚事务！

​      ![4.jpg](all_in_one.assets/85888100_1585033113.jpg)       

明天我们继续来看看insert、delete和update几种操作的undo log到底长什么样，相信大家看完了，就会对undo log这块机制有一个更加深刻的理解了。



## 46 一起来看看INSRET语句的undo log回滚日志长什么样？

昨天我们讲解了undo log回滚日志的作用，说白了，就是你执行事务的时候，里面很多INSERT、UPDATE和DELETE语句都在更新缓存页里的数据，但是万一事务回滚，你必须有每条SQL语句对应的undo log回滚日志，根据回滚日志去恢复缓存页里被更新的数据。



比如你执行了INSERT语句，那么你的undo log必须告诉你插入数据的主键ID，让你在回滚的时候可以从缓存页里把这条数据给删除了；



如果你执行了DELETE语句，那么你的undo log必须记录下来被删除的数据，回滚的时候就得重新插入一条数据；



如果你执行了UPDATE语句，那么你必须记录下来修改之前的数据，回滚的时候就得把数据给更新回去，如下图所示。

​      ![1.jpg](all_in_one.assets/57555500_1585113017.jpg)       

那么今天我们就一起来看看这个INSERT语句的undo log日志到底长什么样子呢？



INSERT语句的undo log的类型是TRX_UNDO_INSERT_REC，这个undo log里包含了以下一些东西：



- 这条日志的开始位置
- 主键的各列长度和值
- 表id
- undo log日志编号
- undo log日志类型
- 这条日志的结束位置



接下来我们来给大家解释一下，首先，一条日志必须得有自己的一个开始位置，这个没什么好说的是吧？



那么主键的各列长度和值是什么意思？大家都知道，你插入一条数据，必然会有一个主键！



如果你自己指定了一个主键，那么可能这个主键就是一个列，比如id之类的，也可能是多个列组成的一个主键，比如“id+name+type”三个字段组成的一个联合主键，也是有可能的。



所以这个主键的各列长度和值，意思就是你插入的这条数据的主键的每个列，他的长度是多少，具体的值是多少。即使你没有设置主键，MySQL自己也会给你弄一个row_id作为隐藏字段，做你的主键。



接着是表id，这个就不用多说了，你插入一条数据必然是往一个表里插入数据的，那当然得有一个表id，记录下来是在哪个表里插入的数据了。



undo log日志编号，这个意思就是，每个undo log日志都是有自己的编号的。



而在一个事务里会有多个SQL语句，就会有多个undo log日志，在每个事务里的undo log日志的编号都是从0开始的，然后依次递增。



至于undo log日志类型，就是TRX_UNDO_INSERT_REC，insert语句的undo log日志类型就是这个东西。



最后一个undo log日志的结束位置，这个自然也不用多说了，他就是告诉你undo log日志结束的位置是什么。



那么接着我们用一个图画一下这个INSERT语句的undo log回滚日志的结构，大家来看一眼，感受一下。

![2.jpg](all_in_one.assets/4450700_1585113024.jpg)       

大家可以想象一下，有了这条日志之后，剩下的事儿就好办了



万一要是你现在在buffer pool的一个缓存页里插入了一条数据了，执行了insert语句，然后你写了一条上面的那种undo log，现在事务要是回滚了，你直接就把这条insert语句的undo log拿出来。



然后在undo log里就知道在哪个表里插入的数据，主键是什么，直接定位到那个表和主键对应的缓存页，从里面删除掉之前insert语句插入进去的数据就可以了，这样就可以实现事务回滚的效果了！



好了，今天先初步的看一下insert语句的undo log回顾日志，delete语句和update语句的回滚日志我们暂时就不细讲了，其实大家应该都能想象到他们是如何实现的。



## 47 简单回顾一下， MySQL运行时多个事务同时执行是什么场景？

到目前为止，我们已经给大家深入讲解了MySQL的buffer pool机制、redo log机制和undo log机制，相信大家现在对我们平时执行一些增删改语句的实现原理，都有了一定较为深入的理解了！



因为平时我们执行增删改的时候，无非就是从磁盘加载数据页到buffer pool的缓存页里去，对缓存页进行更新，同时记录下来undo log回滚日志和redo log重做日志，应对的是事务提交之后MySQL挂了恢复数据的场景，以及事务回滚的场景。



那么接下来其实我们要理解的东西，就是要提高一个层次了，我们要理解到事务这个层面了



所谓的事务呢，其实或多或少每个人都是知道一点的，我们今天只不过是站在MySQL内核原理的角度，拔高到事务的层面给大家回顾一下。



其实大家可以思考，平时我们是不是一般都是写一个业务系统，然后业务系统会去对数据库执行增删改查？



好，我们看下图

![471.jpg](all_in_one.assets/62305900_1585113195.jpg)   

然后我们应该都知道一件事情，通常而言，我们都是在业务系统里会开启事务来执行增删改操作的，我随便给大家举个例子，下面的代码大家看看。



![image.png](all_in_one.assets/45802000_1585113195.png)



所以一般来说，业务系统是执行一个一个的事务，每个事务里可能是一个或者多个增删改查的SQL语句



这个事务的概念想必不用我多说了，其实就是一个事务里的SQL要不然一起成功就提交了，要不然有一个SQL失败，那么事务就回滚了，所有SQL做的修改都撤销了！我们看下图。

​      ![472.jpg](all_in_one.assets/80478500_1585113195.jpg)       

接着问题来了，这个业务系统他可不是一个单线程系统啊！他是有很多线程的！



因为他面向的终端用户是有很多人的，可能会同时发起请求，所以他需要多个线程并发来处理多个请求的



于是，这个业务系统很可能是基于多线程并发的对MySQL数据库去执行多个事务的！看下图。

​      ![473.jpg](all_in_one.assets/1864500_1585113196.jpg)

那么每个事务里面的多个SQL语句都是如何执行的呢？



其实就是我们之前给大家讲过的那一套原理了，包括从磁盘加载数据页到buffer pool的缓存页里去，然后更新buffer pool里的缓存页，同时记录redo log和undo log，如下图所示。

​      ![474.jpg](all_in_one.assets/28152300_1585113196.jpg)       

每个事务如果提交了，那么就皆大欢喜，这个提交的过程我之前最早就讲过了，他有一些步骤，包括在redo log里记录事务提交标识之类的。



如果事务提交之后，redo log刷入磁盘，结果MySQL宕机了，是可以根据redo log恢复事务修改过的缓存数据的。



如果要回滚事务，那么就基于undo log来回滚就可以了，把之前对缓存页做的修改都给回滚了就可以了。



这就是在MySQL内核层面，把多个事务和我们之前讲解的buffer pool、redo log、undo log几个机制都结合在一起的一个场景讲解。想必大家都是可以理解的。



但是这里就有很多问题了：

- 多个事务并发执行的时候，可能会同时对缓存页里的一行数据进行更新，这个冲突怎么处理？是否要加锁？
- 可能有的事务在对一行数据做更新，有的事务在查询这行数据，这里的冲突怎么处理？



所以接下来，我们要给大家讲解的，**就是解决多个事务并发运行的时候，同时写和同时读写的一些并发冲突的处理机制，包括了MySQL事务的隔离级别、MVCC多版本隔离、锁机制，等等。**



## 48 多个事务并发更新以及查询数据，为什么会有脏写和脏读的问题？

上一次我们已经讲到，其实对于我们的业务系统去访问数据库而言，他往往都是多个线程并发执行多个事务的，对于数据库而言，他会有多个事务同时执行，可能这多个事务还会同时更新和查询同一条数据，所以这里会有一些问题需要数据库来解决，如下图。

​      ![481.jpg](all_in_one.assets/k89jg0a10at0dz171hnp.jpg)    

每个事务都会执行各种增删改查的语句，把磁盘上的数据页加载到buffer pool的缓存页里来，然后更新缓存页，记录redo log和undo log，最终提交事务或者是回滚事务，多个事务会并发干上述一系列事情。



所以今天我们就要来看看，如果多个事务要是对缓存页里的同一条数据同时进行更新或者查询，此时会产生哪些问题呢？



这里实际上会涉及到**脏写、脏读、不可重复读、幻读**，四种问题。



先看第一种问题，脏写



这个脏写的话，他的意思就是说有两个事务，事务A和事务B同时在更新一条数据，事务A先把他更新为A值，事务B紧接着就把他更新为B值，如下图所示

​      ![482.jpg](all_in_one.assets/k89jg0a101swf11idfos.jpg)

大家可以看到，此时事务B是后更新那行数据的值，所以此时那行数据的值是不是B值？



没错的。而且此时事务A更新之后会记录一条undo log日志，大家应该还记得吧。事务A是先更新的，他在更新之前，这行数据的值为NULL，对吧？



所以此时事务A的undo log日志大概就是：更新之前这行数据的值为NULL，主键为XX



好，那么此时事务B更新完了数据的值为B，结果此时事务A突然回滚了，那么就会用他的undo log日志去回滚。



此时事务A一回滚，直接就会把那行数据的值更新回之前的NULL值！所以此时事务A回滚了，可能看起来这行数据的值就是NULL了，如下图。

​      ![483.jpg](all_in_one.assets/k89jg0a10cowheodv72n.jpg)      

然后就尴尬了，事务B一看，我的妈呀，为什么我更新的B值没了？就因为你事务A反悔了就把数据值回滚成NULL了，搞的我更新的B值也没了，这也太坑爹了吧！



所以对于事务B看到的场景，就是自己明明更新了，结果值却没了，**这就是脏写**！



所谓脏写，就是我刚才明明写了一个数据值，结果过了一会儿却没了！真是莫名其妙。



而他的本质就是事务B去修改了事务A修改过的值，但是此时事务A还没提交，所以事务A随时会回滚，导致事务B修改的值也没了，这就是脏写的定义。



接着我们继续看坑爹的脏读问题



假设事务A更新了一行数据的值为A值，此时事务B去查询了一下这行数据的值，看到的值是不是A值？没错，此时如下图所示。

​      ![484.jpg](all_in_one.assets/k89jg0a201h0p9t37366.jpg)       

好，现在事务B可能还挺high的，拿着刚才查询到的A值做各种业务处理。大家知道，每个事务都是业务系统发出的，所以业务系统里的事务B此时肯定会拿到刚查出来的A值在做一些业务处理。



但是接着坑爹的事情发生了，事务A突然回滚了事务，导致他刚才更新的A值没了，此时那行数据的值回滚为NULL值！



然后事务B紧接着此时再次查询那行数据的值，看到的居然此时是NULL值？事务B此时简直欲哭无泪，看下图：

![485.jpg](all_in_one.assets/k89jg0a20e97r9h2gqy5.jpg)       

所以这就是坑爹的脏读，他的本质其实就是事务B去查询了事务A修改过的数据，但是此时事务A还没提交，所以事务A随时会回滚导致事务B再次查询就读不到刚才事务A修改的数据了！这就是脏读。



好了，今天我们先初步看一下脏写和脏读两种问题，相信大家有了之前的大量MySQL底层知识原理的铺垫，理解这两个问题，肯定是小case，轻松+愉快的



其实一句话总结，**无论是脏写还是脏读，都是因为一个事务去更新或者查询了另外一个还没提交的事务更新过的数据。**



**因为另外一个事务还没提交，所以他随时可能会反悔会回滚，那么必然导致你更新的数据就没了，或者你之前查询到的数据就没了，这就是脏写和脏读两种坑爹场景。**



## 49 一个事务多次查询一条数据读到的都是不同的值，这就是不可重复读？

上一讲我们说完了多个事务并发执行时候，对MySQL的缓存页里的同一行数据同时进行更新或者查询的时候，可能发生的脏写和脏读的问题



我们也都理解了，之所以会发生脏写和脏读，最关键的，其实是因为你一个事务写或者查的是人家事务还没提交的时候更新过的数据，所以人家事务随时会反悔回滚，导致你这里有问题。



那么今天我们继续看多个事务并发执行时候的另外两种问题：**一个是不可重复读，一个是幻读**



这两种问题都会奇葩一些，大家仔细看下面的图演示。



先来说说这个不可重复读的问题，这个问题是这样的：假设我们有一个事务A开启了，在这个事务A里会多次对一条数据进行查询



然后呢，另外有两个事务，一个是事务B，一个是事务C，他们俩都是对一条数据进行更新的。



然后我们假设一个前提，就是比如说事务B更新数据之后，如果还没提交，那么事务A是读不到的，必须要事务B提交之后，他修改的值才能被事务A给读取到，其实这种情况下，就是我们首先避免了脏读的发生。



因为脏读的意思就是事务A可以读到事务B修改过还没提交的数据，此时事务B一旦回滚，事务A再次读就读不到了，那么此时就会发生脏读问题。



我们现在假设的前提是事务A只能在事务B提交之后读取到他修改的数据，所以此时必然是不会发生脏读的



好了，但是你以为没有脏读就万事大吉了吗？绝对不是，此时会有另外一个问题，叫做**不可重复读**



假设缓存页里一条数据原来的值是A值，此时事务A开启之后，第一次查询这条数据，读取到的就是A值，如下图所示。

​      ![491.jpg](all_in_one.assets/k89jg12s0jiwle2vonup.jpg)  

接着事务B更新了那行数据的值为B值，同时事务B立马提交了，然后事务A此时可是还没提交！



大家注意，此时事务A是没提交的，他在事务执行期间第二次查询数据，此时查到的是事务B修改过的值，B值，因为事务B已经提交了，所以事务A可以读到的了，此时如下图所示。

​      ![492.jpg](all_in_one.assets/k89jg1500as48bssisou.jpg)

紧接着事务C再次更新数据为C值，并且提交事务了，此时事务A在没提交的情况下，第三次查询数据，查到的值为C值，如下图所示。

​      ![493.jpg](all_in_one.assets/k89jg1ga0wco363o5oxi.jpg)       

好，那么上面的场景有什么问题呢？



其实要说没问题也可以是没问题，毕竟事务B和事务C都提交之后，事务A多次查询查到他们修改的值，是ok的。



但是你要说有问题，也可以是有问题的，就是事务A可能第一次查询到的是A值，那么他可能希望的是在事务执行期间，如果多次查询数据，都是同样的一个A值，他希望这个A值是他重复读取的时候一直可以读到的！他希望这行数据的值是可重复读的！



但是此时，明显A值不是可重复读的，因为事务B和事务C一旦更新了值并且提交了，事务A会读到别的值，所以此时这行数据的值是不可重复读的！此时对于你来说，这个不可重复读的场景，就是一种问题了！



不知道大家看到这里理解了没？如果没理解，反复把这个例子看几遍，理解一下！



上面描述的，其实就是不可重复读的问题，其实这个问题你说是问题也不一定就是什么大问题，但是说他有问题，确实是有问题的。



因为这取决于你自己想要数据库是什么样子的，如果你希望看到的场景就是不可重复读，也就是事务A在执行期间多次查询一条数据，每次都可以查到其他已经提交的事务修改过的值，那么就是不可重复读的，如果你希望这样子，那也没问题。



但是如果你希望的是，假设你事务A刚开始执行，第一次查询读到的是值A，然后后续你希望事务执行期间，读到的一直都是这个值A，不管其他事务如何更新这个值，哪怕他们都提交了，你就希望你读到的一直是第一次查询到的值A，那么你就是希望可重复读的。



如果你期望的是可重复读，但是数据库表现的是不可重复读，让你事务A执行期间多次查到的值都不一样，都是别的提交过的事务修改过的值，那么此时你就可以认为，数据库有问题，这个问题就是“不可重复读”的问题！



不知道大家听懂这个不可重复读的问题了吗？稍微有点绕口，但是我觉得这篇文章已经解释的很清晰了，请大家反复看2遍，一定会理解可重复读和不可重复读的区别，以及为什么不可重复读会定义为一种数据库的问题呢！



## 50 听起来很恐怖的数据库幻读，到底是个什么奇葩问题？

上一讲我们给大家讲解了不可重复读这个问题，这个问题简单来说，就是一个事务多次查询一条数据，结果每次读到的值都不一样，这个过程中可能别的事务会修改这条数据的值，而且修改值之后事务都提交了，结果导致人家每次查到的值都不一样，都查到了提交事务修改过的值，这就是所谓的不可重复读。



不可重复读，就是一条数据的值没法满足多次重复读值都一样，别的事务修改了值提交之后，就不可重复读了，说着有点拗口，不过相信大家应该反复看两遍，应该都能理解



包括之前的脏写和脏读其实也都分别代表了不同的数据库的问题，脏写就是两个事务没提交的状况下，都修改同一条数据，结果一个事务回滚了，把另外一个事务修改的值也给撤销了，所谓脏写就是两个事务没提交状态下修改同一个值。



脏读就是一个事务修改了一条数据的值，结果还没提交呢，另外一个事务就读到了你修改的值，然后你回滚了，人家事务再次读，就读不到了，也就是说人家事务读到了你修改之后还没提交的值，这就是脏读了。



而不可重复读，针对的是已经提交的事务修改的值，被你事务给读到了，你事务内多次查询，多次读到的是别的已经提交的事务修改过的值，这就导致不可重复读了。



这个数据库的多种并发问题，确实很拗口，需要大家好好理解。



今天我们来最后讲一种数据库的并发问题，就是听着有点恐怖的幻读问题，幻读听起来很恐怖，搞的跟邪恶的巫师给你搞什么魔法一样，是不是？



其实没那么恐怖的，我们今天给大家来讲讲。



简单来说，你一个事务A，先发送一条SQL语句，里面有一个条件，要查询一批数据出来，比如“select * from table where id>10”，类似这种SQL



然后呢，他一开始查询出来了10条数据，如下图所示。

​      ![0.jpg](all_in_one.assets/k8fnaug60m7fie2wut1.jpg)  

接着这个时候，别的事务B往表里插入了几条数据，而且事务B还提交了，如下图所示，此时多了几行数据出来。

​      ![1.jpg](all_in_one.assets/k8fnb06f0uwt0yhwhdrd.jpg)

接着事务A此时第三次查询，再次按照之前的一模一样的条件执行“select * from table where id>10”这条SQL语句，由于其他事务插入了几条数据，导致这次他查询出来了12条数据，如下图所示。

​      ![2.jpg](all_in_one.assets/k8fnb4et0wixbedyl01j.jpg)

于是此时事务A开始怀疑自己的双眼了，为什么一模一样的SQL语句，第一次查询是10条数据，第二次查询是12条数据？难道刚才出现了幻觉？导致我刚才幻读了？这就是幻读这个名词的由来。



幻读指的就是你一个事务用一样的SQL多次查询，结果每次查询都会发现查到了一些之前没看到过的数据



注意，幻读特指的是你查询到了之前查询没看到过的数据！此时就说你是幻读了。



说实在的，大家看完最近几篇文章，应该都有一个感觉，就是脏写、脏读、不可重复读、幻读，都是因为业务系统会多线程并发执行，每个线程可能都会开启一个事务，每个事务都会执行增删改查操作。



然后数据库会并发执行多个事务，多个事务可能会并发的对缓存页里的同一批数据进行增删改查操作，于是这个并发增删改查同一批数据的问题，可能就会导致我们说的脏写、脏读、不可重复读、幻读，这些问题。



所以这些问题的本质，都是数据库的多事务并发问题，那么为了解决多事务并发问题，数据库才设计了事务隔离机制、MVCC多版本隔离机制、锁机制，用一整套机制来解决多事务并发问题，接下来，我们将要深入讲解这些机制，让大家彻底能够理解数据库内部的执行原理。



深刻理解了原理之后，后续我们讲解各种数据库优化实践案例，大家才能深刻理解，就跟我之前的《从0开始带你成为JVM实战高手》一样，先得透彻理解了JVM运行的工作原理，才能理解如何对JVM进行实战优化。



只不过JVM的内部运行原理比数据库而言相对内容少一些，所以当时很快就进入了大量的实践案例阶段，而数据库的话，内部原理会更加复杂一些，所以耗费的时间会多一些。



## 51 SQL标准中对事务的4个隔离级别，都是如何规定的呢？

之前我们给大家讲了数据库中多个事务并发时可能产生的几种问题，包括了脏写、脏读、不可重复读、幻读，几种问题



那么针对这些多事务并发的问题，实际上SQL标准中就规定了事务的几种隔离级别，用来解决这些问题。



注意一下，我们今天讲的这个SQL标准的事务隔离级别，并不是MySQL的事务隔离级别，MySQL在具体实现事务隔离级别的时候会有点差别，这个我们下一次再讲，今天先关注SQL标准是如何规定事务隔离级别的。



在SQL标准中规定了4种事务隔离级别，就是说多个事务并发运行的时候，互相是如何隔离的，从而避免一些事务并发问题



这4种级别包括了：**read uncommitted（读未提交），read committed（读已提交），repeatable read（可重复读），serializable（串行化）**



不同的隔离级别是可以避免不同的事务并发问题的，所以大家一定要对这个事务隔离级别有一个深刻的理解。



第一个read uncommitted隔离级别，是不允许发生脏写的



也就是说，不可能两个事务在没提交的情况下去更新同一行数据的值，但是在这种隔离级别下，可能发生脏读，不可重复读，幻读。



感觉如何？是不是感觉这种隔离级别让你整个人都感觉不好了！因为脏读的话，就是人家事务在没提交情况下修改的值，居然被你读到了，人家随时可能会回滚的！而且你执行期间多次查询一行数据，可能读到的值都不同，因为别的事务随时会修改值再提交，这个值是不可重复读的！幻读更不用说了，肯定会发生。



说实在的，一般来说，是没有人做系统开发的时候，傻到把事务隔离级别设置为读未提交这个级别的。



第二个是read committed隔离级别，这个级别下，不会发生脏写和脏读



也就是说，人家事务没提交的情况下修改的值，你是绝对读不到的！但是呢，可能会发生不可重复读和幻读问题，因为一旦人家事务修改了值然后提交了，你事务是会读到的，所以可能你多次读到的值是不同的！



这里教给大家一个稍微有点骚气的简写名词，就是RC，一般如果你在公司里做开发，有个其他团队的兄弟讨论技术方案的时候，跟你来了句，把事务隔离级别设置成RC！这个时候你不要目瞪口呆，知道是读已提交级别就行了。



你只要记住，这个级别在别的事务已经提交之后读到他们修改过的值就可以了，但是别的事务没提交的时候，绝对不会读到人家修改的值。



第三个是REPEATABLE READ隔离级别，就是可重复读级别



这个级别下，不会发生脏写、脏读和不可重复读的问题，因为你一个事务多次查询一个数据的值，哪怕别的事务修改了这个值还提交了，没用，你不会读到人家提交事务修改过的值，你事务一旦开始，多次查询一个值，会一直读到同一个值！



我们给大家一个图看看这个RR级别的效果，以后记得这个骚气的简写词，就是RR，公司里有兄弟让你把事务设置成RR的时候，你也不要一脸懵逼。



一个事务A，第一次查询一行数据的值是值A，如下图所示。

![511.jpg](all_in_one.assets/k8ix7dot0pjoumj58dg.jpg)

接着事务B修改了这行数据的值为值B，还提交了，如下图所示。

![512.jpg](all_in_one.assets/k8ix7dot008zbxilmbck.jpg)

接着事务A再次查询这行数据的值，读到的还是值A，因为他在事务执行期间，多次读一行数据，绝对读到的都是一样的值，他是允许可重复读的！希望大家理解一下这个概念，可重复读！如下图。

![513.jpg](all_in_one.assets/k8ix7dot05ijqg3hnawu.jpg)

这就是第三种隔离级别，给一个骚气的名字，RR级别，记住了RR级别保证你不会读到人家已经提交的事务修改过的值！但是他还是会发生幻读的



因为假设你一次SQL是根据条件查询，比如“select * from table where id>10”，第一次查出来10条数据，结果另外一个事务插入了一条数据，下次你可能会查出来11条数据，还是会有幻读问题的！



RR隔离级别，只不过保证对同一行数据的多次查询，你不会读到不一样的值，人家已提交事务修改了这行数据的值，对你也没影响！



最后一个隔离就别，就是serializable级别，这种级别，根本就不允许你多个事务并发执行，只能串行起来执行，先执行事务A提交，然后执行事务B提交，接着执行事务C提交，所以此时你根本不可能有幻读的问题，因为事务压根儿都不并发执行！



但是这种级别一般除非脑子坏了，否则更不可能设置了，因为多个事务串行，那数据库很可能一秒并发就只有几十了，性能会极差的。



好了，今天就把SQL标准里的四种隔离级别讲完了，**大家一定要记住非常骚气的RC和RR级别**，因为平时比较常见的就是用RC和RR两种隔离级别。



下次我们继续讲MySQL里是如何支持事务隔离级别的，同时在Spring的事务注解里是如何设置事务隔离级别的。



## 52 MySQL是如何支持4种事务隔离级别的？Spring事务注解是如何设置的？

上次我们讲完了SQL标准下的4种事务隔离级别，平时比较多用的就是RC和RR两种级别，那么在MySQL中也是支持那4种隔离级别的，基本的语义都是差不多的



但是要注意的一点是，MySQL默认设置的事务隔离级别，都是RR级别的，而且MySQL的RR级别是可以避免幻读发生的。



这点是MySQL的RR级别的语义跟SQL标准的RR级别不同的，毕竟SQL标准里规定RR级别是可以发生幻读的，但是MySQL的RR级别避免了！



也就是说，MySQL里执行的事务，默认情况下不会发生脏写、脏读、不可重复读和幻读的问题，事务的执行都是并行的，大家互相不会影响，我不会读到你没提交事务修改的值，即使你修改了值还提交了，我也不会读到的，即使你插入了一行值还提交了，我也不会读到的，总之，事务之间互相都完全不影响！



当然，要做到这么神奇和牛叉的效果，MySQL是下了苦功夫的，后续我们接着就要讲解MySQL里的MVCC机制，就是多版本并发控制隔离机制，依托这个MVCC机制，就能让RR级别避免不可重复读和幻读的问题。



然后给大家说一下，假设你要修改MySQL的默认事务隔离级别，是下面的命令，可以设置级别为不同的level，level的值可以是REPEATABLE READ，READ COMMITTED，READ UNCOMMITTED，SERIALIZABLE几种级别。



SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;



但是一般来说，真的其实不用修改这个级别，就用默认的RR其实就特别好，保证你每个事务跑的时候都没人干扰，何乐而不为呢？



另外，给大家说一下，假设你在开发业务系统的时候，比如用Spring里的@Transactional注解来做事务这块，假设某个事务你就是有点手痒痒，就想给弄成RC级别，你就想读到人家已经提交事务修改过的值，好，那么没问题。



在@Transactional注解里是有一个isolation参数的，里面是可以设置事务隔离级别的，具体的设置方式如下：



@Transactional(isolation=Isolation.DEFAULT)，然后默认的就是DEFAULT值，这个就是MySQL默认支持什么隔离级别就是什么隔离级别。



那MySQL默认是RR级别，自然你开发的业务系统的事务也都是RR级别的了。



但是你可以手动改成Isolation.READ_UNCOMMITTED级别，此时你就可以读到人家没提交事务修改的值了，够坑的！估计一般没人自己坑自己吧！



也可以改成Isolation.READ_COMMITTED，Isolation.REPEATABLE_READ，Isolation.SERIALIZABLE几个级别，都是可以的。



但是再次提醒，其实默认的RR隔离机制挺好的，真的没必要去修改，除非你一定要在你的事务执行期间多次查询的时候，必须要查到别的已提交事务修改过的最新值，那么此时你的业务有这个要求，你就把Spring的事务注解里的隔离级别设置为Isolation.READ_COMMITTED级别，偶尔可能也是有这种需求的。



好了，事务的并发问题以及事务隔离级别，我们迄今为止已经剖析的很透彻了，接下来就开始讲解MVCC机制，透彻剖析MySQL是怎么实现牛叉的RR级别的，怎么就能让事务互相之间彻底隔离开来呢？



## 53 理解MVCC机制的前奏：undo log版本链是个什么东西？

今天我们正式开始切入讲解MySQL中多个事务并发执行时的隔离到底是怎么做的，因为我们知道默认是骚气的RR隔离级别，也就是说脏写、脏读、不可重复读、幻读，都不会发生，每个事务执行的时候，跟别的事务压根儿就没关系，甭管你别的事务怎么更新和插入，我查到的值都是不变的，是一致的！



但是这到底是怎么做到的呢？



这就是由经典的**MVCC多版本并发控制机制**做到的，但是讲解这个MVCC机制之前，我们还得先讲讲undo log版本链的故事，这是一个前奏，了解了这个机制，大家才能更好的理解MVCC机制。



简单来说呢，我们每条数据其实都有两个隐藏字段，一个是trx_id，一个是roll_pointer，这个trx_id就是最近一次更新这条数据的事务id，roll_pointer就是指向你了你更新这个事务之前生成的undo log，关于undo log之前都讲过了，这里不用多说了。



我们给大家举个例子，现在假设有一个事务A（id=50），插入了一条数据，那么此时这条数据的隐藏字段以及指向的undo log如下图所示，插入的这条数据的值是值A，因为事务A的id是50，所以这条数据的txr_id就是50，roll_pointer指向一个空的undo log，因为之前这条数据是没有的。

![531.jpg](all_in_one.assets/k8ix7dou03py6ce6om3g.jpg)

接着假设有一个事务B跑来修改了一下这条数据，把值改成了值B，事务B的id是58，那么此时更新之前会生成一个undo log记录之前的值，然后会让roll_pointer指向这个实际的undo log回滚日志，如下图所示。

![532.jpg](all_in_one.assets/k8ix7dou0nq1rzsgte2.jpg)

大家看上图是不是觉得很有意思？事务B修改了值为值B，此时表里的那行数据的值就是值B了，那行数据的txr_id就是事务B的id，也就是58，roll_pointer指向了undo log，这个undo log就记录你更新之前的那条数据的值。



所以大家看到roll_pointer指向的那个undo log，里面的值是值A，txr_id是50，因为undo log里记录的这个值是事务A插入的，所以这个undo log的txr_id就是50，我还特意把表里的那行数据和undo log的颜色弄成不一样的，以示区分。



接着假设事务C又来修改了一下这个值为值C，他的事务id是69，此时会把数据行里的txr_id改成69，然后生成一条undo log，记录之前事务B修改的那个值



此时如下图所示，看起来如下。

![533.jpg](all_in_one.assets/k8ix7ea10sc977ccpoml.jpg)

我们在上图可以清晰看到，数据行里的值变成了值C，txr_id是事务C的id，也就是69，然后roll_pointer指向了本次修改之前生成的undo log，也就是记录了事务B修改的那个值，包括事务B的id，同时事务B修改的那个undo log还串联了最早事务A插入的那个undo log，如图所示，过程很清晰明了。



所以这就是今天要给大家讲的一点，大家先不管多个事务并发执行是如何执行的，起码先搞清楚一点，就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段txr_id和roll_pointer，同时之前多个数据快照对应的undo log，会通过roll_pinter指针串联起来，形成一个重要的版本链！



今天要让大家明白的，就是这个多个事务串行更新一行数据的时候，txr_id和roll_pinter两个隐藏字段的概念，包括undo log串联起来的多版本链条的概念！



## 54 基于undo log多版本链条实现的ReadView机制，到底是什么？

接着上次我们讲过的undo log多版本链条，我们来讲讲这个基于undo log多版本链条实现的ReadView机制



把这个机制讲明白了，下一次我们再正式讲解RC和RR隔离级别下的MVCC多版本并发控制机制，就很容易理解了。



这个ReadView呢，简单来说，就是你执行一个事务的时候，就给你生成一个ReadView，里面比较关键的东西有4个



- 一个是m_ids，这个就是说此时有哪些事务在MySQL里执行还没提交的；
- 一个是min_trx_id，就是m_ids里最小的值；
- 一个是max_trx_id，这是说mysql下一个要生成的事务id，就是最大事务id；
- 一个是creator_trx_id，就是你这个事务的id



那么现在我们来举个例子，让大家通过例子来理解这个ReadView是怎么用的



假设原来数据库里就有一行数据，很早以前就有事务插入过了，事务id是32，他的值就是初始值，如下图所示。

![541.jpg](all_in_one.assets/k8ix7een0rcze8pp0jwr.jpg)

接着呢，此时两个事务并发过来执行了，一个是事务A（id=45），一个是事务B（id=59），事务B是要去更新这行数据的，事务A是要去读取这行数据的值的，此时两个事务如下图所示。

​      ![1.jpg](all_in_one.assets/kg3e0vvu04u7dv90cxcc.jpg)

现在事务A直接开启一个ReadView，这个ReadView里的m_ids就包含了事务A和事务B的两个id，45和59，然后min_trx_id就是45，max_trx_id就是60，creator_trx_id就是45，是事务A自己。



这个时候事务A第一次查询这行数据，会走一个判断，就是判断一下当前这行数据的txr_id是否小于ReadView中的min_trx_id，此时发现txr_id=32，是小于ReadView里的min_trx_id就是45的，说明你事务开启之前，修改这行数据的事务早就提交了，所以此时可以查到这行数据，如下图所示。

​      ![543.jpg](all_in_one.assets/k8ix7eqg0qkxloyqxa7f.jpg)

接着事务B开始动手了，他把这行数据的值修改为了值B，然后这行数据的txr_id设置为自己的id，也就是59，同时roll_pointer指向了修改之前生成的一个undo log，接着这个事务B就提交了，如下图所示。

​      ![544.jpg](all_in_one.assets/k8ix7exd0pt9lmt3od1p.jpg)

这个时候事务A再次查询，此时查询的时候，会发现一个问题，那就是此时数据行里的txr_id=59，那么这个txr_id是大于ReadView里的min_txr_id(45)，同时小于ReadView里的max_trx_id（60）的，说明更新这条数据的事务，很可能就跟自己差不多同时开启的，于是会看一下这个txr_id=59，是否在ReadView的m_ids列表里？



果然，在ReadView的m_ids列表里，有45和59两个事务id，直接证实了，这个修改数据的事务是跟自己同一时段并发执行然后提交的，所以对这行数据是不能查询的！如下图所示。

​      ![545.jpg](all_in_one.assets/k8ix7f300qf35mzwtq1.jpg)

那么既然这行数据不能查询，那查什么呢？



简单，顺着这条数据的roll_pointer顺着undo log日志链条往下找，就会找到最近的一条undo log，trx_id是32，此时发现trx_id=32，是小于ReadView里的min_trx_id（45）的，说明这个undo log版本必然是在事务A开启之前就执行且提交的。



好了，那么就查询最近的那个undo log里的值好了，这就是undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值，如下图。

​      ![546.jpg](all_in_one.assets/k8ix7f990mrmyog6rn0j.jpg)

看到这里，大家有没有觉得很奇妙？多个事务并发执行的时候，事务B更新的值，通过这套**ReadView+undo log**日志链条的机制，就可以保证事务A不会读到并发执行的事务B更新的值，只会读到之前最早的值。



接着假设事务A自己更新了这行数据的值，改成值A，trx_id修改为45，同时保存之前事务B修改的值的快照，如下图所示。

​      ![547.jpg](all_in_one.assets/k8ix7fg40e233c40xf8g.jpg)

此时事务A来查询这条数据的值，会发现这个trx_id=45，居然跟自己的ReadView里的creator_trx_id（45）是一样的，说明什么？



说明这行数据就是自己修改的啊！自己修改的值当然是可以看到的了！如下图。

​      ![548.jpg](all_in_one.assets/k8ix7flt0boood1g4hzd.jpg)

接着在事务A执行的过程中，突然开启了一个事务C，这个事务的id是78，然后他更新了那行数据的值为值C，还提交了，如下图所示。

​      ![549.jpg](all_in_one.assets/k8ix7fqt0gqzbiktt2z.jpg)

这个时候事务A再去查询，会发现当前数据的trx_id=78，大于了自己的ReadView中的max_trx_id（60），此时说明什么？



说明是这个事务A开启之后，然后有一个事务更新了数据，自己当然是不能看到的了！如下图。

​      ![550.jpg](all_in_one.assets/k8ix7fws0p1fcslhmaz.jpg)

此时就会顺着undo log多版本链条往下找，自然先找到值A自己之前修改的过的那个版本，因为那个trx_id=45跟自己的ReadView里的creator_trx_id是一样的，所以此时直接读取自己之前修改的那个版本，如下图。

​      ![5501.jpg](all_in_one.assets/k8ix7g3c0bwkgdr8tznl.jpg)

不知道大家看到这里感觉如何？通过一系列的图，我相信每个人都能彻底理解这个ReadView的一套运行机制了



通过undo log多版本链条，加上你开启事务时候生产的一个ReadView，然后再有一个查询的时候，根据ReadView进行判断的机制，你就知道你应该读取哪个版本的数据。



而且他可以保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。假如说是你事务开启之前，就有别的事务正在运行，然后你事务开启之后 ，别的事务更新了值，你是绝对读不到的！或者是你事务开启之后，比你晚开启的事务更新了值，你也是读不到的！



通过这套机制就可以实现多个事务并发执行时候的数据隔离，下一次我们继续深入讲解RC和RR两个隔离级别下，这个ReadView是如何运用的。



## 55 Read Committed隔离级别是如何基于ReadView机制实现的？

今天我们来给大家讲一下，基于之前我们说的ReadView机制是如何实现Read Committed隔离级别的，那么当然了，首先就是要先做一些简单的回顾。所谓的Read Committed隔离级别，我们可以用骚气一点的名字，就是简称为 RC 隔离级别。



这个RC隔离级别，实际上意思就是说你事务运行期间，只要别的事务修改数据还提交了，你就是可以读到人家修改的数据的，所以是会发生不可重复读的问题，包括幻读的问题，都会有的。



那么所谓的ReadView机制，之前我们讲过，他是基于undo log版本链条实现的一套读视图机制，他意思就是说你事务生成一个ReadView，然后呢，如果是你事务自己更新的数据，自己是可以读到的，或者是在你生成ReadView之前提交的事务修改的值，也是可以读取到的。



但是如果是你生成ReadView的时候，就已经活跃的事务，在你生成ReadView之后修改了数据，接着提交了，此时你是读不到的，或者是你生成ReadView以后再开启的事务修改了数据，还提交了，此时也是读不到的。



所以上面的那套机制，实际上就是ReadView机制的一个原理。好，那么既然都回顾完了，我们就来看看，如何基于ReadView机制来实现RC隔离级别呢？



其实这里的一个非常核心的要点在于，当你一个事务设置他处于RC隔离级别的时候，他是每次发起查询，都重新生成一个ReadView！



大家注意，这点是非常重要的，接着我们通过画图一步一步来给大家演示这个RC隔离级别是怎么做到的。



首先假设我们的数据库里有一行数据，是事务id=50的一个事务之前就插入进去的，然后现在呢，活跃着两个事务，一个是事务A（id=60），一个是事务B（id=70），此时如下图所示。

​      ![1.jpg](all_in_one.assets/k8r6gv8r0zxeirq1vgi8.jpg)

现在的情况就是，事务B发起了一次update操作，更新了这条数据，把这条数据的值修改为了值B，所以此时数据的trx_id会变为事务B的id=70，同时会生成一条undo log，由roll_pointer来指向，看下图：

![2.jpg](all_in_one.assets/k8r6gv8r0laja8bmff3f.jpg)

这个时候，事务A要发起一次查询操作，此时他一发起查询操作，就会生成一个ReadView，此时ReadView里的min_trx_id=60，max_trx_id=71，creator_trx_id=60，此时如下图所示。

![3.jpg](all_in_one.assets/k8r6gv8r0bufkj85rko.jpg)

这个时候事务A发起查询，发现当前这条数据的trx_id是70。也就是说，属于ReadView的事务id范围之间，说明是他生成ReadView之前就有这个活跃的事务，是这个事务修改了这条数据的值，但是此时这个事务B还没提交，所以ReadView的m_ids活跃事务列表里，是有[60, 70]两个id的，所以此时根据ReadView的机制，此时事务A是无法查到事务B修改的值B的。



接着就顺着undo log版本链条往下查找，就会找到一个原始值，发现他的trx_id是50，小于当前ReadView里的min_trx_id，说明是他生成ReadView之前，就有一个事务插入了这个值并且早就提交了，因此可以查到这个原始值，如下图。

![4.jpg](all_in_one.assets/k8r6gv8r0h3r0689ener.jpg)

接着，咱们假设事务B此时就提交了，好了，那么提交了就说明事务B不会活跃于数据库里了，是不是？可以的，大家一定记住，事务B现在提交了。那么按照RC隔离级别的定义，事务B此时一旦提交了，说明事务A下次再查询，就可以读到事务B修改过的值了，因为事务B提交了。



那么到底怎么让事务A能够读到提交的事务B修改过的值呢？



很简单，就是让事务A下次发起查询，再次生成一个ReadView。此时再次生成ReadView，数据库内活跃的事务只有事务A了，因此min_trx_id是60，mac_trx_id是71，但是m_ids这个活跃事务列表里，只会有一个60了，事务B的id=70不会出现在m_ids活跃事务列表里了，如下图。

![5.jpg](all_in_one.assets/k8r6gv8s0tih5b5hstc.jpg)       

此时事务A再次基于这个ReadView去查询，会发现这条数据的trx_id=70，虽然在ReadView的min_trx_id和max_trx_id范围之间，但是此时并不在m_ids列表内，说明事务B在生成本次ReadView之前就已经提交了。



那么既然在生成本次ReadView之前，事务B就已经提交了，就说明这次你查询就可以查到事务B修改过的这个值了，此时事务A就会查到值B，如下图所示。

​      ![6.jpg](all_in_one.assets/k8r6gvyi008eemzjyjdhw.jpg)

到此为止，RC隔离级别如何实现的，大家应该就理解了，他的关键点在于每次查询都生成新的ReadView，那么如果在你这次查询之前，有事务修改了数据还提交了，你这次查询生成的ReadView里，那个m_ids列表当然不包含这个已经提交的事务了，既然不包含已经提交的事务了，那么当然可以读到人家修改过的值了。



这就是基于ReadView实现RC隔离级别的原理，希望大家好好仔细去体会，实际上，基于undo log多版本链条以及ReadView机制实现的多事务并发执行的RC隔离级别、RR隔离级别，就是数据库的MVCC多版本并发控制机制。



他本质是协调你多个事务并发运行的时候，并发的读写同一批数据，此时应该如何协调互相的可见性。



## 56 MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？

今天来接着给大家讲解，MySQL中最牛的RR隔离级别，是如何同时避免不可重复读问题和幻读问题的。



其实大家现在应该都知道，在MySQL中让多个事务并发运行的时候能够互相隔离，避免同时读写一条数据的时候有影响，是依托undo log版本链条和ReadView机制来实现的。



上次我们都讲过了，基于ReadView机制可以实现RC隔离级别，即你每次查询的时候都生成一个ReadView，这样的话，只要在你这次查询之前有别的事务提交了，那么别的事务更新的数据，你是可以看到的。



那么如果是RR级别呢？RR级别下，你这个事务读一条数据，无论读多少次，都是一个值，别的事务修改数据之后哪怕提交了，你也是看不到人家修改的值的，这就避免了不可重复读的问题。



同时如果别的事务插入了一些新的数据，你也是读不到的，这样你就可以避免幻读的问题。



那么到底是如何实现的呢？我们今天来看看。



首先我们还是假设有一条数据是事务id=5的一个事务插入的，同时此时有事务A和事务B同时在运行，事务A的id是60，事务B的id是70，如下图所示。

![1.jpg](all_in_one.assets/k8ztoffz0fry5iewa50i.jpg)

这个时候，事务A发起了一个查询，他就是第一次查询就会生成一个ReadView，此时ReadView里的creator_trx_id是60，min_trx_id是60，max_trx_id是71，m_ids是[60, 70]，此时ReadView如下图所示。

​      ![2.jpg](all_in_one.assets/k8ztoffz0tb973mnwgtn.jpg)       

这个时候事务A基于这个ReadView去查这条数据，会发现这条数据的trx_id为50，是小于ReadView里的min_trx_id的，说明他发起查询之前，早就有事务插入这条数据还提交了，所以此时可以查到这条原始值的，如下图。

​      ![3.jpg](all_in_one.assets/k8ztofg10z05ncva0cbr.jpg)

接着就是事务B此时更新了这条数据的值为值B，此时会修改trx_id为70，同时生成一个undo log，而且关键是事务B此时他还提交了，也就是说此时事务B已经结束了，如下图所示。

​      ![4.jpg](all_in_one.assets/k8ztofg10ehf069shkpt.jpg)

这个时候大家思考一个问题，ReadView中的m_ids此时还会是60和70吗？



那必然是的，因为ReadView一旦生成了就不会改变了，这个时候虽然事务B已经结束了，但是事务A的ReadView里，还是会有60和70两个事务id。



他的意思其实就是，在你事务A开启查询的时候，事务B当时是在运行的，就是这个意思。



那么好，接着此时事务A去查询这条数据的值，他会惊讶的发现此时数据的trx_id是70了，70一方面是在ReadView的min_trx_id和max_trx_id的范围区间的，同时还在m_ids列表中



这说明什么？



说明起码是事务A开启查询的时候，id为70的这个事务B还是在运行的，然后由这个事务B更新了这条数据，所以此时事务A是不能查询到事务B更新的这个值的，因此这个时候继续顺着指针往历史版本链条上去找，如下图。

​      ![5.jpg](all_in_one.assets/k8ztofg10bj5z6srgbe.jpg)

接着事务A顺着指针找到下面一条数据，trx_id为50，是小于ReadView的min_trx_id的，说明在他开启查询之前，就已经提交了这个事务了，所以事务A是可以查询到这个值的，此时事务A查到的是原始值，如下图。

![6.jpg](all_in_one.assets/k8ztog8m0slk4k92n22.jpg)

大家看到这里有什么感想？是不是感觉到这一下子就避免了不可重复读的问题？



你事务A多次读同一个数据，每次读到的都是一样的值，除非是他自己修改了值，否则读到的一直会一样的值。



不管别的事务如何修改数据，事务A的ReadView始终是不变的，他基于这个ReadView始终看到的值是一样的！



接着我们来看看幻读的问题他是如何解决的。假设现在事务A先用select * from x where id>10来查询，此时可能查到的就是一条数据，而且读到的是这条数据的原始值的那个版本，至于原因，上面都解释过了，如下图。

​      ![7.jpg](all_in_one.assets/k8ztogar0kqo782nte3i.jpg)      

现在有一个事务C插入了一条数据，然后提交了，此时如下图所示。

![8.jpg](all_in_one.assets/k8ztogf50pjjrmxfjkb.jpg)

接着，此时事务A再次查询，此时会发现符合条件的有2条数据，一条是原始值那个数据，一条是事务C插入的那条数据，但是事务C插入的那条数据的trx_id是80，这个80是大于自己的ReadView的max_trx_id的，说明是自己发起查询之后，这个事务才启动的，所以此时这条数据是不能查询的。



因此事务A本次查询，还是只能查到原始值一条数据，如下图。

​      ![9.jpg](all_in_one.assets/k8ztogkx0t67fxz9n1n.jpg)

所以大家可以看到，在这里，事务A根本不会发生幻读，他根据条件范围查询的时候，每次读到的数据都是一样的，不会读到人家插入进去的数据，这都是依托ReadView机制实现的！



好了，到此为止，如何基于ReadView机制实现RR隔离级别，避免不可重复读问题和幻读问题，就全部讲解清楚了，下次我们来做一个多事务并发隔离机制的总结。



## 57 停一停脚步：梳理一下数据库的多事务并发运行的隔离机制

今天给大家简单梳理一下MySQL中的多事务并发运行的隔离原理，其实这套隔离原理，说白了就是MVCC机制，也就是multi-version concurrent control，就是多版本并发控制机制，专门控制多个事务并发运行的时候，互相之间会如何影响。



首先我们先要明白，多个事务并发运行的时候，同时读写一个数据，可能会出现脏写、脏读、不可重复读、幻读几个问题



所谓的脏写，就是两个事务都更新一个数据，结果有一个人回滚了把另外一个人更新的数据也回滚没了。



脏读，就是一个事务读到了另外一个事务没提交的时候修改的数据，结果另外一个事务回滚了，下次读就读不到了。



不可重复读，就是多次读一条数据，别的事务老是修改数据值还提交了，多次读到的值不同。



幻读，就是范围查询，每次查到的数据不同，有时候别的事务插入了新的值，就会读到更多的数据。



针对这些问题，所以才有RU、RC、RR和串行四个隔离级别



RU隔离级别，就是可以读到人家没提交的事务修改的数据，只能避免脏写问题；



RC隔离级别，可以读到人家提交的事务修改过的数据，可以避免脏写和脏读问题。



RR是不会读到别的已经提交事务修改的数据，可以避免脏读、脏写和不可重复读的问题；



串行是让事务都串行执行，可以避免所有问题。



然后MySQL实现MVCC机制的时候，是基于**undo log多版本链条+ReadView机制**来做的，默认的RR隔离级别，就是基于这套机制来实现的，依托这套机制实现了RR级别，除了避免脏写、脏读、不可重复读，还能避免幻读问题。因此一般来说我们都用默认的RR隔离级别就好了



这就是数据库的隔离机制以及底层的原理，希望大家好好理解，可以复习一下之前的内容，把这套机制理解清楚了，接下来我们就要开始讲解锁机制了。



锁机制，解决的就是多个事务同时更新一行数据，此时必须要有一个加锁的机制



锁机制也是非常复杂的，我们接下来会用比较多的篇幅来讲清楚MySQL一套完整的锁机制，然后讲完了锁机制，就会来讲大量的实战案例了。



## 58 多个事务更新同一行数据时，是如何加锁避免脏写的？

## 59 对MySQL锁机制再深入一步，共享锁和独占锁到底是什么？

## 60 在数据库里，哪些操作会导致在表级别加锁呢？

## 61 表锁和行锁互相之间的关系以及互斥规则是什么呢？

## 62 案例实战：线上数据库不确定性的性能抖动优化实践（上）

## 63 案例实战：线上数据库莫名其妙的随机性能抖动优化（下）

## 64 深入研究索引之前，先来看看磁盘数据页的存储结构

## 65 假设没有任何索引，数据库是如何根据查询语句搜索数据的？

## 66 不断在表中插入数据时，物理存储是如何进行页分裂的？

## 67 基于主键的索引是如何设计的，以及如何根据主键索引查询？

## 68 索引的页存储物理结构，是如何用B+树来实现的？

## 69 更新数据的时候，自动维护的聚簇索引到底是什么？

## 70 针对主键之外的字段建立的二级索引，又是如何运作的？

## 71 插入数据时到底是如何维护好不同索引的B+树的？

## 72 一个表里是不是索引搞的越多越好？那你就大错特错了！

## 73 通过一步一图来深入理解联合索引查询原理以及全值匹配规则

## 74 再来看看几个最常见和最基本的索引使用规则

## 75 当我们在SQL里进行排序的时候，如何才能使用索引？

## 76 当我们在SQL里进行分组的时候，如何才能使用索引？

## 77 回表查询对性能的损害以及覆盖索引是什么？

## 78 设计索引的时候，我们一般要考虑哪些因素呢？（上）

## 79 设计索引的时候，我们一般要考虑哪些因素呢？（中）

## 80 设计索引的时候，我们一般要考虑哪些因素呢？（下）

## 81 案例实战：陌生人社交APP的MySQL索引设计实战（一）

## 82 案例实战：陌生人社交APP的MySQL索引设计实战（二）

## 83 案例实战：陌生人社交APP的MySQL索引设计实战（3）

## 84 案例实战：陌生人社交APP的MySQL索引设计实战（4）

## 85 提纲挈领的告诉你，SQL语句的执行计划和性能优化有什么关系？

## 86 以MySQL单表查询来举例，看看执行计划包含哪些内容（1）？

## 87 以MySQL单表查询来举例，看看执行计划包含哪些内容（2）？

## 88 再次重温写出各种SQL语句的时候，会用什么执行计划？（1）

## 89 再次重温写出各种SQL语句的时候，会用什么执行计划？（2）

## 90 再次重温写出各种SQL语句的时候，会用什么执行计划？（3）

## 91 深入探索多表关联的SQL语句到底是如何执行的？（1）

## 92 深入探索多表关联的SQL语句到底是如何执行的？（2）

## 93 深入探索多表关联的SQL语句到底是如何执行的？（3）

## 94 MySQL是如何根据成本优化选择执行计划的？（上）

## 95 MySQL是如何根据成本优化选择执行计划的？（中）

## 96 MySQL是如何根据成本优化选择执行计划的？（下）

## 97 MySQL是如何基于各种规则去优化执行计划的？（上）

## 98 MySQL是如何基于各种规则去优化执行计划的？（中）

## 99 MySQL是如何基于各种规则去优化执行计划的？（下）

## 100 透彻研究通过explain命令得到的SQL执行计划（1）

## 101 透彻研究通过explain命令得到的SQL执行计划（2）

## 102 透彻研究通过explain命令得到的SQL执行计划（3）

## 103 透彻研究通过explain命令得到的SQL执行计划（4）

## 104 透彻研究通过explain命令得到的SQL执行计划（5）

## 105 透彻研究通过explain命令得到的SQL执行计划（6）

## 106 透彻研究通过explain命令得到的SQL执行计划（7）

## 107 透彻研究通过explain命令得到的SQL执行计划（8）

## 108 透彻研究通过explain命令得到的SQL执行计划（9）

## 109 案例实战：千万级用户场景下的运营系统SQL调优（1）

## 110 案例实战：千万级用户场景下的运营系统SQL调优（2）

## 111 案例实战：千万级用户场景下的运营系统SQL调优（3）

## 112 案例实战：亿级数据量商品系统的SQL调优实战（1）

## 113 案例实战：亿级数据量商品系统的SQL调优实战（2）

## 114 案例实战：亿级数据量商品系统的SQL调优实战（3）

## 115 案例实战：数十亿数量级评论系统的SQL调优实战（1）

## 116 案例实战：千万级数据删除导致的慢查询优化实践（1）

## 117 案例实战：千万级数据删除导致的慢查询优化实践（2）

## 118 我们为什么要搭建一套MySQL的主从复制架构？（1）

## 119 我们为什么要搭建一套MySQL的主从复制架构？（2）

## 120 案例实战：千万级数据删除导致的慢查询优化实践（3）

## 121 如何为MySQL搭建一套主从复制架构？（1）

## 122 如何为MySQL搭建一套主从复制架构？（2）

## 123 如何为MySQL搭建一套主从复制架构？（3）

## 124 主从复制架构中的数据延迟问题，应该如何解决？

## 125 数据库高可用：基于主从复制实现故障转移（1）

## 126 数据库高可用：基于主从复制实现故障转移（2）

## 127 数据库高可用：基于主从复制实现故障转移（3）

## 128 案例实战：大型电商网站的上亿数据量的用户表如何进行水平拆分？

## 129 案例实战：一线电商公司的订单系统是如何进行数据库设计的？

## 130 案例实战：下一个难题，如果需要进行垮库的分页操作，应该怎么来做？

## 131 案例实战：当分库分表技术方案运行几年过后，再次进行扩容应该怎么做？

## 132 专栏总结：撒花庆祝大家对数据库技术的掌握更进一步
